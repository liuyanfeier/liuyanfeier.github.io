{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/README.md","path":"README.md","modified":0,"renderable":0},{"_id":"source/uploads/avatar.jpg","path":"uploads/avatar.jpg","modified":0,"renderable":0},{"_id":"source/images/favicon.ico","path":"images/favicon.ico","modified":0,"renderable":0},{"_id":"source/images/wechatpay.jpg","path":"images/wechatpay.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/README.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"source/.DS_Store","hash":"2640c36bc935e8f0977206a06b90833430b8e451","modified":1547545425000},{"_id":"themes/next/._config.yml.swp","hash":"5618d2c417699e203fb10231ac09702b7573ccd7","modified":1547549389000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1547545425000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1547545425000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1547545425000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1547545425000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1547545425000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1547545425000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1547545425000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1547545425000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1547545425000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1547545425000},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1547545425000},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1547545425000},{"_id":"themes/next/_config.yml","hash":"f172b269c04e645ff2b509369540770a9c9f08c1","modified":1547549389000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1547545425000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1547545425000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1547545425000},{"_id":"source/_posts/.DS_Store","hash":"11a26ce12164fcc542cd19f9a24f04e3eb56c0ac","modified":1547545425000},{"_id":"source/_posts/GMM模型.md","hash":"5b5871393719279593e8b322fab8de81bb1c3e8e","modified":1547545425000},{"_id":"source/_posts/Markdown.md","hash":"7079c62f4e268afff24799333733bd4100742720","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用.md","hash":"5c4ac805a10c3499f7275d8b4201183e297da54c","modified":1547545425000},{"_id":"source/_posts/fbank和mfcc特征提取.md","hash":"de51743045d5b369173b22862a27332646e01db4","modified":1547545425000},{"_id":"source/_posts/gdb使用笔记.md","hash":"0fa2c2ed76a7f5d04598c5450639a2a401bf45e0","modified":1547545425000},{"_id":"source/_posts/git基础.md","hash":"e2e5c0cd527244e93a9909f35a08f88e10855258","modified":1547545425000},{"_id":"source/_posts/item2和zsh配置.md","hash":"e6ad2b53aee66082d331fc2042ad5168c1518b0f","modified":1547545425000},{"_id":"source/_posts/kaldi-sge集群-nfs网络文件系统.md","hash":"732737539fff55afc13c85c15f30e629772a8691","modified":1547545425000},{"_id":"source/_posts/kaldi-chain-model.md","hash":"904de525dc0d3802afbbda3d6e0393c712f7a48e","modified":1547545425000},{"_id":"source/_posts/linux解压缩.md","hash":"6c5d10d30cbe84c0df47ab2f1221c23130df2860","modified":1547545425000},{"_id":"source/_posts/mac常用软件插件.md","hash":"02748a22ede740a5ee917ad5ba64a89684b4dcf8","modified":1547545425000},{"_id":"source/_posts/tensorflow小技巧.md","hash":"76655c9496e7a196fa9c87eb20b51f28cc87d48b","modified":1547545425000},{"_id":"source/_posts/vim和shell技巧.md","hash":"f9d49f3808c806fb5a1eff10966733ae14b47646","modified":1547545425000},{"_id":"source/_posts/viterbi以及forward-backword算法.md","hash":"08b6486576ddd5553a9dc3dfa1ffcc94c3edd854","modified":1547545425000},{"_id":"source/_posts/奇异值分解SVD.md","hash":"c151f28d0ff37ed2644755b44a579da7022bd03e","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法.md","hash":"c8c2fac5b6e19b7bcdb9ad1ce38346d1ba3ff8db","modified":1547545425000},{"_id":"source/_posts/语音基础概念.md","hash":"2c458ca9a2883c74cb6edf770d862e1b25de9006","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理.md","hash":"f5ccb01605e7bc2a2f8253ff68528e15b53ba7cc","modified":1547545425000},{"_id":"source/categories/index.md","hash":"6c1053f7390449919a804f391b04adb8b4018391","modified":1547545425000},{"_id":"source/images/.DS_Store","hash":"a65e7ff390898347c357b70bd2d10f3d8cab78f9","modified":1547545425000},{"_id":"source/tags/index.md","hash":"07e19127be6a959aff1595c09c897f5d7f483915","modified":1547545425000},{"_id":"source/uploads/.DS_Store","hash":"1872c6f790b91d3b586e800ac74968e83a6d58be","modified":1547545425000},{"_id":"source/uploads/avatar.jpg","hash":"926c4d1c146fad3c22c619fde2958235d1ffd2f5","modified":1547545425000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1547545425000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1547545425000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1547545425000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1547545425000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1547545425000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1547545425000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1547545425000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1547545425000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1547545425000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1547545425000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1547545425000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1547545425000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1547545425000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1547545425000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1547545425000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1547545425000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1547545425000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1547545425000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1547545425000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1547545425000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1547545425000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1547545425000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1547545425000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1547545425000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1547545425000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1547545425000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1547545425000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1547545425000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1547545425000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1547545425000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1547545425000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1547545425000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1547545425000},{"_id":"source/images/favicon.ico","hash":"c2bb41299f4cedb3adc3ad667e6811e907de7293","modified":1547545425000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"source/_posts/Markdown/.DS_Store","hash":"94247669b0862350be78760434f387b81d8e3763","modified":1547545425000},{"_id":"source/_posts/Markdown/2.jpg","hash":"8fbf8d66a1c439f42c2c26da8a4a0e9a52b8328f","modified":1547545425000},{"_id":"source/_posts/Markdown/3.jpg","hash":"4f20179a3f433cde3a10113b5316dfee1ee5131a","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用/.DS_Store","hash":"9bc2fcffa1d3e0b3c47756872d30153a82be29d8","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用/1.png","hash":"de836aecb2251187edf449cf9b1a753a4c0ced68","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用/3.png","hash":"a1d6b5faf6dd9c46f32af0b6b2da589d6642551e","modified":1547545425000},{"_id":"source/_posts/fbank和mfcc特征提取/2.png","hash":"b752209ec4abd432de2006ffa0e6fe5b204571cf","modified":1547545425000},{"_id":"source/_posts/git基础/git.jgp","hash":"558c5b3217f5613b3d6fbb7b27aaf2e68427fde9","modified":1547545425000},{"_id":"source/_posts/viterbi以及forward-backword算法/.DS_Store","hash":"d9130572a82d63bfa0311d74feca028470a7542a","modified":1547545425000},{"_id":"source/_posts/奇异值分解SVD/3.png","hash":"54c06511c06d1ff80094136cb3b2683a195dc294","modified":1547545425000},{"_id":"source/_posts/奇异值分解SVD/2.png","hash":"96ad767024d1b78c17e160d01df238409d84a3c9","modified":1547545425000},{"_id":"source/_posts/奇异值分解SVD/4.png","hash":"9d50e9157839e19b61bfa21beab57366e405734b","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法/.DS_Store","hash":"480604d9794b46fe25a1e6cab66f65a7da9de34e","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法/1.png","hash":"6d26da20481598221e09631d25690c609b94e5b4","modified":1547545425000},{"_id":"source/_posts/语音基础概念/.DS_Store","hash":"1490ae3be2be83b9b87b986b046117deeb25d653","modified":1547545425000},{"_id":"source/images/wechatpay.jpg","hash":"e7f3d1cc953df6fffdb18ce5859eccf9fb0dbea9","modified":1547545425000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1547545425000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1547545425000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1547545425000},{"_id":"themes/next/layout/_macro/.post.swig.swp","hash":"0abe462a076b28be0340ec50513370454b7a9905","modified":1547545425000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1547545425000},{"_id":"themes/next/layout/_macro/post.swig","hash":"00ca04166bf1d867c0df9e87f47a29faf916eac8","modified":1547545425000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1547545425000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1547545425000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1547545425000},{"_id":"themes/next/layout/_partials/.footer.swig.swp","hash":"5374f632238b7438f364ec344c81bda502e5b09c","modified":1547545425000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"5fc64a2f8d0bd3604c0edf4f25daf0f5a1e0d69b","modified":1547545425000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1547545425000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1547545425000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1547545425000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1547545425000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1547545425000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1547545425000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1547545425000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1547545425000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1547545425000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1547545425000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1547545425000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1547545425000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1547545425000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1547545425000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1547545425000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1547545425000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1547545425000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1547545425000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1547545425000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1547545425000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1547545425000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1547545425000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1547545425000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1547545425000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1547545425000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1547545425000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1547545425000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1547545425000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1547545425000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1547545425000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1547545425000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1547545425000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1547545425000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1547545425000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1547545425000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1547545425000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1547545425000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1547545425000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1547545425000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1547545425000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1547545425000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1547545425000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1547545425000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1547545425000},{"_id":"source/_posts/Markdown/1.jpg","hash":"38fc4c52eb15f69abff236a3dfa70a04fecb67e0","modified":1547545425000},{"_id":"source/_posts/Markdown/4.jpg","hash":"47ce3af38040c77430855c67f2c9e5bc93be30e4","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用/2.png","hash":"c561fd06f0c15a02d55fa7537ed9f7e9d76f25a3","modified":1547545425000},{"_id":"source/_posts/奇异值分解SVD/1.gif","hash":"c1f6e93c599877e59138177b0527b31fdb438137","modified":1547545425000},{"_id":"source/_posts/奇异值分解SVD/5.png","hash":"3eec70eeedaf453361183ff37f714581f03f9b0a","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/11.png","hash":"ce37a823aaa52096c0be551ee586cf3bc980171c","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/4.png","hash":"db8ad80eecc7301adedd31f9ea43649f701cd339","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/5.png","hash":"8a96bdb2f7f6bfb0bda7b82a662325f110a5061d","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/7.png","hash":"f8b3f5d027d7bfc3326a6c773a00f25435acf4bf","modified":1547545425000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1547545425000},{"_id":"source/_posts/kaldi-chain-model/4.png","hash":"71567217f131ebb93723bde4e7cb388ed1bd699f","modified":1547545425000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1547545425000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1547545425000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1547545425000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1547545425000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1547545425000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1547545425000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1547545425000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1547545425000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1547545425000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1547545425000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1547545425000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1547545425000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1547545425000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1547545425000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1547545425000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1547545425000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1547545425000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"03dc320ebb160378eac117738090cc2e5b97a98a","modified":1547545425000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1547545425000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1547545425000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1547545425000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1547545425000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1547545425000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1547545425000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1547545425000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1547545425000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1547545425000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1547545425000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1547545425000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1547545425000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1547545425000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1547545425000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1547545425000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1547545425000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1547545425000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1547545425000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1547545425000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1547545425000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1547545425000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1547545425000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1547545425000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1547545425000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1547545425000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1547545425000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1547545425000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1547545425000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1547545425000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1547545425000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1547545425000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1547545425000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1547545425000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1547545425000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1547545425000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1547545425000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1547545425000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1547545425000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1547545425000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1547545425000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1547545425000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1547545425000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1547545425000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1547545425000},{"_id":"source/_posts/fbank和mfcc特征提取/1.png","hash":"566b6a3daf55f9490aa47ba7ddfea0bf84e26585","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/1.png","hash":"fe34b739f861f68882eeb1b155efae46c4ea700e","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/10.png","hash":"78803e8169edceb32b0ecbb28dce4c9a3d376bf0","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/3.png","hash":"502feea79395339e0180f5fa51d88a9233a3a052","modified":1547545425000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1547545425000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用/4.png","hash":"555af7d66d4f24e4543a16cfaada39a92dac0d1f","modified":1547545425000},{"_id":"source/_posts/kaldi-chain-model/1.png","hash":"3aa8889f9ab9dba12b6323dd1dcaebad97128d8c","modified":1547545425000},{"_id":"source/_posts/kaldi-chain-model/3.png","hash":"3d3e15e451c4669a2baea61480b639fc29eba07c","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/2.png","hash":"f9adc8c7e1125b0d5a966461c823b7304a4d88c6","modified":1547545425000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1547545425000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1547545425000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1547545425000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1547545425000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1547545425000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1547545425000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1547545425000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1547545425000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1547545425000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1547545425000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1547545425000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1547545425000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1547545425000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1547545425000},{"_id":"source/_posts/viterbi以及forward-backword算法/1.png","hash":"29b93f27a8ddb5cff70dd1e16dadae174546481a","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1547545425000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1547545425000},{"_id":"source/_posts/kaldi-chain-model/2.png","hash":"4a1245e17016567d0b7dac171814f33befef06d8","modified":1547545425000},{"_id":"source/_posts/viterbi以及forward-backword算法/2.png","hash":"2bab17e02bea8bce58b3370840670e16fbfb31f8","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"b61919b8e67f7dacdacf5e3e3d33537bc8c65703","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1547545425000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1547545425000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1547545425000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1547545425000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1547545425000},{"_id":"source/_posts/item2和zsh配置/1.png","hash":"59082b3d30d96f457fb0daeee0574d0d56078117","modified":1547545425000},{"_id":"source/_posts/语音基础概念/2.png","hash":"042701074f73b4a01873650da7ea22ce212def99","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/6.png","hash":"c3a064e7dd295c3f7d1bfd6b4afc0e9a7b6f0ca5","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1547545425000},{"_id":"source/_posts/item2和zsh配置/2.png","hash":"74885eaefcdbe9f63c5c2c7cbd3ea301a89d77a1","modified":1547545425000},{"_id":"source/_posts/语音基础概念/1.png","hash":"7826b5b6966c4ac59d2a4617e3bab8bd98c35bec","modified":1547545425000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/8.png","hash":"dc0cd191115486f28861c63f7dd604c0d11ed82f","modified":1547545425000},{"_id":"source/_posts/ctc在asr上的应用/5.png","hash":"c42f85dd329932ad9e2543ab78e61b7f626eb9b9","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法/5.gif","hash":"7bc6fa9016fd09af21dc546a394621865c60b35d","modified":1547545425000},{"_id":"source/_posts/git基础/git常用命令速查表.jpg","hash":"0060dbfdfef5a2afb0a54bebb916d7a0cbf53fa6","modified":1547545425000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1547545425000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法/4.gif","hash":"0d4d768dcedf08df014f790f86d4f771451b7825","modified":1547545425000},{"_id":"source/_posts/语音识别基本原理/9.png","hash":"ef16ec41511536fc494fb59d952effc45305a1b3","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法/2.png","hash":"4685aa48ea98264184665f6da24b0db26b23ad59","modified":1547545425000},{"_id":"source/_posts/梯度下降优化算法/3.png","hash":"c04c558eb3b650829588a8044bb0441605bc5321","modified":1547545425000},{"_id":"public/categories/index.html","hash":"d8beda9de96b640276b164e484aae6b9cea14129","modified":1547549422164},{"_id":"public/tags/index.html","hash":"249366d7294ce971d5d3fbe35526f8011c358927","modified":1547549422164},{"_id":"public/categories/工具/index.html","hash":"cd9c499217feed1ddb9a825020ff180bab09de38","modified":1547549422164},{"_id":"public/categories/linux/index.html","hash":"79cf3dd33588dee066fdd97a2d6365e6ade7f1d6","modified":1547549422164},{"_id":"public/categories/deep-learning/index.html","hash":"ef49335bfd5aece78de99225a1d45b48962d914c","modified":1547549422164},{"_id":"public/archives/2016/index.html","hash":"d9983517c777b4313fb737fd2f3fc8bdd7e58a54","modified":1547549422164},{"_id":"public/archives/2016/11/index.html","hash":"90214d4ce485f2eedc50a9dbb2df447ffabe4ade","modified":1547549422165},{"_id":"public/archives/2017/01/index.html","hash":"682204d02d3aba4a70d493fe8c54387b954a8f90","modified":1547549422165},{"_id":"public/archives/2017/10/index.html","hash":"d1e633965c46faa8c15de3fb46eb1ea74e603325","modified":1547549422165},{"_id":"public/archives/2017/11/index.html","hash":"8f800838704b19dfcbd37aaa5b62ba6294b77bfc","modified":1547549422165},{"_id":"public/archives/2018/01/index.html","hash":"e0c1491ea1b88957c271dc657ff49730e9331958","modified":1547549422165},{"_id":"public/archives/2018/05/index.html","hash":"0324c3673541931f609f0a21c04b3203e1259418","modified":1547549422165},{"_id":"public/archives/2018/08/index.html","hash":"e38f07f066f52fe49dd7e091f2ba403161077d5c","modified":1547549422165},{"_id":"public/archives/2018/10/index.html","hash":"7f49ac566d5a27c8676b21d57d003b0580be7a98","modified":1547549422165},{"_id":"public/archives/2018/09/index.html","hash":"27b5922bf6bc4fe40923ce05fddd5bbe0e780858","modified":1547549422165},{"_id":"public/archives/2019/index.html","hash":"92cf9d2b99b271a37444368646b64286cc6853c2","modified":1547549422165},{"_id":"public/archives/2019/01/index.html","hash":"984e97ed35e0c5edcb4ec43d839b3a8231224a45","modified":1547549422165},{"_id":"public/tags/工具/index.html","hash":"5fa4d798d04e1e34edf6efd35799cc35b0840859","modified":1547549422165},{"_id":"public/tags/GMM/index.html","hash":"7de847ce9b300d245e71ca28bd01bd7972cd516a","modified":1547549422165},{"_id":"public/tags/ctc/index.html","hash":"19719c2f521282b90de16bd085beb50bfa53f1f0","modified":1547549422165},{"_id":"public/tags/deep-learning/index.html","hash":"9b715a0f5a84890d5cc1358c5f9ffd94b529297b","modified":1547549422165},{"_id":"public/tags/linux/index.html","hash":"ef18e02e6b98a0259afde9cdc76a0efd662cacc2","modified":1547549422165},{"_id":"public/tags/gdb/index.html","hash":"f56808df01c358e2fb25037cacac05404452cf47","modified":1547549422165},{"_id":"public/tags/iTerm2/index.html","hash":"be44de744588b2a1a63f924381473219c271dbe3","modified":1547549422165},{"_id":"public/tags/zsh/index.html","hash":"60287954e601a8e175c699355f8f57fe908a761c","modified":1547549422165},{"_id":"public/tags/git/index.html","hash":"b05e59b869e9e442caeece564c19986de364b5a2","modified":1547549422166},{"_id":"public/tags/kaldi/index.html","hash":"ceb4e787be3ddd458b1be2c1bc3b01011ba13bf7","modified":1547549422166},{"_id":"public/tags/sge/index.html","hash":"832ba2c747369e5f6be62ea70472b9eac4e5d476","modified":1547549422166},{"_id":"public/tags/nfs/index.html","hash":"9c33637308b2da413a855c92ab33252d60049b24","modified":1547549422166},{"_id":"public/tags/chain-model/index.html","hash":"4a905f0bab559ff207bb9cd27383b9d00b80f0e8","modified":1547549422166},{"_id":"public/tags/viterbi/index.html","hash":"36b943b7d9b7cf84edfc922f17bcd34e5c71d089","modified":1547549422166},{"_id":"public/tags/tensorflow/index.html","hash":"8ee52d465ef8d6fe78c1ebd8c7dfce56b9b38377","modified":1547549422166},{"_id":"public/tags/特征提取/index.html","hash":"d890fda66035255ba1bed57cff0a016fd0c78592","modified":1547549422166},{"_id":"public/tags/SVD/index.html","hash":"00e4975042c6bf16e5214845674e82e168b2f4a1","modified":1547549422166},{"_id":"public/tags/SGD/index.html","hash":"a360510b7146ab90c8e08ee049985a9a3ea27291","modified":1547549422166},{"_id":"public/2019/01/07/viterbi以及forward-backword算法/index.html","hash":"bcb141cbd96e23cbaf4a3c3c23a9c0312796bec7","modified":1547549422166},{"_id":"public/2019/01/04/gdb使用笔记/index.html","hash":"0a671d189a42e9cc427d00b13794ed29c51f6b20","modified":1547549422166},{"_id":"public/2018/10/11/奇异值分解SVD/index.html","hash":"aaaf368968ff73cce3a20403097437a3ceab6112","modified":1547549422166},{"_id":"public/2018/09/09/kaldi-sge集群-nfs网络文件系统/index.html","hash":"2b66e69cd9ab75bc51a9c1dbeed89b91673e29f4","modified":1547549422166},{"_id":"public/2018/08/10/梯度下降优化算法/index.html","hash":"168b88914c83853ab3f4995466bb03dbbe878400","modified":1547549422166},{"_id":"public/2018/05/08/kaldi-chain-model/index.html","hash":"432807fce05eafecb0c963a1fb938d4eaadf9059","modified":1547549422166},{"_id":"public/2018/01/23/mac常用软件插件/index.html","hash":"1d9b107ab1a43a3fc232b260a83283c3a788854a","modified":1547549422166},{"_id":"public/2018/01/22/Markdown/index.html","hash":"5fadab3c94423e044228fa480037f045cb73be27","modified":1547549422166},{"_id":"public/2018/01/04/GMM模型/index.html","hash":"7ccbe77ec11cf70a5ddd83d7c3af1501de3614de","modified":1547549422166},{"_id":"public/2018/01/03/vim和shell技巧/index.html","hash":"1cebefeaeffb2cc94fb576d3ea711d414a70cfa9","modified":1547549422167},{"_id":"public/2017/11/07/语音基础概念/index.html","hash":"1e2d126e6f04945a21e0c3d0b90ada2b1924ddb5","modified":1547549422167},{"_id":"public/2017/10/14/tensorflow小技巧/index.html","hash":"587f472b63fd5ed3f373646af0b96d464b937537","modified":1547549422167},{"_id":"public/2017/10/08/ctc在asr上的应用/index.html","hash":"4dc8568227a6a5a68c6c0d91a0540e2f4eb6ae88","modified":1547549422167},{"_id":"public/2017/10/07/fbank和mfcc特征提取/index.html","hash":"6909188804c89ebd8e95acf31fafb6b7bbcd36bd","modified":1547549422167},{"_id":"public/2017/10/07/语音识别基本原理/index.html","hash":"747283c4cf76b93b3e35abcd745010538b8a38b5","modified":1547549422167},{"_id":"public/2017/10/03/git基础/index.html","hash":"32161cac40bb36a800b16347c66ff31f2ec3d928","modified":1547549422167},{"_id":"public/2017/01/04/item2和zsh配置/index.html","hash":"425ff5223f2e934a5ebe62cfed728da842a72099","modified":1547549422167},{"_id":"public/2016/11/03/linux解压缩/index.html","hash":"1a73f4f52c7d35d80aa42596f09da3dd24f43fd2","modified":1547549422167},{"_id":"public/categories/语音识别/index.html","hash":"3cf452d1bde1d6d29efb55f4f475c95291132ae6","modified":1547549422167},{"_id":"public/archives/index.html","hash":"65cf62c4e008d000c7521a225c05bff7e1b69df2","modified":1547549422167},{"_id":"public/archives/page/2/index.html","hash":"c6d2bcb19bec309a796f180d2a3423f9023bf305","modified":1547549422167},{"_id":"public/archives/2017/index.html","hash":"b48abbd90b643047aedf121b928e70217af0bdad","modified":1547549422167},{"_id":"public/archives/2018/index.html","hash":"499743225c10bd2a263a8026a279594407a938a8","modified":1547549422167},{"_id":"public/tags/语音识别/index.html","hash":"845abc49122d33d8c7bb48765d7ddb992c6d5bfb","modified":1547549422167},{"_id":"public/page/2/index.html","hash":"3dc8e8663e68191a4ac868f437d6d4c83e6eb6aa","modified":1547549422167},{"_id":"public/index.html","hash":"1ff3c38ce2fca24ba2c9316e3509cf4616d924e0","modified":1547549422167}],"Category":[{"name":"工具","_id":"cjqxku2he0003ly0ga98cr173"},{"name":"语音识别","_id":"cjqxku2hk0008ly0guuv2w86e"},{"name":"linux","_id":"cjqxku2ht000ily0g9y06vs6d"},{"name":"deep learning","_id":"cjqxku2i60019ly0gycjrb0fk"}],"Data":[],"Page":[{"title":"categories","date":"2019-01-03T09:22:30.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle:      categories\ndate:       2019-01-03 17:22:30\ntype:       \"categories\"\ncomments:   false\n---\n","updated":"2019-01-15T09:43:45.000Z","path":"categories/index.html","layout":"page","_id":"cjqxku2hb0001ly0g2wlv1kyv","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2019-01-03T07:07:55.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-01-03 15:07:55\ntype: \"tags\"\ncomments: false\n---\n","updated":"2019-01-15T09:43:45.000Z","path":"tags/index.html","layout":"page","_id":"cjqxku2nb002ily0gypm6dj7j","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Markdown","author":"    liuyan","catalog":true,"date":"2018-01-22T11:30:00.000Z","urlname":null,"_content":"\n# 语法快捷键\n\n- command + t 可以插入表格\n- $$ + Enter 插入Latex公式   \n- 插入图片的时候直接拖拽就ok了\n- 输入[toc]+enter可以显示目录大纲\n- option + command + c 插入代码   \n- 行内代码`代码`    \\`代码\\`\n- option + command + b 插入公式\n- \\*斜线\\*    *斜线*    或者 command + i\n<!-- more -->\n- \\*\\*加粗\\*\\*    **加粗**   或者 command + b\n- **~**\\~删除~\\~    ~~删除~~\n- 水平分割线 ---\n- \\<u>下划线\\</u>    <u>下划线</u>\n- 无序列表    - 无序列表1    \n- 有序列表    1. 有序列表1\n- 任务列表    - [ ] 任务列表\n- \\>引用\n- \\[]()   插入网址\n- \\![]() 插入图片\n\n# 公式\n\n## 关系运算符\n\n```\n\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod\n```\n$$\n\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod\n$$\n\n## 集合运算符\n\n```\n\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup\n```\n$$\n\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup \n$$\n\n## 数学运算符\n\n```\n\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm{d} a^2 a_1\n```\n$$\n\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm{d} a^2 a_1\n$$\n\n## 实例\n\n```\n\\mathbf { V } _ { 1 } \\times \\mathbf { V } _ { 2 } = \\left| \\begin{array} { c c c } { \\mathbf { i } } & { \\mathbf { j } } & { \\mathbf { k } } \\\\ { \\frac { \\partial X } { \\partial u } } & { \\frac { \\partial Y } { \\partial u } } & { 0 } \\\\ { \\frac { \\partial X } { \\partial v } } & { \\frac { \\partial Y } { \\partial v } } & { 0 } \\end{array} \\right|\n```\n$$\n\\mathbf { V } _ { 1 } \\times \\mathbf { V } _ { 2 } = \\left| \\begin{array} { c c c } { \\mathbf { i } } & { \\mathbf { j } } & { \\mathbf { k } } \\\\ { \\frac { \\partial X } { \\partial u } } & { \\frac { \\partial Y } { \\partial u } } & { 0 } \\\\ { \\frac { \\partial X } { \\partial v } } & { \\frac { \\partial Y } { \\partial v } } & { 0 } \\end{array} \\right|\n$$\n\n```\nlim_{x \\to \\infty} \\ exp(-x)=0\n```\n$$\nlim _ {x \\to \\infty} \\ exp(-x)=0\n$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Markdown.md","raw":"---\ntitle:      Markdown\nauthor:     liuyan\ncatalog:    true\ntags:\n    - 工具\ndate:       2018-01-22 19:30:00\nurlname:    \ncategories: 工具\n---\n\n# 语法快捷键\n\n- command + t 可以插入表格\n- $$ + Enter 插入Latex公式   \n- 插入图片的时候直接拖拽就ok了\n- 输入[toc]+enter可以显示目录大纲\n- option + command + c 插入代码   \n- 行内代码`代码`    \\`代码\\`\n- option + command + b 插入公式\n- \\*斜线\\*    *斜线*    或者 command + i\n<!-- more -->\n- \\*\\*加粗\\*\\*    **加粗**   或者 command + b\n- **~**\\~删除~\\~    ~~删除~~\n- 水平分割线 ---\n- \\<u>下划线\\</u>    <u>下划线</u>\n- 无序列表    - 无序列表1    \n- 有序列表    1. 有序列表1\n- 任务列表    - [ ] 任务列表\n- \\>引用\n- \\[]()   插入网址\n- \\![]() 插入图片\n\n# 公式\n\n## 关系运算符\n\n```\n\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod\n```\n$$\n\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod\n$$\n\n## 集合运算符\n\n```\n\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup\n```\n$$\n\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup \n$$\n\n## 数学运算符\n\n```\n\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm{d} a^2 a_1\n```\n$$\n\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm{d} a^2 a_1\n$$\n\n## 实例\n\n```\n\\mathbf { V } _ { 1 } \\times \\mathbf { V } _ { 2 } = \\left| \\begin{array} { c c c } { \\mathbf { i } } & { \\mathbf { j } } & { \\mathbf { k } } \\\\ { \\frac { \\partial X } { \\partial u } } & { \\frac { \\partial Y } { \\partial u } } & { 0 } \\\\ { \\frac { \\partial X } { \\partial v } } & { \\frac { \\partial Y } { \\partial v } } & { 0 } \\end{array} \\right|\n```\n$$\n\\mathbf { V } _ { 1 } \\times \\mathbf { V } _ { 2 } = \\left| \\begin{array} { c c c } { \\mathbf { i } } & { \\mathbf { j } } & { \\mathbf { k } } \\\\ { \\frac { \\partial X } { \\partial u } } & { \\frac { \\partial Y } { \\partial u } } & { 0 } \\\\ { \\frac { \\partial X } { \\partial v } } & { \\frac { \\partial Y } { \\partial v } } & { 0 } \\end{array} \\right|\n$$\n\n```\nlim_{x \\to \\infty} \\ exp(-x)=0\n```\n$$\nlim _ {x \\to \\infty} \\ exp(-x)=0\n$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Markdown","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2h70000ly0gdoe3gih5","content":"<h1 id=\"语法快捷键\"><a href=\"#语法快捷键\" class=\"headerlink\" title=\"语法快捷键\"></a>语法快捷键</h1><ul>\n<li>command + t 可以插入表格</li>\n<li>$$ + Enter 插入Latex公式   </li>\n<li>插入图片的时候直接拖拽就ok了</li>\n<li>输入[toc]+enter可以显示目录大纲</li>\n<li>option + command + c 插入代码   </li>\n<li>行内代码<code>代码</code>    `代码`</li>\n<li>option + command + b 插入公式</li>\n<li>*斜线*    <em>斜线</em>    或者 command + i<a id=\"more\"></a></li>\n<li>**加粗**    <strong>加粗</strong>   或者 command + b</li>\n<li><strong>~</strong>~删除~~    <del>删除</del></li>\n<li>水平分割线 —</li>\n<li>\\<u>下划线\\</u>    <u>下划线</u></li>\n<li>无序列表    - 无序列表1    </li>\n<li>有序列表    1. 有序列表1</li>\n<li>任务列表    - [ ] 任务列表</li>\n<li>>引用</li>\n<li>[]()   插入网址</li>\n<li>!<a href=\"\"></a> 插入图片</li>\n</ul>\n<h1 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h1><h2 id=\"关系运算符\"><a href=\"#关系运算符\" class=\"headerlink\" title=\"关系运算符\"></a>关系运算符</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod<br>$$</p>\n<h2 id=\"集合运算符\"><a href=\"#集合运算符\" class=\"headerlink\" title=\"集合运算符\"></a>集合运算符</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup<br>$$</p>\n<h2 id=\"数学运算符\"><a href=\"#数学运算符\" class=\"headerlink\" title=\"数学运算符\"></a>数学运算符</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm&#123;d&#125; a^2 a_1</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm{d} a^2 a_1<br>$$</p>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\mathbf &#123; V &#125; _ &#123; 1 &#125; \\times \\mathbf &#123; V &#125; _ &#123; 2 &#125; = \\left| \\begin&#123;array&#125; &#123; c c c &#125; &#123; \\mathbf &#123; i &#125; &#125; &amp; &#123; \\mathbf &#123; j &#125; &#125; &amp; &#123; \\mathbf &#123; k &#125; &#125; \\\\ &#123; \\frac &#123; \\partial X &#125; &#123; \\partial u &#125; &#125; &amp; &#123; \\frac &#123; \\partial Y &#125; &#123; \\partial u &#125; &#125; &amp; &#123; 0 &#125; \\\\ &#123; \\frac &#123; \\partial X &#125; &#123; \\partial v &#125; &#125; &amp; &#123; \\frac &#123; \\partial Y &#125; &#123; \\partial v &#125; &#125; &amp; &#123; 0 &#125; \\end&#123;array&#125; \\right|</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\mathbf { V } _ { 1 } \\times \\mathbf { V } _ { 2 } = \\left| \\begin{array} { c c c } { \\mathbf { i } } &amp; { \\mathbf { j } } &amp; { \\mathbf { k } } \\ { \\frac { \\partial X } { \\partial u } } &amp; { \\frac { \\partial Y } { \\partial u } } &amp; { 0 } \\ { \\frac { \\partial X } { \\partial v } } &amp; { \\frac { \\partial Y } { \\partial v } } &amp; { 0 } \\end{array} \\right|<br>$$</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lim_&#123;x \\to \\infty&#125; \\ exp(-x)=0</span><br></pre></td></tr></table></figure>\n<p>$$<br>lim _ {x \\to \\infty} \\ exp(-x)=0<br>$$</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"语法快捷键\"><a href=\"#语法快捷键\" class=\"headerlink\" title=\"语法快捷键\"></a>语法快捷键</h1><ul>\n<li>command + t 可以插入表格</li>\n<li>$$ + Enter 插入Latex公式   </li>\n<li>插入图片的时候直接拖拽就ok了</li>\n<li>输入[toc]+enter可以显示目录大纲</li>\n<li>option + command + c 插入代码   </li>\n<li>行内代码<code>代码</code>    `代码`</li>\n<li>option + command + b 插入公式</li>\n<li>*斜线*    <em>斜线</em>    或者 command + i</li></ul>","more":"\n<li>**加粗**    <strong>加粗</strong>   或者 command + b</li>\n<li><strong>~</strong>~删除~~    <del>删除</del></li>\n<li>水平分割线 —</li>\n<li>\\<u>下划线\\</u>    <u>下划线</u></li>\n<li>无序列表    - 无序列表1    </li>\n<li>有序列表    1. 有序列表1</li>\n<li>任务列表    - [ ] 任务列表</li>\n<li>>引用</li>\n<li>[]()   插入网址</li>\n<li>!<a href=\"\"></a> 插入图片</li>\n\n<h1 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h1><h2 id=\"关系运算符\"><a href=\"#关系运算符\" class=\"headerlink\" title=\"关系运算符\"></a>关系运算符</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\times  \\div  \\mid  \\cdot  \\circ \\ast  \\bigodot  \\bigotimes  \\bigoplus  \\leq  \\geq  \\neq  \\approx  \\equiv  \\sum  \\prod  \\coprod<br>$$</p>\n<h2 id=\"集合运算符\"><a href=\"#集合运算符\" class=\"headerlink\" title=\"集合运算符\"></a>集合运算符</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\emptyset  \\in  \\notin  \\subset  \\supset  \\subseteq  \\supseteq  \\bigcap  \\bigcup  \\bigvee  \\bigwedge  \\biguplus  \\bigsqcup<br>$$</p>\n<h2 id=\"数学运算符\"><a href=\"#数学运算符\" class=\"headerlink\" title=\"数学运算符\"></a>数学运算符</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm&#123;d&#125; a^2 a_1</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\log  \\lg  \\ln  \\bot  \\angle  \\sin  \\cos  \\tan  \\cot  \\sec  \\csc  \\prime  \\int  \\iint  \\iiint  \\oint  \\lim  \\infty  \\nabla  \\mathrm{d} a^2 a_1<br>$$</p>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\mathbf &#123; V &#125; _ &#123; 1 &#125; \\times \\mathbf &#123; V &#125; _ &#123; 2 &#125; = \\left| \\begin&#123;array&#125; &#123; c c c &#125; &#123; \\mathbf &#123; i &#125; &#125; &amp; &#123; \\mathbf &#123; j &#125; &#125; &amp; &#123; \\mathbf &#123; k &#125; &#125; \\\\ &#123; \\frac &#123; \\partial X &#125; &#123; \\partial u &#125; &#125; &amp; &#123; \\frac &#123; \\partial Y &#125; &#123; \\partial u &#125; &#125; &amp; &#123; 0 &#125; \\\\ &#123; \\frac &#123; \\partial X &#125; &#123; \\partial v &#125; &#125; &amp; &#123; \\frac &#123; \\partial Y &#125; &#123; \\partial v &#125; &#125; &amp; &#123; 0 &#125; \\end&#123;array&#125; \\right|</span><br></pre></td></tr></table></figure>\n<p>$$<br>\\mathbf { V } _ { 1 } \\times \\mathbf { V } _ { 2 } = \\left| \\begin{array} { c c c } { \\mathbf { i } } &amp; { \\mathbf { j } } &amp; { \\mathbf { k } } \\ { \\frac { \\partial X } { \\partial u } } &amp; { \\frac { \\partial Y } { \\partial u } } &amp; { 0 } \\ { \\frac { \\partial X } { \\partial v } } &amp; { \\frac { \\partial Y } { \\partial v } } &amp; { 0 } \\end{array} \\right|<br>$$</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lim_&#123;x \\to \\infty&#125; \\ exp(-x)=0</span><br></pre></td></tr></table></figure>\n<p>$$<br>lim _ {x \\to \\infty} \\ exp(-x)=0<br>$$</p>"},{"title":"GMM模型","author":"liuyan","catalog":true,"date":"2018-01-04T09:55:05.000Z","urlname":null,"_content":"\n### 概述\n\n现有的高斯模型有单高斯模型（SGM）和高斯混合模型（GMM）两种。从几何上讲，单高斯分布模型在二维空间上近似于椭圆，在三维空间上近似于椭球。 在很多情况下，属于同一类别的样本点并不满足椭圆分布的特性，所以我们需要引入混合高斯模型来解决这种情况。\n\n在DNN兴盛之前，高斯混合模型（GMM, Gaussian Mixture Model）广泛应用在语音识别的声学模型建模中，即使现在，在训练DNN模型之前依然需要通过GMM模型进行迭代，以及进行强制对齐。因此想要对语音识别技术有一定的了解，对于GMM模型的了解是必不可少的。\n\n<!-- more -->\n\n### 单高斯模型\n\n如果多维变量X服从高斯分布时，它的概率密度函数（PDF）定义为：\n$$\n\\mathrm { N } ( \\mathrm { x } | \\mu , \\Sigma ) = \\frac { 1 } { ( 2 \\pi ) ^ { D / 2 } } \\frac { 1 } { ( | \\Sigma | ) ^ { 1 / 2 } } \\exp \\left[ - \\frac { 1 } { 2 } ( x - \\mu ) ^ { T } \\Sigma ^ { - 1 } ( x - \\mu ) \\right]\n$$\n\n在上述定义中,x是维数为D的样本向量，$ \\mu $是模型期望，$ \\Sigma $是模型协方差。对于单高斯模型，可以明确训练样本是否属于该高斯模型，所以我们经常将$ \\mu $用训练样本的均值代替，将$ \\Sigma $用训练样本的协方差代替。\n\n### 高斯混合模型\n\n高斯混合模型，就是数据可以看作是从多个高斯分布中生成出来的。每个GMM由K个高斯分布组成，每个高斯分布称为一个组件（Component），这些组件线性加成在一起就组成了GMM的概率密度函数:\n$$\n\\mathrm { p } ( \\mathrm { x } ) = \\sum _ { k = 1 } ^ { K } p ( k ) p ( x | k ) = \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x | \\mu _ { k } , \\Sigma _ { k } )\n$$\n其中$ \\pi _ {k} $是样本数据属于第k个子模型的概率。\n\n根据上面的式子，如果我们要从GMM分布中随机地取一个点，需要两步：\n- 随机地在这K个组件中选一个，每个组件被选中的概率实际上就是它的系数$ \\pi_k $；\n- 选中了组件之后，再单独地考虑从这个组件的分布中选取一个点。\n\n在已知概率密度函数的情况下，要估计其中参数的过程被称作参数估计。我们可以利用最大似然估计来确定这些参数，GMM的似然函数如下:\n$$\n\\sum _ { i = 1 } ^ { N } \\log { \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x _ { i } | \\mu _ { k } , \\Sigma _ { k } ) }\n$$\n\n### EM算法进行GMM参数估计\n\n对于高斯混合模型，参数包括$ \\pi, \\mu, \\Sigma $。直接进行模型估计比较困难所以我们使用EM算法来求解这些参数。EM算法通常分成两步:\n- E步，根据当前的参数$ \\pi, \\mu, \\Sigma $，计算每个样本在每个高斯分量上的后验概率。\n- M步，根据当前的后验概率分布，更新参数$ \\pi, \\mu, \\Sigma $。\n\nE-M算法：\n\n1. 初始化模型参数。\n\n2. E步，计算每个样本由各个组件生成的概率。对于样本$ x _ {i} $来说，它由第k个组件生成的概率为：\n$$\n\\gamma ( \\mathrm { i } , \\mathrm { k } ) = \\frac { \\pi _ { k } N \\left( x _ { i } | \\mu _ { k } , \\Sigma _ { k } \\right) } { \\sum _ { j = 1 } ^ { K } \\pi _ { j } N \\left( x _ { i } | \\mu _ { j } , \\Sigma _ { k j } \\right) }\n$$\n在上面的概率公式中，我们假定$ \\pi $，$ \\mu $和$ \\Sigma $均是已知的，它们的值来自于初始化值或者上一次迭代。\n\n3. M步，估计每个组件的参数。由于每个组件都是一个标准的高斯分布，可以很容易的求出最大似然所对应的参数值：\n$$\n{ N _ { k } = \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) } \n$$\n$$\n{ \\pi _ { k } = \\frac { N _ { k } } { N } } \n$$\n$$\n{ \\mu _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) x _ { i } } \n$$\n$$\n\\Sigma _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) \\left( x _ { i } - \\mu _ { k } \\right) \\left( x _ { i } - \\mu _ { k } \\right) ^ { T }\n$$\n\n","source":"_posts/GMM模型.md","raw":"---\ntitle:      GMM模型\nauthor:     liuyan\ncatalog:    true\ntags:\n  - GMM\n  - 语音识别\ndate:       2018-01-04 17:55:05\nurlname:\ncategories: 语音识别\n---\n\n### 概述\n\n现有的高斯模型有单高斯模型（SGM）和高斯混合模型（GMM）两种。从几何上讲，单高斯分布模型在二维空间上近似于椭圆，在三维空间上近似于椭球。 在很多情况下，属于同一类别的样本点并不满足椭圆分布的特性，所以我们需要引入混合高斯模型来解决这种情况。\n\n在DNN兴盛之前，高斯混合模型（GMM, Gaussian Mixture Model）广泛应用在语音识别的声学模型建模中，即使现在，在训练DNN模型之前依然需要通过GMM模型进行迭代，以及进行强制对齐。因此想要对语音识别技术有一定的了解，对于GMM模型的了解是必不可少的。\n\n<!-- more -->\n\n### 单高斯模型\n\n如果多维变量X服从高斯分布时，它的概率密度函数（PDF）定义为：\n$$\n\\mathrm { N } ( \\mathrm { x } | \\mu , \\Sigma ) = \\frac { 1 } { ( 2 \\pi ) ^ { D / 2 } } \\frac { 1 } { ( | \\Sigma | ) ^ { 1 / 2 } } \\exp \\left[ - \\frac { 1 } { 2 } ( x - \\mu ) ^ { T } \\Sigma ^ { - 1 } ( x - \\mu ) \\right]\n$$\n\n在上述定义中,x是维数为D的样本向量，$ \\mu $是模型期望，$ \\Sigma $是模型协方差。对于单高斯模型，可以明确训练样本是否属于该高斯模型，所以我们经常将$ \\mu $用训练样本的均值代替，将$ \\Sigma $用训练样本的协方差代替。\n\n### 高斯混合模型\n\n高斯混合模型，就是数据可以看作是从多个高斯分布中生成出来的。每个GMM由K个高斯分布组成，每个高斯分布称为一个组件（Component），这些组件线性加成在一起就组成了GMM的概率密度函数:\n$$\n\\mathrm { p } ( \\mathrm { x } ) = \\sum _ { k = 1 } ^ { K } p ( k ) p ( x | k ) = \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x | \\mu _ { k } , \\Sigma _ { k } )\n$$\n其中$ \\pi _ {k} $是样本数据属于第k个子模型的概率。\n\n根据上面的式子，如果我们要从GMM分布中随机地取一个点，需要两步：\n- 随机地在这K个组件中选一个，每个组件被选中的概率实际上就是它的系数$ \\pi_k $；\n- 选中了组件之后，再单独地考虑从这个组件的分布中选取一个点。\n\n在已知概率密度函数的情况下，要估计其中参数的过程被称作参数估计。我们可以利用最大似然估计来确定这些参数，GMM的似然函数如下:\n$$\n\\sum _ { i = 1 } ^ { N } \\log { \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x _ { i } | \\mu _ { k } , \\Sigma _ { k } ) }\n$$\n\n### EM算法进行GMM参数估计\n\n对于高斯混合模型，参数包括$ \\pi, \\mu, \\Sigma $。直接进行模型估计比较困难所以我们使用EM算法来求解这些参数。EM算法通常分成两步:\n- E步，根据当前的参数$ \\pi, \\mu, \\Sigma $，计算每个样本在每个高斯分量上的后验概率。\n- M步，根据当前的后验概率分布，更新参数$ \\pi, \\mu, \\Sigma $。\n\nE-M算法：\n\n1. 初始化模型参数。\n\n2. E步，计算每个样本由各个组件生成的概率。对于样本$ x _ {i} $来说，它由第k个组件生成的概率为：\n$$\n\\gamma ( \\mathrm { i } , \\mathrm { k } ) = \\frac { \\pi _ { k } N \\left( x _ { i } | \\mu _ { k } , \\Sigma _ { k } \\right) } { \\sum _ { j = 1 } ^ { K } \\pi _ { j } N \\left( x _ { i } | \\mu _ { j } , \\Sigma _ { k j } \\right) }\n$$\n在上面的概率公式中，我们假定$ \\pi $，$ \\mu $和$ \\Sigma $均是已知的，它们的值来自于初始化值或者上一次迭代。\n\n3. M步，估计每个组件的参数。由于每个组件都是一个标准的高斯分布，可以很容易的求出最大似然所对应的参数值：\n$$\n{ N _ { k } = \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) } \n$$\n$$\n{ \\pi _ { k } = \\frac { N _ { k } } { N } } \n$$\n$$\n{ \\mu _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) x _ { i } } \n$$\n$$\n\\Sigma _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) \\left( x _ { i } - \\mu _ { k } \\right) \\left( x _ { i } - \\mu _ { k } \\right) ^ { T }\n$$\n\n","slug":"GMM模型","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hc0002ly0g9dexu64i","content":"<h3 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h3><p>现有的高斯模型有单高斯模型（SGM）和高斯混合模型（GMM）两种。从几何上讲，单高斯分布模型在二维空间上近似于椭圆，在三维空间上近似于椭球。 在很多情况下，属于同一类别的样本点并不满足椭圆分布的特性，所以我们需要引入混合高斯模型来解决这种情况。</p>\n<p>在DNN兴盛之前，高斯混合模型（GMM, Gaussian Mixture Model）广泛应用在语音识别的声学模型建模中，即使现在，在训练DNN模型之前依然需要通过GMM模型进行迭代，以及进行强制对齐。因此想要对语音识别技术有一定的了解，对于GMM模型的了解是必不可少的。</p>\n<a id=\"more\"></a>\n<h3 id=\"单高斯模型\"><a href=\"#单高斯模型\" class=\"headerlink\" title=\"单高斯模型\"></a>单高斯模型</h3><p>如果多维变量X服从高斯分布时，它的概率密度函数（PDF）定义为：<br>$$<br>\\mathrm { N } ( \\mathrm { x } | \\mu , \\Sigma ) = \\frac { 1 } { ( 2 \\pi ) ^ { D / 2 } } \\frac { 1 } { ( | \\Sigma | ) ^ { 1 / 2 } } \\exp \\left[ - \\frac { 1 } { 2 } ( x - \\mu ) ^ { T } \\Sigma ^ { - 1 } ( x - \\mu ) \\right]<br>$$</p>\n<p>在上述定义中,x是维数为D的样本向量，$ \\mu $是模型期望，$ \\Sigma $是模型协方差。对于单高斯模型，可以明确训练样本是否属于该高斯模型，所以我们经常将$ \\mu $用训练样本的均值代替，将$ \\Sigma $用训练样本的协方差代替。</p>\n<h3 id=\"高斯混合模型\"><a href=\"#高斯混合模型\" class=\"headerlink\" title=\"高斯混合模型\"></a>高斯混合模型</h3><p>高斯混合模型，就是数据可以看作是从多个高斯分布中生成出来的。每个GMM由K个高斯分布组成，每个高斯分布称为一个组件（Component），这些组件线性加成在一起就组成了GMM的概率密度函数:<br>$$<br>\\mathrm { p } ( \\mathrm { x } ) = \\sum _ { k = 1 } ^ { K } p ( k ) p ( x | k ) = \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x | \\mu _ { k } , \\Sigma _ { k } )<br>$$<br>其中$ \\pi _ {k} $是样本数据属于第k个子模型的概率。</p>\n<p>根据上面的式子，如果我们要从GMM分布中随机地取一个点，需要两步：</p>\n<ul>\n<li>随机地在这K个组件中选一个，每个组件被选中的概率实际上就是它的系数$ \\pi_k $；</li>\n<li>选中了组件之后，再单独地考虑从这个组件的分布中选取一个点。</li>\n</ul>\n<p>在已知概率密度函数的情况下，要估计其中参数的过程被称作参数估计。我们可以利用最大似然估计来确定这些参数，GMM的似然函数如下:<br>$$<br>\\sum _ { i = 1 } ^ { N } \\log { \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x _ { i } | \\mu _ { k } , \\Sigma _ { k } ) }<br>$$</p>\n<h3 id=\"EM算法进行GMM参数估计\"><a href=\"#EM算法进行GMM参数估计\" class=\"headerlink\" title=\"EM算法进行GMM参数估计\"></a>EM算法进行GMM参数估计</h3><p>对于高斯混合模型，参数包括$ \\pi, \\mu, \\Sigma $。直接进行模型估计比较困难所以我们使用EM算法来求解这些参数。EM算法通常分成两步:</p>\n<ul>\n<li>E步，根据当前的参数$ \\pi, \\mu, \\Sigma $，计算每个样本在每个高斯分量上的后验概率。</li>\n<li>M步，根据当前的后验概率分布，更新参数$ \\pi, \\mu, \\Sigma $。</li>\n</ul>\n<p>E-M算法：</p>\n<ol>\n<li><p>初始化模型参数。</p>\n</li>\n<li><p>E步，计算每个样本由各个组件生成的概率。对于样本$ x _ {i} $来说，它由第k个组件生成的概率为：<br>$$<br>\\gamma ( \\mathrm { i } , \\mathrm { k } ) = \\frac { \\pi _ { k } N \\left( x _ { i } | \\mu _ { k } , \\Sigma _ { k } \\right) } { \\sum _ { j = 1 } ^ { K } \\pi _ { j } N \\left( x _ { i } | \\mu _ { j } , \\Sigma _ { k j } \\right) }<br>$$<br>在上面的概率公式中，我们假定$ \\pi $，$ \\mu $和$ \\Sigma $均是已知的，它们的值来自于初始化值或者上一次迭代。</p>\n</li>\n<li><p>M步，估计每个组件的参数。由于每个组件都是一个标准的高斯分布，可以很容易的求出最大似然所对应的参数值：<br>$$<br>{ N _ { k } = \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) }<br>$$<br>$$<br>{ \\pi _ { k } = \\frac { N _ { k } } { N } }<br>$$<br>$$<br>{ \\mu _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) x _ { i } }<br>$$<br>$$<br>\\Sigma _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) \\left( x _ { i } - \\mu _ { k } \\right) \\left( x _ { i } - \\mu _ { k } \\right) ^ { T }<br>$$</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h3 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h3><p>现有的高斯模型有单高斯模型（SGM）和高斯混合模型（GMM）两种。从几何上讲，单高斯分布模型在二维空间上近似于椭圆，在三维空间上近似于椭球。 在很多情况下，属于同一类别的样本点并不满足椭圆分布的特性，所以我们需要引入混合高斯模型来解决这种情况。</p>\n<p>在DNN兴盛之前，高斯混合模型（GMM, Gaussian Mixture Model）广泛应用在语音识别的声学模型建模中，即使现在，在训练DNN模型之前依然需要通过GMM模型进行迭代，以及进行强制对齐。因此想要对语音识别技术有一定的了解，对于GMM模型的了解是必不可少的。</p>","more":"<h3 id=\"单高斯模型\"><a href=\"#单高斯模型\" class=\"headerlink\" title=\"单高斯模型\"></a>单高斯模型</h3><p>如果多维变量X服从高斯分布时，它的概率密度函数（PDF）定义为：<br>$$<br>\\mathrm { N } ( \\mathrm { x } | \\mu , \\Sigma ) = \\frac { 1 } { ( 2 \\pi ) ^ { D / 2 } } \\frac { 1 } { ( | \\Sigma | ) ^ { 1 / 2 } } \\exp \\left[ - \\frac { 1 } { 2 } ( x - \\mu ) ^ { T } \\Sigma ^ { - 1 } ( x - \\mu ) \\right]<br>$$</p>\n<p>在上述定义中,x是维数为D的样本向量，$ \\mu $是模型期望，$ \\Sigma $是模型协方差。对于单高斯模型，可以明确训练样本是否属于该高斯模型，所以我们经常将$ \\mu $用训练样本的均值代替，将$ \\Sigma $用训练样本的协方差代替。</p>\n<h3 id=\"高斯混合模型\"><a href=\"#高斯混合模型\" class=\"headerlink\" title=\"高斯混合模型\"></a>高斯混合模型</h3><p>高斯混合模型，就是数据可以看作是从多个高斯分布中生成出来的。每个GMM由K个高斯分布组成，每个高斯分布称为一个组件（Component），这些组件线性加成在一起就组成了GMM的概率密度函数:<br>$$<br>\\mathrm { p } ( \\mathrm { x } ) = \\sum _ { k = 1 } ^ { K } p ( k ) p ( x | k ) = \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x | \\mu _ { k } , \\Sigma _ { k } )<br>$$<br>其中$ \\pi _ {k} $是样本数据属于第k个子模型的概率。</p>\n<p>根据上面的式子，如果我们要从GMM分布中随机地取一个点，需要两步：</p>\n<ul>\n<li>随机地在这K个组件中选一个，每个组件被选中的概率实际上就是它的系数$ \\pi_k $；</li>\n<li>选中了组件之后，再单独地考虑从这个组件的分布中选取一个点。</li>\n</ul>\n<p>在已知概率密度函数的情况下，要估计其中参数的过程被称作参数估计。我们可以利用最大似然估计来确定这些参数，GMM的似然函数如下:<br>$$<br>\\sum _ { i = 1 } ^ { N } \\log { \\sum _ { k = 1 } ^ { K } \\pi _ { k } N ( x _ { i } | \\mu _ { k } , \\Sigma _ { k } ) }<br>$$</p>\n<h3 id=\"EM算法进行GMM参数估计\"><a href=\"#EM算法进行GMM参数估计\" class=\"headerlink\" title=\"EM算法进行GMM参数估计\"></a>EM算法进行GMM参数估计</h3><p>对于高斯混合模型，参数包括$ \\pi, \\mu, \\Sigma $。直接进行模型估计比较困难所以我们使用EM算法来求解这些参数。EM算法通常分成两步:</p>\n<ul>\n<li>E步，根据当前的参数$ \\pi, \\mu, \\Sigma $，计算每个样本在每个高斯分量上的后验概率。</li>\n<li>M步，根据当前的后验概率分布，更新参数$ \\pi, \\mu, \\Sigma $。</li>\n</ul>\n<p>E-M算法：</p>\n<ol>\n<li><p>初始化模型参数。</p>\n</li>\n<li><p>E步，计算每个样本由各个组件生成的概率。对于样本$ x _ {i} $来说，它由第k个组件生成的概率为：<br>$$<br>\\gamma ( \\mathrm { i } , \\mathrm { k } ) = \\frac { \\pi _ { k } N \\left( x _ { i } | \\mu _ { k } , \\Sigma _ { k } \\right) } { \\sum _ { j = 1 } ^ { K } \\pi _ { j } N \\left( x _ { i } | \\mu _ { j } , \\Sigma _ { k j } \\right) }<br>$$<br>在上面的概率公式中，我们假定$ \\pi $，$ \\mu $和$ \\Sigma $均是已知的，它们的值来自于初始化值或者上一次迭代。</p>\n</li>\n<li><p>M步，估计每个组件的参数。由于每个组件都是一个标准的高斯分布，可以很容易的求出最大似然所对应的参数值：<br>$$<br>{ N _ { k } = \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) }<br>$$<br>$$<br>{ \\pi _ { k } = \\frac { N _ { k } } { N } }<br>$$<br>$$<br>{ \\mu _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) x _ { i } }<br>$$<br>$$<br>\\Sigma _ { k } = \\frac { 1 } { N _ { k } } \\sum _ { i = 1 } ^ { N } \\gamma ( \\mathrm { i } , \\mathrm { k } ) \\left( x _ { i } - \\mu _ { k } \\right) \\left( x _ { i } - \\mu _ { k } \\right) ^ { T }<br>$$</p>\n</li>\n</ol>"},{"title":"ctc在asr上的应用","author":"liuyan","catalog":true,"date":"2017-10-08T03:20:54.000Z","urlname":null,"_content":"\n### CTC概念\n\nCTC算法全称叫：Connectionist temporal classification，从字面上理解它是用来解决时序类数据的分类问题的。\n\n下图是nihao这句话的声音波形示意图，每个红色的框代表一帧数据，传统DNN训练需要知道每一帧数据对应的发音音素。比如第1,2,3,4帧对应n的发音，第5,6,7帧对应i的音素......（这里暂且将每个字母作为一个发音音素，下同）\n\n![](1.png)\n\n<!-- more -->\n\n采用CTC作为损失函数的声学模型，不需要预先对数据做对齐，只需要一个输入序列和一个输出序列就可以进行训练。\n\nCTC引入了blank（该帧没有预测值），每个预测的分类对应一整段语音中的一个spike（尖峰），其他不是尖峰的位置认为是blank。对于一段语音，CTC最后的输出是尖峰的序列，其并不关心每一个音素持续了多长时间。 \n\n![](2.png)\n\n进过CTC预测的序列结果在时间上可能会稍微延迟于真实发音对应的时间点，其他时间点都会被标记会blank。 \n\n![](3.png)\n\n这种神经网络+CTC的结构除了声学模型以外，也可以用到任何输入序列到输出序列的训练上（**输入序列的长度必须大于输出序列**）。比如，OCR识别也可以采用RNN+CTC来做。\n\n### CTC详情\n\nCTC是一种损失函数，它用来衡量输入的序列数据经过神经网络之后，和真实的输出相差有多少。\n\n对于nihao这句话，假设输入是30帧的音频数据，输出的音素长度为5。若两个人都说了nihao这句话，他们的真实输出结果都是nihao这5个有序的音素，但是因为每个人的发音特点不一样，原始的音频数据在经过神经网络计算之后，第一个人得到的结果可能是：nni...aao（长度为30），第二个人说的话得到的结果可能是：nii...aoo（长度为30），都是正确结果。可以想象长度为30的音频数据，最后可以对应上nihao这个发音顺序的结果是非常多的。CTC就是在这种序列有多种可能性的情况下，计算损失值的一种方法。\n\n#### 详细描述\n\n训练集合为$ S = ( x ^ { 1 } , z ^ { 1 } ) , ( x ^ { 2 } , z ^ { 2 } ) , \\ldots ( x ^ { N } , z ^ { N } ) $, 表示有N个训练样本，x是输入样本，z是对应的输出。\n\n对于其中一个样本$ ( x , z ) , x = \\left( x _ { 1 } , x _ { 2 } , x _ { 3 } , \\ldots , x _ { T } \\right)  $表示一个长度为T帧的数据，每一帧数据是一个m维向量。$ x _ {i} $可以理解为对于一段语音，每25ms作为一帧，其中第i帧经过MFCC计算后得到的结果。$ z = \\left( z _ { 1 } , z _ { 2 } , z _ { 3 } , \\dots z _ { U } \\right)  $表示这段语音对应的正确音素。\n\n特征x在经过RNN和softmax层之后，得到音素的后验概率矩阵y。 $ y _ { k } ^ { t } ( k = 1,2,3 , \\ldots n , t = 1,2,3 , \\ldots , T )  $表示在t时刻，发音为音素k的概率，其中音素的种类个数一共n个，k表示第k个音素，在一帧的数据上所有的音素概率加起来为1。即：\n$$\n\\sum _ { t = 1 } ^ { T } y _ { k } ^ { t } = 1 , y _ { k } ^ { t } \\geq 0\n$$\n\n具体过程如下图所示：\n![](4.png)\n\n后面基于CTC的训练就是基于后验概率矩阵y得到的。\n\n#### 映射关系\n\n30帧数据经过RNN前向计算之后输出的是一个30\\*n（n是音素个数+1，blank）的矩阵，矩阵每一列取最大值之后也是得到30个输出，那怎么和[n,i,h,a,o]这5个因素比较计算loss。\n\n定义B变换表示简单的压缩：$ B(𝑎,𝑎,𝑏,𝑏,𝑐,𝑐,𝑑)=(𝑎,𝑏,𝑐,𝑑) $\n$ 那么B(n,i,i,h,...,a,o)=(n,i,h,a,o)，B(n,n,i,h,...,a,o,o)=(n,i,h,a,o)... $\n\n但是这种变换有一个缺陷就是没法表示两个相同因素在一起的情况。解决方法就是我们前面提到的CTC中引入的blank。加入blank之后具体映射方式如下图。\n\n![](5.png)\n\n通过这种映射关系，30个RNN输出就可以被映射到[n,i,h,a,o]这5个音素上。\n\n前向后向算法bp过程见：https://blog.csdn.net/xmdxcsj/article/details/51763886\nCTC原始论文见：http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf\n\n其中取log为：\n$$\n\\begin{array} { c } { \\log ( a + b ) = \\log \\left( a \\left( 1 + \\frac { b } { a } \\right) \\right) = \\log a + \\log \\left( 1 + \\frac { b } { a } \\right) } \\\\ { = \\log a + \\log \\left( 1 + \\exp \\left( \\log \\left( \\frac { b } { a } \\right) \\right) \\right) = \\log a + \\log ( 1 + \\exp ( \\log b - \\log a ) ) } \\end{array}\n$$\n\n","source":"_posts/ctc在asr上的应用.md","raw":"---\ntitle:      ctc在asr上的应用\nauthor:     liuyan\ncatalog:    true\ntags:\n  - ctc\n  - deep learning\n  - 语音识别\ndate:       2017-10-08 11:20:54\nurlname:\ncategories: 语音识别\n---\n\n### CTC概念\n\nCTC算法全称叫：Connectionist temporal classification，从字面上理解它是用来解决时序类数据的分类问题的。\n\n下图是nihao这句话的声音波形示意图，每个红色的框代表一帧数据，传统DNN训练需要知道每一帧数据对应的发音音素。比如第1,2,3,4帧对应n的发音，第5,6,7帧对应i的音素......（这里暂且将每个字母作为一个发音音素，下同）\n\n![](1.png)\n\n<!-- more -->\n\n采用CTC作为损失函数的声学模型，不需要预先对数据做对齐，只需要一个输入序列和一个输出序列就可以进行训练。\n\nCTC引入了blank（该帧没有预测值），每个预测的分类对应一整段语音中的一个spike（尖峰），其他不是尖峰的位置认为是blank。对于一段语音，CTC最后的输出是尖峰的序列，其并不关心每一个音素持续了多长时间。 \n\n![](2.png)\n\n进过CTC预测的序列结果在时间上可能会稍微延迟于真实发音对应的时间点，其他时间点都会被标记会blank。 \n\n![](3.png)\n\n这种神经网络+CTC的结构除了声学模型以外，也可以用到任何输入序列到输出序列的训练上（**输入序列的长度必须大于输出序列**）。比如，OCR识别也可以采用RNN+CTC来做。\n\n### CTC详情\n\nCTC是一种损失函数，它用来衡量输入的序列数据经过神经网络之后，和真实的输出相差有多少。\n\n对于nihao这句话，假设输入是30帧的音频数据，输出的音素长度为5。若两个人都说了nihao这句话，他们的真实输出结果都是nihao这5个有序的音素，但是因为每个人的发音特点不一样，原始的音频数据在经过神经网络计算之后，第一个人得到的结果可能是：nni...aao（长度为30），第二个人说的话得到的结果可能是：nii...aoo（长度为30），都是正确结果。可以想象长度为30的音频数据，最后可以对应上nihao这个发音顺序的结果是非常多的。CTC就是在这种序列有多种可能性的情况下，计算损失值的一种方法。\n\n#### 详细描述\n\n训练集合为$ S = ( x ^ { 1 } , z ^ { 1 } ) , ( x ^ { 2 } , z ^ { 2 } ) , \\ldots ( x ^ { N } , z ^ { N } ) $, 表示有N个训练样本，x是输入样本，z是对应的输出。\n\n对于其中一个样本$ ( x , z ) , x = \\left( x _ { 1 } , x _ { 2 } , x _ { 3 } , \\ldots , x _ { T } \\right)  $表示一个长度为T帧的数据，每一帧数据是一个m维向量。$ x _ {i} $可以理解为对于一段语音，每25ms作为一帧，其中第i帧经过MFCC计算后得到的结果。$ z = \\left( z _ { 1 } , z _ { 2 } , z _ { 3 } , \\dots z _ { U } \\right)  $表示这段语音对应的正确音素。\n\n特征x在经过RNN和softmax层之后，得到音素的后验概率矩阵y。 $ y _ { k } ^ { t } ( k = 1,2,3 , \\ldots n , t = 1,2,3 , \\ldots , T )  $表示在t时刻，发音为音素k的概率，其中音素的种类个数一共n个，k表示第k个音素，在一帧的数据上所有的音素概率加起来为1。即：\n$$\n\\sum _ { t = 1 } ^ { T } y _ { k } ^ { t } = 1 , y _ { k } ^ { t } \\geq 0\n$$\n\n具体过程如下图所示：\n![](4.png)\n\n后面基于CTC的训练就是基于后验概率矩阵y得到的。\n\n#### 映射关系\n\n30帧数据经过RNN前向计算之后输出的是一个30\\*n（n是音素个数+1，blank）的矩阵，矩阵每一列取最大值之后也是得到30个输出，那怎么和[n,i,h,a,o]这5个因素比较计算loss。\n\n定义B变换表示简单的压缩：$ B(𝑎,𝑎,𝑏,𝑏,𝑐,𝑐,𝑑)=(𝑎,𝑏,𝑐,𝑑) $\n$ 那么B(n,i,i,h,...,a,o)=(n,i,h,a,o)，B(n,n,i,h,...,a,o,o)=(n,i,h,a,o)... $\n\n但是这种变换有一个缺陷就是没法表示两个相同因素在一起的情况。解决方法就是我们前面提到的CTC中引入的blank。加入blank之后具体映射方式如下图。\n\n![](5.png)\n\n通过这种映射关系，30个RNN输出就可以被映射到[n,i,h,a,o]这5个音素上。\n\n前向后向算法bp过程见：https://blog.csdn.net/xmdxcsj/article/details/51763886\nCTC原始论文见：http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf\n\n其中取log为：\n$$\n\\begin{array} { c } { \\log ( a + b ) = \\log \\left( a \\left( 1 + \\frac { b } { a } \\right) \\right) = \\log a + \\log \\left( 1 + \\frac { b } { a } \\right) } \\\\ { = \\log a + \\log \\left( 1 + \\exp \\left( \\log \\left( \\frac { b } { a } \\right) \\right) \\right) = \\log a + \\log ( 1 + \\exp ( \\log b - \\log a ) ) } \\end{array}\n$$\n\n","slug":"ctc在asr上的应用","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hg0005ly0ggta75jfa","content":"<h3 id=\"CTC概念\"><a href=\"#CTC概念\" class=\"headerlink\" title=\"CTC概念\"></a>CTC概念</h3><p>CTC算法全称叫：Connectionist temporal classification，从字面上理解它是用来解决时序类数据的分类问题的。</p>\n<p>下图是nihao这句话的声音波形示意图，每个红色的框代表一帧数据，传统DNN训练需要知道每一帧数据对应的发音音素。比如第1,2,3,4帧对应n的发音，第5,6,7帧对应i的音素……（这里暂且将每个字母作为一个发音音素，下同）</p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/1.png\" alt=\"\"></p>\n<a id=\"more\"></a>\n<p>采用CTC作为损失函数的声学模型，不需要预先对数据做对齐，只需要一个输入序列和一个输出序列就可以进行训练。</p>\n<p>CTC引入了blank（该帧没有预测值），每个预测的分类对应一整段语音中的一个spike（尖峰），其他不是尖峰的位置认为是blank。对于一段语音，CTC最后的输出是尖峰的序列，其并不关心每一个音素持续了多长时间。 </p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/2.png\" alt=\"\"></p>\n<p>进过CTC预测的序列结果在时间上可能会稍微延迟于真实发音对应的时间点，其他时间点都会被标记会blank。 </p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/3.png\" alt=\"\"></p>\n<p>这种神经网络+CTC的结构除了声学模型以外，也可以用到任何输入序列到输出序列的训练上（<strong>输入序列的长度必须大于输出序列</strong>）。比如，OCR识别也可以采用RNN+CTC来做。</p>\n<h3 id=\"CTC详情\"><a href=\"#CTC详情\" class=\"headerlink\" title=\"CTC详情\"></a>CTC详情</h3><p>CTC是一种损失函数，它用来衡量输入的序列数据经过神经网络之后，和真实的输出相差有多少。</p>\n<p>对于nihao这句话，假设输入是30帧的音频数据，输出的音素长度为5。若两个人都说了nihao这句话，他们的真实输出结果都是nihao这5个有序的音素，但是因为每个人的发音特点不一样，原始的音频数据在经过神经网络计算之后，第一个人得到的结果可能是：nni…aao（长度为30），第二个人说的话得到的结果可能是：nii…aoo（长度为30），都是正确结果。可以想象长度为30的音频数据，最后可以对应上nihao这个发音顺序的结果是非常多的。CTC就是在这种序列有多种可能性的情况下，计算损失值的一种方法。</p>\n<h4 id=\"详细描述\"><a href=\"#详细描述\" class=\"headerlink\" title=\"详细描述\"></a>详细描述</h4><p>训练集合为$ S = ( x ^ { 1 } , z ^ { 1 } ) , ( x ^ { 2 } , z ^ { 2 } ) , \\ldots ( x ^ { N } , z ^ { N } ) $, 表示有N个训练样本，x是输入样本，z是对应的输出。</p>\n<p>对于其中一个样本$ ( x , z ) , x = \\left( x _ { 1 } , x _ { 2 } , x _ { 3 } , \\ldots , x _ { T } \\right)  $表示一个长度为T帧的数据，每一帧数据是一个m维向量。$ x _ {i} $可以理解为对于一段语音，每25ms作为一帧，其中第i帧经过MFCC计算后得到的结果。$ z = \\left( z _ { 1 } , z _ { 2 } , z _ { 3 } , \\dots z _ { U } \\right)  $表示这段语音对应的正确音素。</p>\n<p>特征x在经过RNN和softmax层之后，得到音素的后验概率矩阵y。 $ y _ { k } ^ { t } ( k = 1,2,3 , \\ldots n , t = 1,2,3 , \\ldots , T )  $表示在t时刻，发音为音素k的概率，其中音素的种类个数一共n个，k表示第k个音素，在一帧的数据上所有的音素概率加起来为1。即：<br>$$<br>\\sum _ { t = 1 } ^ { T } y _ { k } ^ { t } = 1 , y _ { k } ^ { t } \\geq 0<br>$$</p>\n<p>具体过程如下图所示：<br><img src=\"/2017/10/08/ctc在asr上的应用/4.png\" alt=\"\"></p>\n<p>后面基于CTC的训练就是基于后验概率矩阵y得到的。</p>\n<h4 id=\"映射关系\"><a href=\"#映射关系\" class=\"headerlink\" title=\"映射关系\"></a>映射关系</h4><p>30帧数据经过RNN前向计算之后输出的是一个30*n（n是音素个数+1，blank）的矩阵，矩阵每一列取最大值之后也是得到30个输出，那怎么和[n,i,h,a,o]这5个因素比较计算loss。</p>\n<p>定义B变换表示简单的压缩：$ B(𝑎,𝑎,𝑏,𝑏,𝑐,𝑐,𝑑)=(𝑎,𝑏,𝑐,𝑑) $<br>$ 那么B(n,i,i,h,…,a,o)=(n,i,h,a,o)，B(n,n,i,h,…,a,o,o)=(n,i,h,a,o)… $</p>\n<p>但是这种变换有一个缺陷就是没法表示两个相同因素在一起的情况。解决方法就是我们前面提到的CTC中引入的blank。加入blank之后具体映射方式如下图。</p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/5.png\" alt=\"\"></p>\n<p>通过这种映射关系，30个RNN输出就可以被映射到[n,i,h,a,o]这5个音素上。</p>\n<p>前向后向算法bp过程见：<a href=\"https://blog.csdn.net/xmdxcsj/article/details/51763886\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/xmdxcsj/article/details/51763886</a><br>CTC原始论文见：<a href=\"http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf\" target=\"_blank\" rel=\"noopener\">http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf</a></p>\n<p>其中取log为：<br>$$<br>\\begin{array} { c } { \\log ( a + b ) = \\log \\left( a \\left( 1 + \\frac { b } { a } \\right) \\right) = \\log a + \\log \\left( 1 + \\frac { b } { a } \\right) } \\ { = \\log a + \\log \\left( 1 + \\exp \\left( \\log \\left( \\frac { b } { a } \\right) \\right) \\right) = \\log a + \\log ( 1 + \\exp ( \\log b - \\log a ) ) } \\end{array}<br>$$</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"CTC概念\"><a href=\"#CTC概念\" class=\"headerlink\" title=\"CTC概念\"></a>CTC概念</h3><p>CTC算法全称叫：Connectionist temporal classification，从字面上理解它是用来解决时序类数据的分类问题的。</p>\n<p>下图是nihao这句话的声音波形示意图，每个红色的框代表一帧数据，传统DNN训练需要知道每一帧数据对应的发音音素。比如第1,2,3,4帧对应n的发音，第5,6,7帧对应i的音素……（这里暂且将每个字母作为一个发音音素，下同）</p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/1.png\" alt=\"\"></p>","more":"<p>采用CTC作为损失函数的声学模型，不需要预先对数据做对齐，只需要一个输入序列和一个输出序列就可以进行训练。</p>\n<p>CTC引入了blank（该帧没有预测值），每个预测的分类对应一整段语音中的一个spike（尖峰），其他不是尖峰的位置认为是blank。对于一段语音，CTC最后的输出是尖峰的序列，其并不关心每一个音素持续了多长时间。 </p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/2.png\" alt=\"\"></p>\n<p>进过CTC预测的序列结果在时间上可能会稍微延迟于真实发音对应的时间点，其他时间点都会被标记会blank。 </p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/3.png\" alt=\"\"></p>\n<p>这种神经网络+CTC的结构除了声学模型以外，也可以用到任何输入序列到输出序列的训练上（<strong>输入序列的长度必须大于输出序列</strong>）。比如，OCR识别也可以采用RNN+CTC来做。</p>\n<h3 id=\"CTC详情\"><a href=\"#CTC详情\" class=\"headerlink\" title=\"CTC详情\"></a>CTC详情</h3><p>CTC是一种损失函数，它用来衡量输入的序列数据经过神经网络之后，和真实的输出相差有多少。</p>\n<p>对于nihao这句话，假设输入是30帧的音频数据，输出的音素长度为5。若两个人都说了nihao这句话，他们的真实输出结果都是nihao这5个有序的音素，但是因为每个人的发音特点不一样，原始的音频数据在经过神经网络计算之后，第一个人得到的结果可能是：nni…aao（长度为30），第二个人说的话得到的结果可能是：nii…aoo（长度为30），都是正确结果。可以想象长度为30的音频数据，最后可以对应上nihao这个发音顺序的结果是非常多的。CTC就是在这种序列有多种可能性的情况下，计算损失值的一种方法。</p>\n<h4 id=\"详细描述\"><a href=\"#详细描述\" class=\"headerlink\" title=\"详细描述\"></a>详细描述</h4><p>训练集合为$ S = ( x ^ { 1 } , z ^ { 1 } ) , ( x ^ { 2 } , z ^ { 2 } ) , \\ldots ( x ^ { N } , z ^ { N } ) $, 表示有N个训练样本，x是输入样本，z是对应的输出。</p>\n<p>对于其中一个样本$ ( x , z ) , x = \\left( x _ { 1 } , x _ { 2 } , x _ { 3 } , \\ldots , x _ { T } \\right)  $表示一个长度为T帧的数据，每一帧数据是一个m维向量。$ x _ {i} $可以理解为对于一段语音，每25ms作为一帧，其中第i帧经过MFCC计算后得到的结果。$ z = \\left( z _ { 1 } , z _ { 2 } , z _ { 3 } , \\dots z _ { U } \\right)  $表示这段语音对应的正确音素。</p>\n<p>特征x在经过RNN和softmax层之后，得到音素的后验概率矩阵y。 $ y _ { k } ^ { t } ( k = 1,2,3 , \\ldots n , t = 1,2,3 , \\ldots , T )  $表示在t时刻，发音为音素k的概率，其中音素的种类个数一共n个，k表示第k个音素，在一帧的数据上所有的音素概率加起来为1。即：<br>$$<br>\\sum _ { t = 1 } ^ { T } y _ { k } ^ { t } = 1 , y _ { k } ^ { t } \\geq 0<br>$$</p>\n<p>具体过程如下图所示：<br><img src=\"/2017/10/08/ctc在asr上的应用/4.png\" alt=\"\"></p>\n<p>后面基于CTC的训练就是基于后验概率矩阵y得到的。</p>\n<h4 id=\"映射关系\"><a href=\"#映射关系\" class=\"headerlink\" title=\"映射关系\"></a>映射关系</h4><p>30帧数据经过RNN前向计算之后输出的是一个30*n（n是音素个数+1，blank）的矩阵，矩阵每一列取最大值之后也是得到30个输出，那怎么和[n,i,h,a,o]这5个因素比较计算loss。</p>\n<p>定义B变换表示简单的压缩：$ B(𝑎,𝑎,𝑏,𝑏,𝑐,𝑐,𝑑)=(𝑎,𝑏,𝑐,𝑑) $<br>$ 那么B(n,i,i,h,…,a,o)=(n,i,h,a,o)，B(n,n,i,h,…,a,o,o)=(n,i,h,a,o)… $</p>\n<p>但是这种变换有一个缺陷就是没法表示两个相同因素在一起的情况。解决方法就是我们前面提到的CTC中引入的blank。加入blank之后具体映射方式如下图。</p>\n<p><img src=\"/2017/10/08/ctc在asr上的应用/5.png\" alt=\"\"></p>\n<p>通过这种映射关系，30个RNN输出就可以被映射到[n,i,h,a,o]这5个音素上。</p>\n<p>前向后向算法bp过程见：<a href=\"https://blog.csdn.net/xmdxcsj/article/details/51763886\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/xmdxcsj/article/details/51763886</a><br>CTC原始论文见：<a href=\"http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf\" target=\"_blank\" rel=\"noopener\">http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf</a></p>\n<p>其中取log为：<br>$$<br>\\begin{array} { c } { \\log ( a + b ) = \\log \\left( a \\left( 1 + \\frac { b } { a } \\right) \\right) = \\log a + \\log \\left( 1 + \\frac { b } { a } \\right) } \\ { = \\log a + \\log \\left( 1 + \\exp \\left( \\log \\left( \\frac { b } { a } \\right) \\right) \\right) = \\log a + \\log ( 1 + \\exp ( \\log b - \\log a ) ) } \\end{array}<br>$$</p>"},{"title":"gdb使用笔记","author":"liuyan","catalog":true,"date":"2019-01-04T07:41:33.000Z","urlname":null,"_content":"\n### 例子\n\n```shell\ngdb mimir\nr --config=config\nbt\n```\n\n<!-- more -->\n\n### 命令\n\n- 进入GDB　　`gdb mimir`\n\n  `mimir`是要调试的程序，由`gcc mimir.c -g -o mimir`生成。进入后提示符变为(gdb) 。\n\n- 查看源码　　`(gdb) l`\n\n  如果需要查看在其他文件中定义的函数，在l后加上函数名即可定位到这个函数的定义及查看附近的其他源码。\n\n- 运行代码　　`(gdb) r`\n\n- 设置断点　　`(gdb) b filename:function/linenum`\n\n  这样会在运行到该文件的function或者linenum时停止，可以查看变量的值、堆栈情况等。**想看那个函数就直接下断点进去就好。**\n\n- 查看断点处情况　　`(gdb) info b`\n\n  可以通过`info b`来查看断点处情况，可以设置多个断点。\n\n- 查看函数堆栈     `(gdb) bt`\n\n  `bt(backtrace)`命令是很有用的一个命令，当程序运行过程中崩了的时候可以使用该命令快速定位。\n\n- 显示变量值　　`(gdb) p n`\n\n  在程序暂停时，键入`p(print) 变量名`即可。GDB在显示变量值时都会在对应值之前加上`$N`标记，它是当前变量值的引用标记，以后若想再次引用此变量，就可以直接写作`$N`，而无需写冗长的变量名。\n\n- 观察变量　　`(gdb) watch n`\n\n  在某一循环处，往往希望能够观察一个变量的变化情况，这时就可以键入命令`watch`来观察变量的变化情况，GDB在n设置了观察点。\n\n- 单步运行　　`(gdb) n/s [count]`\n\n  `n(next)`和`s(step)`都表示单步跟踪，如果有函数调用s进入该函数n不进入。count表示执行其后的n条指令。\n\n- 程序继续运行　　`(gdb) c/fg [ignore-count]`\n\n  `c(continue)/fg`使程序继续往下运行，直到再次遇到断点或程序结束。ignore-count表示忽略其后n个断点。\n\n- 退出GDB　　`(gdb) q`\n\n","source":"_posts/gdb使用笔记.md","raw":"---\ntitle:      gdb使用笔记\nauthor:     liuyan\ncatalog:    true\ntags:\n  - linux\n  - gdb\ndate:       2019-01-04 15:41:33\nurlname:\ncategories: linux\n---\n\n### 例子\n\n```shell\ngdb mimir\nr --config=config\nbt\n```\n\n<!-- more -->\n\n### 命令\n\n- 进入GDB　　`gdb mimir`\n\n  `mimir`是要调试的程序，由`gcc mimir.c -g -o mimir`生成。进入后提示符变为(gdb) 。\n\n- 查看源码　　`(gdb) l`\n\n  如果需要查看在其他文件中定义的函数，在l后加上函数名即可定位到这个函数的定义及查看附近的其他源码。\n\n- 运行代码　　`(gdb) r`\n\n- 设置断点　　`(gdb) b filename:function/linenum`\n\n  这样会在运行到该文件的function或者linenum时停止，可以查看变量的值、堆栈情况等。**想看那个函数就直接下断点进去就好。**\n\n- 查看断点处情况　　`(gdb) info b`\n\n  可以通过`info b`来查看断点处情况，可以设置多个断点。\n\n- 查看函数堆栈     `(gdb) bt`\n\n  `bt(backtrace)`命令是很有用的一个命令，当程序运行过程中崩了的时候可以使用该命令快速定位。\n\n- 显示变量值　　`(gdb) p n`\n\n  在程序暂停时，键入`p(print) 变量名`即可。GDB在显示变量值时都会在对应值之前加上`$N`标记，它是当前变量值的引用标记，以后若想再次引用此变量，就可以直接写作`$N`，而无需写冗长的变量名。\n\n- 观察变量　　`(gdb) watch n`\n\n  在某一循环处，往往希望能够观察一个变量的变化情况，这时就可以键入命令`watch`来观察变量的变化情况，GDB在n设置了观察点。\n\n- 单步运行　　`(gdb) n/s [count]`\n\n  `n(next)`和`s(step)`都表示单步跟踪，如果有函数调用s进入该函数n不进入。count表示执行其后的n条指令。\n\n- 程序继续运行　　`(gdb) c/fg [ignore-count]`\n\n  `c(continue)/fg`使程序继续往下运行，直到再次遇到断点或程序结束。ignore-count表示忽略其后n个断点。\n\n- 退出GDB　　`(gdb) q`\n\n","slug":"gdb使用笔记","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hi0006ly0gd5yiwx6e","content":"<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gdb mimir</span><br><span class=\"line\">r --config=config</span><br><span class=\"line\">bt</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h3 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h3><ul>\n<li><p>进入GDB　　<code>gdb mimir</code></p>\n<p><code>mimir</code>是要调试的程序，由<code>gcc mimir.c -g -o mimir</code>生成。进入后提示符变为(gdb) 。</p>\n</li>\n<li><p>查看源码　　<code>(gdb) l</code></p>\n<p>如果需要查看在其他文件中定义的函数，在l后加上函数名即可定位到这个函数的定义及查看附近的其他源码。</p>\n</li>\n<li><p>运行代码　　<code>(gdb) r</code></p>\n</li>\n<li><p>设置断点　　<code>(gdb) b filename:function/linenum</code></p>\n<p>这样会在运行到该文件的function或者linenum时停止，可以查看变量的值、堆栈情况等。<strong>想看那个函数就直接下断点进去就好。</strong></p>\n</li>\n<li><p>查看断点处情况　　<code>(gdb) info b</code></p>\n<p>可以通过<code>info b</code>来查看断点处情况，可以设置多个断点。</p>\n</li>\n<li><p>查看函数堆栈     <code>(gdb) bt</code></p>\n<p><code>bt(backtrace)</code>命令是很有用的一个命令，当程序运行过程中崩了的时候可以使用该命令快速定位。</p>\n</li>\n<li><p>显示变量值　　<code>(gdb) p n</code></p>\n<p>在程序暂停时，键入<code>p(print) 变量名</code>即可。GDB在显示变量值时都会在对应值之前加上<code>$N</code>标记，它是当前变量值的引用标记，以后若想再次引用此变量，就可以直接写作<code>$N</code>，而无需写冗长的变量名。</p>\n</li>\n<li><p>观察变量　　<code>(gdb) watch n</code></p>\n<p>在某一循环处，往往希望能够观察一个变量的变化情况，这时就可以键入命令<code>watch</code>来观察变量的变化情况，GDB在n设置了观察点。</p>\n</li>\n<li><p>单步运行　　<code>(gdb) n/s [count]</code></p>\n<p><code>n(next)</code>和<code>s(step)</code>都表示单步跟踪，如果有函数调用s进入该函数n不进入。count表示执行其后的n条指令。</p>\n</li>\n<li><p>程序继续运行　　<code>(gdb) c/fg [ignore-count]</code></p>\n<p><code>c(continue)/fg</code>使程序继续往下运行，直到再次遇到断点或程序结束。ignore-count表示忽略其后n个断点。</p>\n</li>\n<li><p>退出GDB　　<code>(gdb) q</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gdb mimir</span><br><span class=\"line\">r --config=config</span><br><span class=\"line\">bt</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h3><ul>\n<li><p>进入GDB　　<code>gdb mimir</code></p>\n<p><code>mimir</code>是要调试的程序，由<code>gcc mimir.c -g -o mimir</code>生成。进入后提示符变为(gdb) 。</p>\n</li>\n<li><p>查看源码　　<code>(gdb) l</code></p>\n<p>如果需要查看在其他文件中定义的函数，在l后加上函数名即可定位到这个函数的定义及查看附近的其他源码。</p>\n</li>\n<li><p>运行代码　　<code>(gdb) r</code></p>\n</li>\n<li><p>设置断点　　<code>(gdb) b filename:function/linenum</code></p>\n<p>这样会在运行到该文件的function或者linenum时停止，可以查看变量的值、堆栈情况等。<strong>想看那个函数就直接下断点进去就好。</strong></p>\n</li>\n<li><p>查看断点处情况　　<code>(gdb) info b</code></p>\n<p>可以通过<code>info b</code>来查看断点处情况，可以设置多个断点。</p>\n</li>\n<li><p>查看函数堆栈     <code>(gdb) bt</code></p>\n<p><code>bt(backtrace)</code>命令是很有用的一个命令，当程序运行过程中崩了的时候可以使用该命令快速定位。</p>\n</li>\n<li><p>显示变量值　　<code>(gdb) p n</code></p>\n<p>在程序暂停时，键入<code>p(print) 变量名</code>即可。GDB在显示变量值时都会在对应值之前加上<code>$N</code>标记，它是当前变量值的引用标记，以后若想再次引用此变量，就可以直接写作<code>$N</code>，而无需写冗长的变量名。</p>\n</li>\n<li><p>观察变量　　<code>(gdb) watch n</code></p>\n<p>在某一循环处，往往希望能够观察一个变量的变化情况，这时就可以键入命令<code>watch</code>来观察变量的变化情况，GDB在n设置了观察点。</p>\n</li>\n<li><p>单步运行　　<code>(gdb) n/s [count]</code></p>\n<p><code>n(next)</code>和<code>s(step)</code>都表示单步跟踪，如果有函数调用s进入该函数n不进入。count表示执行其后的n条指令。</p>\n</li>\n<li><p>程序继续运行　　<code>(gdb) c/fg [ignore-count]</code></p>\n<p><code>c(continue)/fg</code>使程序继续往下运行，直到再次遇到断点或程序结束。ignore-count表示忽略其后n个断点。</p>\n</li>\n<li><p>退出GDB　　<code>(gdb) q</code></p>\n</li>\n</ul>"},{"title":"item2和zsh配置","author":"liuyan","catalog":true,"date":"2017-01-04T08:13:01.000Z","urlname":null,"_content":"\n## iTerm2安装与配置\n\n### 安装iTerm2\n\niTerm2官网：https://www.iterm2.com/\n\n### Solarized主题配置\n\niTerm2支持许多的主题配色，可以自己定义，也可以参考网上现成的主题配色。我个人比较喜欢Solarized配色，因为可以配合Vim里面的Solarized主题。\n\n<!-- more -->\n\n![](1.png)\n\n```shell\n# git下Solarized 的源码\ngit clone git://github.com/altercation/solarized.git\ncd solarized/vim-colors-solarized/colors\n\nsudo mkdir -p ~/.vim/colors\nsudo cp solarized.vim ~/.vim/colors/\n\n# 把下面这三行复制到~/.vimrc\nsyntax enable\nset background=dark\ncolorscheme solarized\n```\n\n要使ITerm2和vim的显示效果保持一致，还需要最后一步设置：**Preferences -> Profiles ->Text**中取消Draw bold text in bright color的勾选。\n\n### Powerline字体\n\n```sh\ngit clone https://github.com/powerline/fonts.git\ncd fonts\n./install.sh\t\t\t#安装所有Powerline字体\n```\n\n然后到 iterm2 配置，设置字体为`Roboto Mono for Powerline`\n\n![](2.png)\n\n## zsh安装与配置\n\n### 安装zsh\n\n```shell\ncat /etc/shells\t\t\t\t#查看系统内置的shell\nsudo brew install zsh\t\t#安装zsh\nchsh -s /bin/zsh\t\t\t#将zsh配置为默认的shell\nchsh -s /bin/bash\t\t\t#默认shell切换回bash\necho $SHELL\t\t\t\t\t#查看当前shell\n```\n\n### 安装oh-my-zsh\n\n```shell\ngit clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh\ncp ~/.zshrc ~/.zshrc.bk\ncp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc\n\ncd ~/.oh-my-zsh/tools\n./install.sh\n```\n\n### 主题配置\n\n通过修改`~/.zshrc`中的环境变量`ZSH_THEME`可以进行zsh主题配置\n\n查看主题：https://github.com/robbyrussell/oh-my-zsh/wiki/Themes\n\n```shell\nZSH_THEME=\"agnoster\"      \nZSH_THEME=\"random\" \t\t#主题随机变化\n```\n\n","source":"_posts/item2和zsh配置.md","raw":"---\ntitle:      item2和zsh配置\nauthor:     liuyan\ncatalog:    true\ntags:\n  - iTerm2\n  - zsh\n  - linux\ndate: 2017-01-04 16:13:01\nurlname:\ncategories: linux\n---\n\n## iTerm2安装与配置\n\n### 安装iTerm2\n\niTerm2官网：https://www.iterm2.com/\n\n### Solarized主题配置\n\niTerm2支持许多的主题配色，可以自己定义，也可以参考网上现成的主题配色。我个人比较喜欢Solarized配色，因为可以配合Vim里面的Solarized主题。\n\n<!-- more -->\n\n![](1.png)\n\n```shell\n# git下Solarized 的源码\ngit clone git://github.com/altercation/solarized.git\ncd solarized/vim-colors-solarized/colors\n\nsudo mkdir -p ~/.vim/colors\nsudo cp solarized.vim ~/.vim/colors/\n\n# 把下面这三行复制到~/.vimrc\nsyntax enable\nset background=dark\ncolorscheme solarized\n```\n\n要使ITerm2和vim的显示效果保持一致，还需要最后一步设置：**Preferences -> Profiles ->Text**中取消Draw bold text in bright color的勾选。\n\n### Powerline字体\n\n```sh\ngit clone https://github.com/powerline/fonts.git\ncd fonts\n./install.sh\t\t\t#安装所有Powerline字体\n```\n\n然后到 iterm2 配置，设置字体为`Roboto Mono for Powerline`\n\n![](2.png)\n\n## zsh安装与配置\n\n### 安装zsh\n\n```shell\ncat /etc/shells\t\t\t\t#查看系统内置的shell\nsudo brew install zsh\t\t#安装zsh\nchsh -s /bin/zsh\t\t\t#将zsh配置为默认的shell\nchsh -s /bin/bash\t\t\t#默认shell切换回bash\necho $SHELL\t\t\t\t\t#查看当前shell\n```\n\n### 安装oh-my-zsh\n\n```shell\ngit clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh\ncp ~/.zshrc ~/.zshrc.bk\ncp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc\n\ncd ~/.oh-my-zsh/tools\n./install.sh\n```\n\n### 主题配置\n\n通过修改`~/.zshrc`中的环境变量`ZSH_THEME`可以进行zsh主题配置\n\n查看主题：https://github.com/robbyrussell/oh-my-zsh/wiki/Themes\n\n```shell\nZSH_THEME=\"agnoster\"      \nZSH_THEME=\"random\" \t\t#主题随机变化\n```\n\n","slug":"item2和zsh配置","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hk0007ly0gqhqd78wp","content":"<h2 id=\"iTerm2安装与配置\"><a href=\"#iTerm2安装与配置\" class=\"headerlink\" title=\"iTerm2安装与配置\"></a>iTerm2安装与配置</h2><h3 id=\"安装iTerm2\"><a href=\"#安装iTerm2\" class=\"headerlink\" title=\"安装iTerm2\"></a>安装iTerm2</h3><p>iTerm2官网：<a href=\"https://www.iterm2.com/\" target=\"_blank\" rel=\"noopener\">https://www.iterm2.com/</a></p>\n<h3 id=\"Solarized主题配置\"><a href=\"#Solarized主题配置\" class=\"headerlink\" title=\"Solarized主题配置\"></a>Solarized主题配置</h3><p>iTerm2支持许多的主题配色，可以自己定义，也可以参考网上现成的主题配色。我个人比较喜欢Solarized配色，因为可以配合Vim里面的Solarized主题。</p>\n<a id=\"more\"></a>\n<p><img src=\"/2017/01/04/item2和zsh配置/1.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> git下Solarized 的源码</span><br><span class=\"line\">git clone git://github.com/altercation/solarized.git</span><br><span class=\"line\">cd solarized/vim-colors-solarized/colors</span><br><span class=\"line\"></span><br><span class=\"line\">sudo mkdir -p ~/.vim/colors</span><br><span class=\"line\">sudo cp solarized.vim ~/.vim/colors/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 把下面这三行复制到~/.vimrc</span><br><span class=\"line\">syntax enable</span><br><span class=\"line\">set background=dark</span><br><span class=\"line\">colorscheme solarized</span><br></pre></td></tr></table></figure>\n<p>要使ITerm2和vim的显示效果保持一致，还需要最后一步设置：<strong>Preferences -&gt; Profiles -&gt;Text</strong>中取消Draw bold text in bright color的勾选。</p>\n<h3 id=\"Powerline字体\"><a href=\"#Powerline字体\" class=\"headerlink\" title=\"Powerline字体\"></a>Powerline字体</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/powerline/fonts.git</span><br><span class=\"line\"><span class=\"built_in\">cd</span> fonts</span><br><span class=\"line\">./install.sh\t\t\t<span class=\"comment\">#安装所有Powerline字体</span></span><br></pre></td></tr></table></figure>\n<p>然后到 iterm2 配置，设置字体为<code>Roboto Mono for Powerline</code></p>\n<p><img src=\"/2017/01/04/item2和zsh配置/2.png\" alt=\"\"></p>\n<h2 id=\"zsh安装与配置\"><a href=\"#zsh安装与配置\" class=\"headerlink\" title=\"zsh安装与配置\"></a>zsh安装与配置</h2><h3 id=\"安装zsh\"><a href=\"#安装zsh\" class=\"headerlink\" title=\"安装zsh\"></a>安装zsh</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/shells\t\t\t\t#查看系统内置的shell</span><br><span class=\"line\">sudo brew install zsh\t\t#安装zsh</span><br><span class=\"line\">chsh -s /bin/zsh\t\t\t#将zsh配置为默认的shell</span><br><span class=\"line\">chsh -s /bin/bash\t\t\t#默认shell切换回bash</span><br><span class=\"line\">echo $SHELL\t\t\t\t\t#查看当前shell</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装oh-my-zsh\"><a href=\"#安装oh-my-zsh\" class=\"headerlink\" title=\"安装oh-my-zsh\"></a>安装oh-my-zsh</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh</span><br><span class=\"line\">cp ~/.zshrc ~/.zshrc.bk</span><br><span class=\"line\">cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc</span><br><span class=\"line\"></span><br><span class=\"line\">cd ~/.oh-my-zsh/tools</span><br><span class=\"line\">./install.sh</span><br></pre></td></tr></table></figure>\n<h3 id=\"主题配置\"><a href=\"#主题配置\" class=\"headerlink\" title=\"主题配置\"></a>主题配置</h3><p>通过修改<code>~/.zshrc</code>中的环境变量<code>ZSH_THEME</code>可以进行zsh主题配置</p>\n<p>查看主题：<a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/Themes\" target=\"_blank\" rel=\"noopener\">https://github.com/robbyrussell/oh-my-zsh/wiki/Themes</a></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ZSH_THEME=\"agnoster\"      </span><br><span class=\"line\">ZSH_THEME=\"random\" \t\t#主题随机变化</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<h2 id=\"iTerm2安装与配置\"><a href=\"#iTerm2安装与配置\" class=\"headerlink\" title=\"iTerm2安装与配置\"></a>iTerm2安装与配置</h2><h3 id=\"安装iTerm2\"><a href=\"#安装iTerm2\" class=\"headerlink\" title=\"安装iTerm2\"></a>安装iTerm2</h3><p>iTerm2官网：<a href=\"https://www.iterm2.com/\" target=\"_blank\" rel=\"noopener\">https://www.iterm2.com/</a></p>\n<h3 id=\"Solarized主题配置\"><a href=\"#Solarized主题配置\" class=\"headerlink\" title=\"Solarized主题配置\"></a>Solarized主题配置</h3><p>iTerm2支持许多的主题配色，可以自己定义，也可以参考网上现成的主题配色。我个人比较喜欢Solarized配色，因为可以配合Vim里面的Solarized主题。</p>","more":"<p><img src=\"/2017/01/04/item2和zsh配置/1.png\" alt=\"\"></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> git下Solarized 的源码</span><br><span class=\"line\">git clone git://github.com/altercation/solarized.git</span><br><span class=\"line\">cd solarized/vim-colors-solarized/colors</span><br><span class=\"line\"></span><br><span class=\"line\">sudo mkdir -p ~/.vim/colors</span><br><span class=\"line\">sudo cp solarized.vim ~/.vim/colors/</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 把下面这三行复制到~/.vimrc</span><br><span class=\"line\">syntax enable</span><br><span class=\"line\">set background=dark</span><br><span class=\"line\">colorscheme solarized</span><br></pre></td></tr></table></figure>\n<p>要使ITerm2和vim的显示效果保持一致，还需要最后一步设置：<strong>Preferences -&gt; Profiles -&gt;Text</strong>中取消Draw bold text in bright color的勾选。</p>\n<h3 id=\"Powerline字体\"><a href=\"#Powerline字体\" class=\"headerlink\" title=\"Powerline字体\"></a>Powerline字体</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/powerline/fonts.git</span><br><span class=\"line\"><span class=\"built_in\">cd</span> fonts</span><br><span class=\"line\">./install.sh\t\t\t<span class=\"comment\">#安装所有Powerline字体</span></span><br></pre></td></tr></table></figure>\n<p>然后到 iterm2 配置，设置字体为<code>Roboto Mono for Powerline</code></p>\n<p><img src=\"/2017/01/04/item2和zsh配置/2.png\" alt=\"\"></p>\n<h2 id=\"zsh安装与配置\"><a href=\"#zsh安装与配置\" class=\"headerlink\" title=\"zsh安装与配置\"></a>zsh安装与配置</h2><h3 id=\"安装zsh\"><a href=\"#安装zsh\" class=\"headerlink\" title=\"安装zsh\"></a>安装zsh</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/shells\t\t\t\t#查看系统内置的shell</span><br><span class=\"line\">sudo brew install zsh\t\t#安装zsh</span><br><span class=\"line\">chsh -s /bin/zsh\t\t\t#将zsh配置为默认的shell</span><br><span class=\"line\">chsh -s /bin/bash\t\t\t#默认shell切换回bash</span><br><span class=\"line\">echo $SHELL\t\t\t\t\t#查看当前shell</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装oh-my-zsh\"><a href=\"#安装oh-my-zsh\" class=\"headerlink\" title=\"安装oh-my-zsh\"></a>安装oh-my-zsh</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh</span><br><span class=\"line\">cp ~/.zshrc ~/.zshrc.bk</span><br><span class=\"line\">cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc</span><br><span class=\"line\"></span><br><span class=\"line\">cd ~/.oh-my-zsh/tools</span><br><span class=\"line\">./install.sh</span><br></pre></td></tr></table></figure>\n<h3 id=\"主题配置\"><a href=\"#主题配置\" class=\"headerlink\" title=\"主题配置\"></a>主题配置</h3><p>通过修改<code>~/.zshrc</code>中的环境变量<code>ZSH_THEME</code>可以进行zsh主题配置</p>\n<p>查看主题：<a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/Themes\" target=\"_blank\" rel=\"noopener\">https://github.com/robbyrussell/oh-my-zsh/wiki/Themes</a></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ZSH_THEME=\"agnoster\"      </span><br><span class=\"line\">ZSH_THEME=\"random\" \t\t#主题随机变化</span><br></pre></td></tr></table></figure>"},{"title":"git基础","author":"liuyan","catalog":true,"date":"2017-10-03T12:18:44.000Z","urlname":null,"_content":"\n###  综述\n下面这张图是git工作区域的一个简单介绍\n\n![](git.jgp)\n\n几个专用名词的译名如下。\n\n    Workspace：工作区\n    Index / Stage：暂存区\n    Repository：仓库区（或本地仓库）\n    Remote：远程仓库\n\n<!-- more -->\n\n### ~/.gitconfig文件\n\n```shell\n[user]\n    email = liuyan30@meituan.com\n    name = Liu Yan\n[alias]\n  br = branch\n  ci = commit\n  co = checkout\n  st = status\n  a = add\n  d = diff\n```\n\n### git常用命令\n\n```shell\ngit log --pretty=oneline                #查看版本号\ngit remote add origin git@***.git       #让本地仓库和远程仓库进行关联\ngit branch                              #查看本地分支\ngit branch -a                           #查看远程分支\ngit diff (--stat)                       #查看修改的部分\ngit chockout -b liuyan                  #新建本地分支liuyan并进入新分支\ngit add .                               #添加当前目录的所有文件到暂存区\ngit commit -a -m \"modify mimir options\" #commit代码到新分支\ngit fetch                               #fetch所有分支\ngit checkout -b xxx origin/xxx          #将远程分支拉到本地\ngit pull origin xxx                     #pull xxx分支\ngit checkout ann.cc                     #把ann.cc回退到上一次提交的版本\ngit checkout xxx                        #切换到xxx分支\ngit merge xxx                           #将xxx分支merge到当前分支\ngit branch -d xxx                       #删除本地xxx分支\ngit status                              #显示变更的文件\ngit push origin xxx                     #push代码到远程分支xxx，要是不存在会新建分支xxx\ngit push origin --delete xxx            #删除远程分支xxx\ngit branch -m xxx1 xxx2                 #重命名本地分支\n```\n\n### git常用命令速查表\n\n![](git常用命令速查表.jpg)\n","source":"_posts/git基础.md","raw":"---\ntitle:      git基础\nauthor:     liuyan\ncatalog:    true\ntags:\n  - git\n  - linux\ndate:       2017-10-03 20:18:44\nurlname:\ncategories: linux\n---\n\n###  综述\n下面这张图是git工作区域的一个简单介绍\n\n![](git.jgp)\n\n几个专用名词的译名如下。\n\n    Workspace：工作区\n    Index / Stage：暂存区\n    Repository：仓库区（或本地仓库）\n    Remote：远程仓库\n\n<!-- more -->\n\n### ~/.gitconfig文件\n\n```shell\n[user]\n    email = liuyan30@meituan.com\n    name = Liu Yan\n[alias]\n  br = branch\n  ci = commit\n  co = checkout\n  st = status\n  a = add\n  d = diff\n```\n\n### git常用命令\n\n```shell\ngit log --pretty=oneline                #查看版本号\ngit remote add origin git@***.git       #让本地仓库和远程仓库进行关联\ngit branch                              #查看本地分支\ngit branch -a                           #查看远程分支\ngit diff (--stat)                       #查看修改的部分\ngit chockout -b liuyan                  #新建本地分支liuyan并进入新分支\ngit add .                               #添加当前目录的所有文件到暂存区\ngit commit -a -m \"modify mimir options\" #commit代码到新分支\ngit fetch                               #fetch所有分支\ngit checkout -b xxx origin/xxx          #将远程分支拉到本地\ngit pull origin xxx                     #pull xxx分支\ngit checkout ann.cc                     #把ann.cc回退到上一次提交的版本\ngit checkout xxx                        #切换到xxx分支\ngit merge xxx                           #将xxx分支merge到当前分支\ngit branch -d xxx                       #删除本地xxx分支\ngit status                              #显示变更的文件\ngit push origin xxx                     #push代码到远程分支xxx，要是不存在会新建分支xxx\ngit push origin --delete xxx            #删除远程分支xxx\ngit branch -m xxx1 xxx2                 #重命名本地分支\n```\n\n### git常用命令速查表\n\n![](git常用命令速查表.jpg)\n","slug":"git基础","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hl000bly0gwnkbhl98","content":"<h3 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h3><p>下面这张图是git工作区域的一个简单介绍</p>\n<p><img src=\"/2017/10/03/git基础/git.jgp\" alt=\"\"></p>\n<p>几个专用名词的译名如下。</p>\n<pre><code>Workspace：工作区\nIndex / Stage：暂存区\nRepository：仓库区（或本地仓库）\nRemote：远程仓库\n</code></pre><a id=\"more\"></a>\n<h3 id=\"gitconfig文件\"><a href=\"#gitconfig文件\" class=\"headerlink\" title=\"~/.gitconfig文件\"></a>~/.gitconfig文件</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[user]</span><br><span class=\"line\">    email = liuyan30@meituan.com</span><br><span class=\"line\">    name = Liu Yan</span><br><span class=\"line\">[alias]</span><br><span class=\"line\">  br = branch</span><br><span class=\"line\">  ci = commit</span><br><span class=\"line\">  co = checkout</span><br><span class=\"line\">  st = status</span><br><span class=\"line\">  a = add</span><br><span class=\"line\">  d = diff</span><br></pre></td></tr></table></figure>\n<h3 id=\"git常用命令\"><a href=\"#git常用命令\" class=\"headerlink\" title=\"git常用命令\"></a>git常用命令</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git log --pretty=oneline                #查看版本号</span><br><span class=\"line\">git remote add origin git@***.git       #让本地仓库和远程仓库进行关联</span><br><span class=\"line\">git branch                              #查看本地分支</span><br><span class=\"line\">git branch -a                           #查看远程分支</span><br><span class=\"line\">git diff (--stat)                       #查看修改的部分</span><br><span class=\"line\">git chockout -b liuyan                  #新建本地分支liuyan并进入新分支</span><br><span class=\"line\">git add .                               #添加当前目录的所有文件到暂存区</span><br><span class=\"line\">git commit -a -m \"modify mimir options\" #commit代码到新分支</span><br><span class=\"line\">git fetch                               #fetch所有分支</span><br><span class=\"line\">git checkout -b xxx origin/xxx          #将远程分支拉到本地</span><br><span class=\"line\">git pull origin xxx                     #pull xxx分支</span><br><span class=\"line\">git checkout ann.cc                     #把ann.cc回退到上一次提交的版本</span><br><span class=\"line\">git checkout xxx                        #切换到xxx分支</span><br><span class=\"line\">git merge xxx                           #将xxx分支merge到当前分支</span><br><span class=\"line\">git branch -d xxx                       #删除本地xxx分支</span><br><span class=\"line\">git status                              #显示变更的文件</span><br><span class=\"line\">git push origin xxx                     #push代码到远程分支xxx，要是不存在会新建分支xxx</span><br><span class=\"line\">git push origin --delete xxx            #删除远程分支xxx</span><br><span class=\"line\">git branch -m xxx1 xxx2                 #重命名本地分支</span><br></pre></td></tr></table></figure>\n<h3 id=\"git常用命令速查表\"><a href=\"#git常用命令速查表\" class=\"headerlink\" title=\"git常用命令速查表\"></a>git常用命令速查表</h3><p><img src=\"/2017/10/03/git基础/git常用命令速查表.jpg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h3><p>下面这张图是git工作区域的一个简单介绍</p>\n<p><img src=\"/2017/10/03/git基础/git.jgp\" alt=\"\"></p>\n<p>几个专用名词的译名如下。</p>\n<pre><code>Workspace：工作区\nIndex / Stage：暂存区\nRepository：仓库区（或本地仓库）\nRemote：远程仓库\n</code></pre>","more":"<h3 id=\"gitconfig文件\"><a href=\"#gitconfig文件\" class=\"headerlink\" title=\"~/.gitconfig文件\"></a>~/.gitconfig文件</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[user]</span><br><span class=\"line\">    email = liuyan30@meituan.com</span><br><span class=\"line\">    name = Liu Yan</span><br><span class=\"line\">[alias]</span><br><span class=\"line\">  br = branch</span><br><span class=\"line\">  ci = commit</span><br><span class=\"line\">  co = checkout</span><br><span class=\"line\">  st = status</span><br><span class=\"line\">  a = add</span><br><span class=\"line\">  d = diff</span><br></pre></td></tr></table></figure>\n<h3 id=\"git常用命令\"><a href=\"#git常用命令\" class=\"headerlink\" title=\"git常用命令\"></a>git常用命令</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git log --pretty=oneline                #查看版本号</span><br><span class=\"line\">git remote add origin git@***.git       #让本地仓库和远程仓库进行关联</span><br><span class=\"line\">git branch                              #查看本地分支</span><br><span class=\"line\">git branch -a                           #查看远程分支</span><br><span class=\"line\">git diff (--stat)                       #查看修改的部分</span><br><span class=\"line\">git chockout -b liuyan                  #新建本地分支liuyan并进入新分支</span><br><span class=\"line\">git add .                               #添加当前目录的所有文件到暂存区</span><br><span class=\"line\">git commit -a -m \"modify mimir options\" #commit代码到新分支</span><br><span class=\"line\">git fetch                               #fetch所有分支</span><br><span class=\"line\">git checkout -b xxx origin/xxx          #将远程分支拉到本地</span><br><span class=\"line\">git pull origin xxx                     #pull xxx分支</span><br><span class=\"line\">git checkout ann.cc                     #把ann.cc回退到上一次提交的版本</span><br><span class=\"line\">git checkout xxx                        #切换到xxx分支</span><br><span class=\"line\">git merge xxx                           #将xxx分支merge到当前分支</span><br><span class=\"line\">git branch -d xxx                       #删除本地xxx分支</span><br><span class=\"line\">git status                              #显示变更的文件</span><br><span class=\"line\">git push origin xxx                     #push代码到远程分支xxx，要是不存在会新建分支xxx</span><br><span class=\"line\">git push origin --delete xxx            #删除远程分支xxx</span><br><span class=\"line\">git branch -m xxx1 xxx2                 #重命名本地分支</span><br></pre></td></tr></table></figure>\n<h3 id=\"git常用命令速查表\"><a href=\"#git常用命令速查表\" class=\"headerlink\" title=\"git常用命令速查表\"></a>git常用命令速查表</h3><p><img src=\"/2017/10/03/git基础/git常用命令速查表.jpg\" alt=\"\"></p>"},{"title":"kaldi sge集群和nfs网络文件系统","author":"liuyan","catalog":true,"date":"2018-09-09T08:42:26.000Z","urlname":null,"_content":"\n### sge安装\n\n#### qmaster sge安装\n```shell\ninstall_rpm.sh                    #qmaster节点上运行\ninstall_qmaster.sh <admin-user>   #qmaster节点上运行\n```\n\n#### 使用nfs将qmaster上的sge部署到exec节点\n\n- 在qmaster和exec节点安装nfs。需要保证各机器上的nfs版本一致。\n```shell\nsudo yum -y install nfs-utils   #安装\nsudo yum -y upgrade nfs-utils   #更新\nrpm -qa | grep nfs-utils        #查看版本\n```\n\n<!-- more -->\n\n- qmaster节点配置nfs。在qmaster节点的/etc/exports中添加 `/opt/sge 10.40.0.0/16(rw,root_squash)`，其中10.40是exec节点的ip前缀。修改 `/etc/sysconfig/nfs`中的参数RPCNFSDCOUNT=64，将线程数设为64. 在文件`/proc/net/rpc/nfsd`中可以查看线程数。这样qmaster节点上的/opt/sge文件可以共享给所有ip以10.40开头的exec。\n```shell\nsudo systemctl start rpcbind.service\nsudo systemctl start nfs.service        #启动服务\nsudo exportfs -ra                       #使配置生效\nsudo systemctl status nfs.service       #查看status\n```\n\n- exec节点挂载nfs。nfs日志文件放在 `/var/log/message` 和 `/var/log/cron`中，出现故障的时候可查看日志。\n```shell\nsudo mount -t nfs -o rw,vers=3,acdirmin=5,acdirmax=8,hard,proto=tcp xx.xx.xx.xx:/opt/nfs/train1 /opt/nfs/train1\t\t#在exec挂载qmaster的目录，挂载之前exec和qmaster目录都需要存在。xx.xx.xx.xx是qmaster的ip\nnfsstat -m          #查看nfs版本\numount -f           #卸载exec上的nfs，可添加-l强制卸载\n```\n\n- 错误解决。qmaster节点上启动服务`sudo systemctl start rpcbind.service`时出现问题`A dependency job for rpcbind.service failed. See 'journalctl -xe' for details.`主要是因为ipv6被禁用了，打开`/etc/systemd/system/sockets.target.wants/rpcbind.socket`，注释掉`ListenStream=[::]:111`即可。\n\n#### 启动sge服务\n- 在所有qmaster和exec节点执行下面的操作：\n```shell\nqconf -ah $node_name\nqconf -as $node_name\n```\n\n- on exec node run:\n```shell\ninstall_deps.sh\ninstall_rpm.sh\ninstall_execd.sh\n```\n\n- start on boot\n```shell\nsystemctl enable sgemaster.p6444            #启动qmaster上的sge\n#sudo /etc/init.d/sgeexecd.p6444 start  \nsystemctl enable sgeexecd.p6444\n#sudo /etc/init.d/sgemaster.p6444 start \nsystemctl status sgeexecd.p6444             #查看sge状态\n```\n\n#### keeping grid stable\n保证集群中内存不会崩，当内存接近使用完的时候自动杀死当前占用内存最多的非系统应用。\n```shell\nsudo bash\nyum install -y subversion\nsvn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/sbin/mem-killer.pl > /sbin/mem-killer.pl\nchmod +x /sbin/mem-killer.pl\ncd /etc/init.d/ \nsvn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/etc/init.d/mem-killer >mem-killer\nchmod +x mem-killer \nchkconfig --add mem-killer\nsystemctl start mem-killer\nsystemctl status mem-killer\n```\n\n#### 配置\nqconf -me dx-ai-speechoffline-training1\n```shell\ncomplex_values        ram_free=188G,gpu=2   #没有gpu不写gpu，配置共享内存\n```\n\ncephfs挂载\n```shell\nsudo fusermount -uz /opt/meituan/cephfs \nsudo ceph-fuse -c /etc/ceph/ceph.conf -n client.ceph-speech --client_mountpoint /ceph-speech /opt/meituan/cephfs\n```\n\n### sge使用\n```shell\nqhost -q        #查看sge节点信息\nqstat -u user   #按用户查看    \nqstat -u \"*\"    #查看所有任务\nqstat -f        #查看所有任务 \nqstat -j jobid  #按任务id查看 \nqdel jobID      #删除某个任务\nqdel -u user    #删除某个用户的所有任务\n\n任务状态\nqw      #表示等待状态 \neqw     #投递任务出错 \nr       #表示任务正在运行 \ndr      #节点挂了之后，删除任务就会出现这个状态，只有节点重启之后，任务才会消失\n```\n\ndf -h\t查看nfs是否配置成功\nworking on centos 6/7\n以上所有安装脚本以及相应的资源文件无法提供\n\n参考：\n[Parallelization in Kaldi](http://kaldi-asr.org/doc/queue.html)\n","source":"_posts/kaldi-sge集群-nfs网络文件系统.md","raw":"---\ntitle:      kaldi sge集群和nfs网络文件系统\nauthor:     liuyan\ncatalog:    true\ntags:\n  - kaldi\n  - 语音识别\n  - sge\n  - nfs\ndate:       2018-09-09 16:42:26\nurlname:\ncategories: 语音识别\n---\n\n### sge安装\n\n#### qmaster sge安装\n```shell\ninstall_rpm.sh                    #qmaster节点上运行\ninstall_qmaster.sh <admin-user>   #qmaster节点上运行\n```\n\n#### 使用nfs将qmaster上的sge部署到exec节点\n\n- 在qmaster和exec节点安装nfs。需要保证各机器上的nfs版本一致。\n```shell\nsudo yum -y install nfs-utils   #安装\nsudo yum -y upgrade nfs-utils   #更新\nrpm -qa | grep nfs-utils        #查看版本\n```\n\n<!-- more -->\n\n- qmaster节点配置nfs。在qmaster节点的/etc/exports中添加 `/opt/sge 10.40.0.0/16(rw,root_squash)`，其中10.40是exec节点的ip前缀。修改 `/etc/sysconfig/nfs`中的参数RPCNFSDCOUNT=64，将线程数设为64. 在文件`/proc/net/rpc/nfsd`中可以查看线程数。这样qmaster节点上的/opt/sge文件可以共享给所有ip以10.40开头的exec。\n```shell\nsudo systemctl start rpcbind.service\nsudo systemctl start nfs.service        #启动服务\nsudo exportfs -ra                       #使配置生效\nsudo systemctl status nfs.service       #查看status\n```\n\n- exec节点挂载nfs。nfs日志文件放在 `/var/log/message` 和 `/var/log/cron`中，出现故障的时候可查看日志。\n```shell\nsudo mount -t nfs -o rw,vers=3,acdirmin=5,acdirmax=8,hard,proto=tcp xx.xx.xx.xx:/opt/nfs/train1 /opt/nfs/train1\t\t#在exec挂载qmaster的目录，挂载之前exec和qmaster目录都需要存在。xx.xx.xx.xx是qmaster的ip\nnfsstat -m          #查看nfs版本\numount -f           #卸载exec上的nfs，可添加-l强制卸载\n```\n\n- 错误解决。qmaster节点上启动服务`sudo systemctl start rpcbind.service`时出现问题`A dependency job for rpcbind.service failed. See 'journalctl -xe' for details.`主要是因为ipv6被禁用了，打开`/etc/systemd/system/sockets.target.wants/rpcbind.socket`，注释掉`ListenStream=[::]:111`即可。\n\n#### 启动sge服务\n- 在所有qmaster和exec节点执行下面的操作：\n```shell\nqconf -ah $node_name\nqconf -as $node_name\n```\n\n- on exec node run:\n```shell\ninstall_deps.sh\ninstall_rpm.sh\ninstall_execd.sh\n```\n\n- start on boot\n```shell\nsystemctl enable sgemaster.p6444            #启动qmaster上的sge\n#sudo /etc/init.d/sgeexecd.p6444 start  \nsystemctl enable sgeexecd.p6444\n#sudo /etc/init.d/sgemaster.p6444 start \nsystemctl status sgeexecd.p6444             #查看sge状态\n```\n\n#### keeping grid stable\n保证集群中内存不会崩，当内存接近使用完的时候自动杀死当前占用内存最多的非系统应用。\n```shell\nsudo bash\nyum install -y subversion\nsvn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/sbin/mem-killer.pl > /sbin/mem-killer.pl\nchmod +x /sbin/mem-killer.pl\ncd /etc/init.d/ \nsvn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/etc/init.d/mem-killer >mem-killer\nchmod +x mem-killer \nchkconfig --add mem-killer\nsystemctl start mem-killer\nsystemctl status mem-killer\n```\n\n#### 配置\nqconf -me dx-ai-speechoffline-training1\n```shell\ncomplex_values        ram_free=188G,gpu=2   #没有gpu不写gpu，配置共享内存\n```\n\ncephfs挂载\n```shell\nsudo fusermount -uz /opt/meituan/cephfs \nsudo ceph-fuse -c /etc/ceph/ceph.conf -n client.ceph-speech --client_mountpoint /ceph-speech /opt/meituan/cephfs\n```\n\n### sge使用\n```shell\nqhost -q        #查看sge节点信息\nqstat -u user   #按用户查看    \nqstat -u \"*\"    #查看所有任务\nqstat -f        #查看所有任务 \nqstat -j jobid  #按任务id查看 \nqdel jobID      #删除某个任务\nqdel -u user    #删除某个用户的所有任务\n\n任务状态\nqw      #表示等待状态 \neqw     #投递任务出错 \nr       #表示任务正在运行 \ndr      #节点挂了之后，删除任务就会出现这个状态，只有节点重启之后，任务才会消失\n```\n\ndf -h\t查看nfs是否配置成功\nworking on centos 6/7\n以上所有安装脚本以及相应的资源文件无法提供\n\n参考：\n[Parallelization in Kaldi](http://kaldi-asr.org/doc/queue.html)\n","slug":"kaldi-sge集群-nfs网络文件系统","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hn000cly0gkggl4iyj","content":"<h3 id=\"sge安装\"><a href=\"#sge安装\" class=\"headerlink\" title=\"sge安装\"></a>sge安装</h3><h4 id=\"qmaster-sge安装\"><a href=\"#qmaster-sge安装\" class=\"headerlink\" title=\"qmaster sge安装\"></a>qmaster sge安装</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">install_rpm.sh                    #qmaster节点上运行</span><br><span class=\"line\">install_qmaster.sh &lt;admin-user&gt;   #qmaster节点上运行</span><br></pre></td></tr></table></figure>\n<h4 id=\"使用nfs将qmaster上的sge部署到exec节点\"><a href=\"#使用nfs将qmaster上的sge部署到exec节点\" class=\"headerlink\" title=\"使用nfs将qmaster上的sge部署到exec节点\"></a>使用nfs将qmaster上的sge部署到exec节点</h4><ul>\n<li>在qmaster和exec节点安装nfs。需要保证各机器上的nfs版本一致。<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum -y install nfs-utils   #安装</span><br><span class=\"line\">sudo yum -y upgrade nfs-utils   #更新</span><br><span class=\"line\">rpm -qa | grep nfs-utils        #查看版本</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li><p>qmaster节点配置nfs。在qmaster节点的/etc/exports中添加 <code>/opt/sge 10.40.0.0/16(rw,root_squash)</code>，其中10.40是exec节点的ip前缀。修改 <code>/etc/sysconfig/nfs</code>中的参数RPCNFSDCOUNT=64，将线程数设为64. 在文件<code>/proc/net/rpc/nfsd</code>中可以查看线程数。这样qmaster节点上的/opt/sge文件可以共享给所有ip以10.40开头的exec。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl start rpcbind.service</span><br><span class=\"line\">sudo systemctl start nfs.service        #启动服务</span><br><span class=\"line\">sudo exportfs -ra                       #使配置生效</span><br><span class=\"line\">sudo systemctl status nfs.service       #查看status</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>exec节点挂载nfs。nfs日志文件放在 <code>/var/log/message</code> 和 <code>/var/log/cron</code>中，出现故障的时候可查看日志。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mount -t nfs -o rw,vers=3,acdirmin=5,acdirmax=8,hard,proto=tcp xx.xx.xx.xx:/opt/nfs/train1 /opt/nfs/train1\t\t#在exec挂载qmaster的目录，挂载之前exec和qmaster目录都需要存在。xx.xx.xx.xx是qmaster的ip</span><br><span class=\"line\">nfsstat -m          #查看nfs版本</span><br><span class=\"line\">umount -f           #卸载exec上的nfs，可添加-l强制卸载</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>错误解决。qmaster节点上启动服务<code>sudo systemctl start rpcbind.service</code>时出现问题<code>A dependency job for rpcbind.service failed. See &#39;journalctl -xe&#39; for details.</code>主要是因为ipv6被禁用了，打开<code>/etc/systemd/system/sockets.target.wants/rpcbind.socket</code>，注释掉<code>ListenStream=[::]:111</code>即可。</p>\n</li>\n</ul>\n<h4 id=\"启动sge服务\"><a href=\"#启动sge服务\" class=\"headerlink\" title=\"启动sge服务\"></a>启动sge服务</h4><ul>\n<li><p>在所有qmaster和exec节点执行下面的操作：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">qconf -ah $node_name</span><br><span class=\"line\">qconf -as $node_name</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>on exec node run:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">install_deps.sh</span><br><span class=\"line\">install_rpm.sh</span><br><span class=\"line\">install_execd.sh</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>start on boot</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable sgemaster.p6444            #启动qmaster上的sge</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">sudo /etc/init.d/sgeexecd.p6444 start  </span></span><br><span class=\"line\">systemctl enable sgeexecd.p6444</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">sudo /etc/init.d/sgemaster.p6444 start </span></span><br><span class=\"line\">systemctl status sgeexecd.p6444             #查看sge状态</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"keeping-grid-stable\"><a href=\"#keeping-grid-stable\" class=\"headerlink\" title=\"keeping grid stable\"></a>keeping grid stable</h4><p>保证集群中内存不会崩，当内存接近使用完的时候自动杀死当前占用内存最多的非系统应用。<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo bash</span><br><span class=\"line\">yum install -y subversion</span><br><span class=\"line\">svn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/sbin/mem-killer.pl &gt; /sbin/mem-killer.pl</span><br><span class=\"line\">chmod +x /sbin/mem-killer.pl</span><br><span class=\"line\">cd /etc/init.d/ </span><br><span class=\"line\">svn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/etc/init.d/mem-killer &gt;mem-killer</span><br><span class=\"line\">chmod +x mem-killer </span><br><span class=\"line\">chkconfig --add mem-killer</span><br><span class=\"line\">systemctl start mem-killer</span><br><span class=\"line\">systemctl status mem-killer</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h4><p>qconf -me dx-ai-speechoffline-training1<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">complex_values        ram_free=188G,gpu=2   #没有gpu不写gpu，配置共享内存</span><br></pre></td></tr></table></figure></p>\n<p>cephfs挂载<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo fusermount -uz /opt/meituan/cephfs </span><br><span class=\"line\">sudo ceph-fuse -c /etc/ceph/ceph.conf -n client.ceph-speech --client_mountpoint /ceph-speech /opt/meituan/cephfs</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"sge使用\"><a href=\"#sge使用\" class=\"headerlink\" title=\"sge使用\"></a>sge使用</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">qhost -q        #查看sge节点信息</span><br><span class=\"line\">qstat -u user   #按用户查看    </span><br><span class=\"line\">qstat -u \"*\"    #查看所有任务</span><br><span class=\"line\">qstat -f        #查看所有任务 </span><br><span class=\"line\">qstat -j jobid  #按任务id查看 </span><br><span class=\"line\">qdel jobID      #删除某个任务</span><br><span class=\"line\">qdel -u user    #删除某个用户的所有任务</span><br><span class=\"line\"></span><br><span class=\"line\">任务状态</span><br><span class=\"line\">qw      #表示等待状态 </span><br><span class=\"line\">eqw     #投递任务出错 </span><br><span class=\"line\">r       #表示任务正在运行 </span><br><span class=\"line\">dr      #节点挂了之后，删除任务就会出现这个状态，只有节点重启之后，任务才会消失</span><br></pre></td></tr></table></figure>\n<p>df -h    查看nfs是否配置成功<br>working on centos 6/7<br>以上所有安装脚本以及相应的资源文件无法提供</p>\n<p>参考：<br><a href=\"http://kaldi-asr.org/doc/queue.html\" target=\"_blank\" rel=\"noopener\">Parallelization in Kaldi</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"sge安装\"><a href=\"#sge安装\" class=\"headerlink\" title=\"sge安装\"></a>sge安装</h3><h4 id=\"qmaster-sge安装\"><a href=\"#qmaster-sge安装\" class=\"headerlink\" title=\"qmaster sge安装\"></a>qmaster sge安装</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">install_rpm.sh                    #qmaster节点上运行</span><br><span class=\"line\">install_qmaster.sh &lt;admin-user&gt;   #qmaster节点上运行</span><br></pre></td></tr></table></figure>\n<h4 id=\"使用nfs将qmaster上的sge部署到exec节点\"><a href=\"#使用nfs将qmaster上的sge部署到exec节点\" class=\"headerlink\" title=\"使用nfs将qmaster上的sge部署到exec节点\"></a>使用nfs将qmaster上的sge部署到exec节点</h4><ul>\n<li>在qmaster和exec节点安装nfs。需要保证各机器上的nfs版本一致。<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum -y install nfs-utils   #安装</span><br><span class=\"line\">sudo yum -y upgrade nfs-utils   #更新</span><br><span class=\"line\">rpm -qa | grep nfs-utils        #查看版本</span><br></pre></td></tr></table></figure>\n</li>\n</ul>","more":"<ul>\n<li><p>qmaster节点配置nfs。在qmaster节点的/etc/exports中添加 <code>/opt/sge 10.40.0.0/16(rw,root_squash)</code>，其中10.40是exec节点的ip前缀。修改 <code>/etc/sysconfig/nfs</code>中的参数RPCNFSDCOUNT=64，将线程数设为64. 在文件<code>/proc/net/rpc/nfsd</code>中可以查看线程数。这样qmaster节点上的/opt/sge文件可以共享给所有ip以10.40开头的exec。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl start rpcbind.service</span><br><span class=\"line\">sudo systemctl start nfs.service        #启动服务</span><br><span class=\"line\">sudo exportfs -ra                       #使配置生效</span><br><span class=\"line\">sudo systemctl status nfs.service       #查看status</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>exec节点挂载nfs。nfs日志文件放在 <code>/var/log/message</code> 和 <code>/var/log/cron</code>中，出现故障的时候可查看日志。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mount -t nfs -o rw,vers=3,acdirmin=5,acdirmax=8,hard,proto=tcp xx.xx.xx.xx:/opt/nfs/train1 /opt/nfs/train1\t\t#在exec挂载qmaster的目录，挂载之前exec和qmaster目录都需要存在。xx.xx.xx.xx是qmaster的ip</span><br><span class=\"line\">nfsstat -m          #查看nfs版本</span><br><span class=\"line\">umount -f           #卸载exec上的nfs，可添加-l强制卸载</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>错误解决。qmaster节点上启动服务<code>sudo systemctl start rpcbind.service</code>时出现问题<code>A dependency job for rpcbind.service failed. See &#39;journalctl -xe&#39; for details.</code>主要是因为ipv6被禁用了，打开<code>/etc/systemd/system/sockets.target.wants/rpcbind.socket</code>，注释掉<code>ListenStream=[::]:111</code>即可。</p>\n</li>\n</ul>\n<h4 id=\"启动sge服务\"><a href=\"#启动sge服务\" class=\"headerlink\" title=\"启动sge服务\"></a>启动sge服务</h4><ul>\n<li><p>在所有qmaster和exec节点执行下面的操作：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">qconf -ah $node_name</span><br><span class=\"line\">qconf -as $node_name</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>on exec node run:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">install_deps.sh</span><br><span class=\"line\">install_rpm.sh</span><br><span class=\"line\">install_execd.sh</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>start on boot</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable sgemaster.p6444            #启动qmaster上的sge</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">sudo /etc/init.d/sgeexecd.p6444 start  </span></span><br><span class=\"line\">systemctl enable sgeexecd.p6444</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">sudo /etc/init.d/sgemaster.p6444 start </span></span><br><span class=\"line\">systemctl status sgeexecd.p6444             #查看sge状态</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"keeping-grid-stable\"><a href=\"#keeping-grid-stable\" class=\"headerlink\" title=\"keeping grid stable\"></a>keeping grid stable</h4><p>保证集群中内存不会崩，当内存接近使用完的时候自动杀死当前占用内存最多的非系统应用。<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo bash</span><br><span class=\"line\">yum install -y subversion</span><br><span class=\"line\">svn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/sbin/mem-killer.pl &gt; /sbin/mem-killer.pl</span><br><span class=\"line\">chmod +x /sbin/mem-killer.pl</span><br><span class=\"line\">cd /etc/init.d/ </span><br><span class=\"line\">svn cat https://svn.code.sf.net/p/kluster/code/trunk/scripts/etc/init.d/mem-killer &gt;mem-killer</span><br><span class=\"line\">chmod +x mem-killer </span><br><span class=\"line\">chkconfig --add mem-killer</span><br><span class=\"line\">systemctl start mem-killer</span><br><span class=\"line\">systemctl status mem-killer</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h4><p>qconf -me dx-ai-speechoffline-training1<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">complex_values        ram_free=188G,gpu=2   #没有gpu不写gpu，配置共享内存</span><br></pre></td></tr></table></figure></p>\n<p>cephfs挂载<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo fusermount -uz /opt/meituan/cephfs </span><br><span class=\"line\">sudo ceph-fuse -c /etc/ceph/ceph.conf -n client.ceph-speech --client_mountpoint /ceph-speech /opt/meituan/cephfs</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"sge使用\"><a href=\"#sge使用\" class=\"headerlink\" title=\"sge使用\"></a>sge使用</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">qhost -q        #查看sge节点信息</span><br><span class=\"line\">qstat -u user   #按用户查看    </span><br><span class=\"line\">qstat -u \"*\"    #查看所有任务</span><br><span class=\"line\">qstat -f        #查看所有任务 </span><br><span class=\"line\">qstat -j jobid  #按任务id查看 </span><br><span class=\"line\">qdel jobID      #删除某个任务</span><br><span class=\"line\">qdel -u user    #删除某个用户的所有任务</span><br><span class=\"line\"></span><br><span class=\"line\">任务状态</span><br><span class=\"line\">qw      #表示等待状态 </span><br><span class=\"line\">eqw     #投递任务出错 </span><br><span class=\"line\">r       #表示任务正在运行 </span><br><span class=\"line\">dr      #节点挂了之后，删除任务就会出现这个状态，只有节点重启之后，任务才会消失</span><br></pre></td></tr></table></figure>\n<p>df -h    查看nfs是否配置成功<br>working on centos 6/7<br>以上所有安装脚本以及相应的资源文件无法提供</p>\n<p>参考：<br><a href=\"http://kaldi-asr.org/doc/queue.html\" target=\"_blank\" rel=\"noopener\">Parallelization in Kaldi</a></p>"},{"title":"kaldi chain model","author":"liuyan","catalog":true,"date":"2018-05-08T12:00:29.000Z","urlname":null,"_content":"\n### 声学模型网络\n\n声学模型就是用来估计不同音素对某一帧语音的条件概率，最终找出哪一种音素序列最有可能呈现出系统接收到的波形。\n\n#### DNN\n\nDNN 是一个典型的前馈网络，语音特征在进入输入层之后，逐层传播，最终在输出层得出每个音素的概率。值得注意的是，DNN在输入层除了当前帧之外，还会额外接收相邻的帧，这使得 DNN 一方面能够捕捉更广阔的时域信息，同时能够学习到相邻帧之间的变化特点。在实际应用中，DNN 往往会接受连续 10~20 帧作为输入。\n\n<!-- more -->\n\n![](1.png)\n\n#### TDNN\n\nTDNN与普通 DNN 类似，也是前馈网络，语音特征在网络内也是逐层向前传播，不同之处在于 TDNN 对隐层也做了上下文扩展。普通 DNN 每个隐层仅仅接收到前一个隐层的当前输出，而TDNN会将隐层的当前输出与其前后若干时刻的输出拼在一起，作为下一个隐层的输入。\n\n![](2.png)\n\n#### RNN\n\n与 RNN 对比来看，DNN 和 TDNN 的每个隐层都只会接收前一个隐层的输出，而由于语音特征在网络中传播时存在回路，RNN 中的隐层除了接收前一个隐层的输出外，还会将自己前一时刻的输出重新输入给自己。这样的结构使得 RNN 在理论上可以学习到无限长度的历史信息，但是在训练过程中，也会面临着复杂度较高以及梯度消失的问题。\n\n![](3.png)\n\n因为 RNN 模型有递归层的存在，导致很难像传统 DNN 那样进行并行化训练，同时与前馈神经网络相比 ，RNN 训练的复杂度要高很多，随之而来的问题就是模型训练时间过长。\n\n而 TDNN 的优点在于不仅能够对长时间依赖性的语音信号进行建模，同时与传统DNN的训练和解码效率几乎相当。\n\n### Chain Model\n\n#### TF-MMI\n\n在语音识别领域，区分性训练（Discriminative Training）能够显著提升语音识别系统的性能。区分性训练需要所有的单词序列组合来做训练，一般而言我们会先利用交叉熵准则训练一个基准模型，配合使用一个相对较弱的语言模型生成相应的词图（Lattice）。Lattice里面除了包含与正确识别结果相对应的路径外，还包含了与正确路径足够接近的其他路径，区分性训练就是要提高模型走正确路径的概率，同时压低走相似路径的概率。\n\n近年来CTC（Connectionist Temporal Classification）在语音识别领域受到很大关注，但CTC相比传统模型的优势，需要在很大的数据集上才能体现出来，而且CTC的训练速度很慢，参数调节更困难。与区分性训练中常用的MMI（Maximum Mutual Information）准则类似，CTC训练准则的目标是最大化正确标注的条件概率，而MMI着重优化正确路径和其他相似路径的概率差。\n\nLF-MMI（Lattice-Free Maximum Mutual Information）训练准则通过在神经网络输出层计算出来所有可能的标注序列，根据这些标注序列计算出相应的MMI信息和相关的梯度，然后通过梯度传播算法完成训练。\n\nLF-MMI训练准则能够在训练过程中直接计算所有可能路径的后验概率（Posterior Probability），省去了区分性训练前需要提前生成Lattice的麻烦，所以这种方法被叫做Lattice-Free MMI。\n\n**Chain Model在LF-MMI训练方法的基础上，还能够使用三分之一甚至更低的帧率、更简单的HMM拓扑结构来降低解码时间。**\n\n所谓的Chain Model就是结合了低帧率输出、优化过后的HMM拓扑结构和LF-MMI训练方法的语音识别系统。从实际效果来看，相对于主流的交叉熵模型系统，Chain Model搭配时延深度神经网络（TDNN），在语音识别系统的准确率（CER，字错误率）和解码速度上都获得了显著的提高。\n\n![](4.png)\n\n#### topo\n\ntdnn的输出帧速率是常规帧速率的1/3。这样做是因为从tdnn的网络结构来看相邻节点之间的变化较少，而且包含了大量重复信息，因此可以每隔几帧才计算一帧的结果，从而加速训练和解码过程。通过选择合适的时间步长，可以在大幅减少运算量的同时，没有漏掉任何历史信息，从而在识别准确性和运算量之间取得平衡。\n\ntdnn的输入特征是每秒100帧（每10毫秒一帧）的原始帧速率，输出的帧速率降低之后是每30毫秒一帧，所以需要修改hmm拓扑结构。传统的hmm拓扑是一种从左到右的3-state结构，可以至少在三帧内穿越。tdnn使用的拓扑结构可以在一帧内穿越，具有只能出现一次的状态，然后有可能出现零次或多次的另一种状态。所以单个HMM可以发出a或ab或abb等不同的状态，其中b可以理解为ctc中的blank。\n\n使用新的拓扑结构和基于GMM模型相同的过程来获得状态聚类。\n\n#### Training on frame-shifted data\n\n我们在之前已经有产生扰动数据的方法来人为地增加我们训练的数据量，在chain model中我们还可以额外的通过帧移位的方式来增加数据。\n\ntdnn的输出帧速率是常规帧速率的三分之一（可配置），这意味着我们只在t值为3的倍数时评估网络的输出，因此我们可以通过对训练数据进行帧移动来生成不同版本的训练数据，例如移动0,1和2帧。这是在训练脚本中自动完成的，当我们从磁盘读取训练示例时，nnet3-chain-copy-egs具有由脚本设置的-frame-shift选项。这其实影响的是epoch的数量，例如用户请求4个epoch，那么实际上训练12个epoch，我们只是在3个不同版本的数据上这样做。实际上，选项--frame-shift = t选项的作用是将输入帧移动t，并将输出帧按3到t的最接近的多重值移动。 （通常它可能不是3，是名为--frame-subsampling-factor的配置变量）。\n\n\n参考：\n[http://www.zongchang.net/a/kuaibao/20727.html](http://www.zongchang.net/a/kuaibao/20727.html)\n[Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI](https://www.isca-speech.org/archive/Interspeech_2016/pdfs/0595.PDF)\n","source":"_posts/kaldi-chain-model.md","raw":"---\ntitle:      kaldi chain model\nauthor:     liuyan\ncatalog:    true\ntags:\n  - 语音识别\n  - kaldi\n  - chain model\ndate:       2018-05-08 20:00:29\nurlname:\ncategories: 语音识别\n---\n\n### 声学模型网络\n\n声学模型就是用来估计不同音素对某一帧语音的条件概率，最终找出哪一种音素序列最有可能呈现出系统接收到的波形。\n\n#### DNN\n\nDNN 是一个典型的前馈网络，语音特征在进入输入层之后，逐层传播，最终在输出层得出每个音素的概率。值得注意的是，DNN在输入层除了当前帧之外，还会额外接收相邻的帧，这使得 DNN 一方面能够捕捉更广阔的时域信息，同时能够学习到相邻帧之间的变化特点。在实际应用中，DNN 往往会接受连续 10~20 帧作为输入。\n\n<!-- more -->\n\n![](1.png)\n\n#### TDNN\n\nTDNN与普通 DNN 类似，也是前馈网络，语音特征在网络内也是逐层向前传播，不同之处在于 TDNN 对隐层也做了上下文扩展。普通 DNN 每个隐层仅仅接收到前一个隐层的当前输出，而TDNN会将隐层的当前输出与其前后若干时刻的输出拼在一起，作为下一个隐层的输入。\n\n![](2.png)\n\n#### RNN\n\n与 RNN 对比来看，DNN 和 TDNN 的每个隐层都只会接收前一个隐层的输出，而由于语音特征在网络中传播时存在回路，RNN 中的隐层除了接收前一个隐层的输出外，还会将自己前一时刻的输出重新输入给自己。这样的结构使得 RNN 在理论上可以学习到无限长度的历史信息，但是在训练过程中，也会面临着复杂度较高以及梯度消失的问题。\n\n![](3.png)\n\n因为 RNN 模型有递归层的存在，导致很难像传统 DNN 那样进行并行化训练，同时与前馈神经网络相比 ，RNN 训练的复杂度要高很多，随之而来的问题就是模型训练时间过长。\n\n而 TDNN 的优点在于不仅能够对长时间依赖性的语音信号进行建模，同时与传统DNN的训练和解码效率几乎相当。\n\n### Chain Model\n\n#### TF-MMI\n\n在语音识别领域，区分性训练（Discriminative Training）能够显著提升语音识别系统的性能。区分性训练需要所有的单词序列组合来做训练，一般而言我们会先利用交叉熵准则训练一个基准模型，配合使用一个相对较弱的语言模型生成相应的词图（Lattice）。Lattice里面除了包含与正确识别结果相对应的路径外，还包含了与正确路径足够接近的其他路径，区分性训练就是要提高模型走正确路径的概率，同时压低走相似路径的概率。\n\n近年来CTC（Connectionist Temporal Classification）在语音识别领域受到很大关注，但CTC相比传统模型的优势，需要在很大的数据集上才能体现出来，而且CTC的训练速度很慢，参数调节更困难。与区分性训练中常用的MMI（Maximum Mutual Information）准则类似，CTC训练准则的目标是最大化正确标注的条件概率，而MMI着重优化正确路径和其他相似路径的概率差。\n\nLF-MMI（Lattice-Free Maximum Mutual Information）训练准则通过在神经网络输出层计算出来所有可能的标注序列，根据这些标注序列计算出相应的MMI信息和相关的梯度，然后通过梯度传播算法完成训练。\n\nLF-MMI训练准则能够在训练过程中直接计算所有可能路径的后验概率（Posterior Probability），省去了区分性训练前需要提前生成Lattice的麻烦，所以这种方法被叫做Lattice-Free MMI。\n\n**Chain Model在LF-MMI训练方法的基础上，还能够使用三分之一甚至更低的帧率、更简单的HMM拓扑结构来降低解码时间。**\n\n所谓的Chain Model就是结合了低帧率输出、优化过后的HMM拓扑结构和LF-MMI训练方法的语音识别系统。从实际效果来看，相对于主流的交叉熵模型系统，Chain Model搭配时延深度神经网络（TDNN），在语音识别系统的准确率（CER，字错误率）和解码速度上都获得了显著的提高。\n\n![](4.png)\n\n#### topo\n\ntdnn的输出帧速率是常规帧速率的1/3。这样做是因为从tdnn的网络结构来看相邻节点之间的变化较少，而且包含了大量重复信息，因此可以每隔几帧才计算一帧的结果，从而加速训练和解码过程。通过选择合适的时间步长，可以在大幅减少运算量的同时，没有漏掉任何历史信息，从而在识别准确性和运算量之间取得平衡。\n\ntdnn的输入特征是每秒100帧（每10毫秒一帧）的原始帧速率，输出的帧速率降低之后是每30毫秒一帧，所以需要修改hmm拓扑结构。传统的hmm拓扑是一种从左到右的3-state结构，可以至少在三帧内穿越。tdnn使用的拓扑结构可以在一帧内穿越，具有只能出现一次的状态，然后有可能出现零次或多次的另一种状态。所以单个HMM可以发出a或ab或abb等不同的状态，其中b可以理解为ctc中的blank。\n\n使用新的拓扑结构和基于GMM模型相同的过程来获得状态聚类。\n\n#### Training on frame-shifted data\n\n我们在之前已经有产生扰动数据的方法来人为地增加我们训练的数据量，在chain model中我们还可以额外的通过帧移位的方式来增加数据。\n\ntdnn的输出帧速率是常规帧速率的三分之一（可配置），这意味着我们只在t值为3的倍数时评估网络的输出，因此我们可以通过对训练数据进行帧移动来生成不同版本的训练数据，例如移动0,1和2帧。这是在训练脚本中自动完成的，当我们从磁盘读取训练示例时，nnet3-chain-copy-egs具有由脚本设置的-frame-shift选项。这其实影响的是epoch的数量，例如用户请求4个epoch，那么实际上训练12个epoch，我们只是在3个不同版本的数据上这样做。实际上，选项--frame-shift = t选项的作用是将输入帧移动t，并将输出帧按3到t的最接近的多重值移动。 （通常它可能不是3，是名为--frame-subsampling-factor的配置变量）。\n\n\n参考：\n[http://www.zongchang.net/a/kuaibao/20727.html](http://www.zongchang.net/a/kuaibao/20727.html)\n[Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI](https://www.isca-speech.org/archive/Interspeech_2016/pdfs/0595.PDF)\n","slug":"kaldi-chain-model","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hp000gly0gpzxf7hz4","content":"<h3 id=\"声学模型网络\"><a href=\"#声学模型网络\" class=\"headerlink\" title=\"声学模型网络\"></a>声学模型网络</h3><p>声学模型就是用来估计不同音素对某一帧语音的条件概率，最终找出哪一种音素序列最有可能呈现出系统接收到的波形。</p>\n<h4 id=\"DNN\"><a href=\"#DNN\" class=\"headerlink\" title=\"DNN\"></a>DNN</h4><p>DNN 是一个典型的前馈网络，语音特征在进入输入层之后，逐层传播，最终在输出层得出每个音素的概率。值得注意的是，DNN在输入层除了当前帧之外，还会额外接收相邻的帧，这使得 DNN 一方面能够捕捉更广阔的时域信息，同时能够学习到相邻帧之间的变化特点。在实际应用中，DNN 往往会接受连续 10~20 帧作为输入。</p>\n<a id=\"more\"></a>\n<p><img src=\"/2018/05/08/kaldi-chain-model/1.png\" alt=\"\"></p>\n<h4 id=\"TDNN\"><a href=\"#TDNN\" class=\"headerlink\" title=\"TDNN\"></a>TDNN</h4><p>TDNN与普通 DNN 类似，也是前馈网络，语音特征在网络内也是逐层向前传播，不同之处在于 TDNN 对隐层也做了上下文扩展。普通 DNN 每个隐层仅仅接收到前一个隐层的当前输出，而TDNN会将隐层的当前输出与其前后若干时刻的输出拼在一起，作为下一个隐层的输入。</p>\n<p><img src=\"/2018/05/08/kaldi-chain-model/2.png\" alt=\"\"></p>\n<h4 id=\"RNN\"><a href=\"#RNN\" class=\"headerlink\" title=\"RNN\"></a>RNN</h4><p>与 RNN 对比来看，DNN 和 TDNN 的每个隐层都只会接收前一个隐层的输出，而由于语音特征在网络中传播时存在回路，RNN 中的隐层除了接收前一个隐层的输出外，还会将自己前一时刻的输出重新输入给自己。这样的结构使得 RNN 在理论上可以学习到无限长度的历史信息，但是在训练过程中，也会面临着复杂度较高以及梯度消失的问题。</p>\n<p><img src=\"/2018/05/08/kaldi-chain-model/3.png\" alt=\"\"></p>\n<p>因为 RNN 模型有递归层的存在，导致很难像传统 DNN 那样进行并行化训练，同时与前馈神经网络相比 ，RNN 训练的复杂度要高很多，随之而来的问题就是模型训练时间过长。</p>\n<p>而 TDNN 的优点在于不仅能够对长时间依赖性的语音信号进行建模，同时与传统DNN的训练和解码效率几乎相当。</p>\n<h3 id=\"Chain-Model\"><a href=\"#Chain-Model\" class=\"headerlink\" title=\"Chain Model\"></a>Chain Model</h3><h4 id=\"TF-MMI\"><a href=\"#TF-MMI\" class=\"headerlink\" title=\"TF-MMI\"></a>TF-MMI</h4><p>在语音识别领域，区分性训练（Discriminative Training）能够显著提升语音识别系统的性能。区分性训练需要所有的单词序列组合来做训练，一般而言我们会先利用交叉熵准则训练一个基准模型，配合使用一个相对较弱的语言模型生成相应的词图（Lattice）。Lattice里面除了包含与正确识别结果相对应的路径外，还包含了与正确路径足够接近的其他路径，区分性训练就是要提高模型走正确路径的概率，同时压低走相似路径的概率。</p>\n<p>近年来CTC（Connectionist Temporal Classification）在语音识别领域受到很大关注，但CTC相比传统模型的优势，需要在很大的数据集上才能体现出来，而且CTC的训练速度很慢，参数调节更困难。与区分性训练中常用的MMI（Maximum Mutual Information）准则类似，CTC训练准则的目标是最大化正确标注的条件概率，而MMI着重优化正确路径和其他相似路径的概率差。</p>\n<p>LF-MMI（Lattice-Free Maximum Mutual Information）训练准则通过在神经网络输出层计算出来所有可能的标注序列，根据这些标注序列计算出相应的MMI信息和相关的梯度，然后通过梯度传播算法完成训练。</p>\n<p>LF-MMI训练准则能够在训练过程中直接计算所有可能路径的后验概率（Posterior Probability），省去了区分性训练前需要提前生成Lattice的麻烦，所以这种方法被叫做Lattice-Free MMI。</p>\n<p><strong>Chain Model在LF-MMI训练方法的基础上，还能够使用三分之一甚至更低的帧率、更简单的HMM拓扑结构来降低解码时间。</strong></p>\n<p>所谓的Chain Model就是结合了低帧率输出、优化过后的HMM拓扑结构和LF-MMI训练方法的语音识别系统。从实际效果来看，相对于主流的交叉熵模型系统，Chain Model搭配时延深度神经网络（TDNN），在语音识别系统的准确率（CER，字错误率）和解码速度上都获得了显著的提高。</p>\n<p><img src=\"/2018/05/08/kaldi-chain-model/4.png\" alt=\"\"></p>\n<h4 id=\"topo\"><a href=\"#topo\" class=\"headerlink\" title=\"topo\"></a>topo</h4><p>tdnn的输出帧速率是常规帧速率的1/3。这样做是因为从tdnn的网络结构来看相邻节点之间的变化较少，而且包含了大量重复信息，因此可以每隔几帧才计算一帧的结果，从而加速训练和解码过程。通过选择合适的时间步长，可以在大幅减少运算量的同时，没有漏掉任何历史信息，从而在识别准确性和运算量之间取得平衡。</p>\n<p>tdnn的输入特征是每秒100帧（每10毫秒一帧）的原始帧速率，输出的帧速率降低之后是每30毫秒一帧，所以需要修改hmm拓扑结构。传统的hmm拓扑是一种从左到右的3-state结构，可以至少在三帧内穿越。tdnn使用的拓扑结构可以在一帧内穿越，具有只能出现一次的状态，然后有可能出现零次或多次的另一种状态。所以单个HMM可以发出a或ab或abb等不同的状态，其中b可以理解为ctc中的blank。</p>\n<p>使用新的拓扑结构和基于GMM模型相同的过程来获得状态聚类。</p>\n<h4 id=\"Training-on-frame-shifted-data\"><a href=\"#Training-on-frame-shifted-data\" class=\"headerlink\" title=\"Training on frame-shifted data\"></a>Training on frame-shifted data</h4><p>我们在之前已经有产生扰动数据的方法来人为地增加我们训练的数据量，在chain model中我们还可以额外的通过帧移位的方式来增加数据。</p>\n<p>tdnn的输出帧速率是常规帧速率的三分之一（可配置），这意味着我们只在t值为3的倍数时评估网络的输出，因此我们可以通过对训练数据进行帧移动来生成不同版本的训练数据，例如移动0,1和2帧。这是在训练脚本中自动完成的，当我们从磁盘读取训练示例时，nnet3-chain-copy-egs具有由脚本设置的-frame-shift选项。这其实影响的是epoch的数量，例如用户请求4个epoch，那么实际上训练12个epoch，我们只是在3个不同版本的数据上这样做。实际上，选项–frame-shift = t选项的作用是将输入帧移动t，并将输出帧按3到t的最接近的多重值移动。 （通常它可能不是3，是名为–frame-subsampling-factor的配置变量）。</p>\n<p>参考：<br><a href=\"http://www.zongchang.net/a/kuaibao/20727.html\" target=\"_blank\" rel=\"noopener\">http://www.zongchang.net/a/kuaibao/20727.html</a><br><a href=\"https://www.isca-speech.org/archive/Interspeech_2016/pdfs/0595.PDF\" target=\"_blank\" rel=\"noopener\">Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"声学模型网络\"><a href=\"#声学模型网络\" class=\"headerlink\" title=\"声学模型网络\"></a>声学模型网络</h3><p>声学模型就是用来估计不同音素对某一帧语音的条件概率，最终找出哪一种音素序列最有可能呈现出系统接收到的波形。</p>\n<h4 id=\"DNN\"><a href=\"#DNN\" class=\"headerlink\" title=\"DNN\"></a>DNN</h4><p>DNN 是一个典型的前馈网络，语音特征在进入输入层之后，逐层传播，最终在输出层得出每个音素的概率。值得注意的是，DNN在输入层除了当前帧之外，还会额外接收相邻的帧，这使得 DNN 一方面能够捕捉更广阔的时域信息，同时能够学习到相邻帧之间的变化特点。在实际应用中，DNN 往往会接受连续 10~20 帧作为输入。</p>","more":"<p><img src=\"/2018/05/08/kaldi-chain-model/1.png\" alt=\"\"></p>\n<h4 id=\"TDNN\"><a href=\"#TDNN\" class=\"headerlink\" title=\"TDNN\"></a>TDNN</h4><p>TDNN与普通 DNN 类似，也是前馈网络，语音特征在网络内也是逐层向前传播，不同之处在于 TDNN 对隐层也做了上下文扩展。普通 DNN 每个隐层仅仅接收到前一个隐层的当前输出，而TDNN会将隐层的当前输出与其前后若干时刻的输出拼在一起，作为下一个隐层的输入。</p>\n<p><img src=\"/2018/05/08/kaldi-chain-model/2.png\" alt=\"\"></p>\n<h4 id=\"RNN\"><a href=\"#RNN\" class=\"headerlink\" title=\"RNN\"></a>RNN</h4><p>与 RNN 对比来看，DNN 和 TDNN 的每个隐层都只会接收前一个隐层的输出，而由于语音特征在网络中传播时存在回路，RNN 中的隐层除了接收前一个隐层的输出外，还会将自己前一时刻的输出重新输入给自己。这样的结构使得 RNN 在理论上可以学习到无限长度的历史信息，但是在训练过程中，也会面临着复杂度较高以及梯度消失的问题。</p>\n<p><img src=\"/2018/05/08/kaldi-chain-model/3.png\" alt=\"\"></p>\n<p>因为 RNN 模型有递归层的存在，导致很难像传统 DNN 那样进行并行化训练，同时与前馈神经网络相比 ，RNN 训练的复杂度要高很多，随之而来的问题就是模型训练时间过长。</p>\n<p>而 TDNN 的优点在于不仅能够对长时间依赖性的语音信号进行建模，同时与传统DNN的训练和解码效率几乎相当。</p>\n<h3 id=\"Chain-Model\"><a href=\"#Chain-Model\" class=\"headerlink\" title=\"Chain Model\"></a>Chain Model</h3><h4 id=\"TF-MMI\"><a href=\"#TF-MMI\" class=\"headerlink\" title=\"TF-MMI\"></a>TF-MMI</h4><p>在语音识别领域，区分性训练（Discriminative Training）能够显著提升语音识别系统的性能。区分性训练需要所有的单词序列组合来做训练，一般而言我们会先利用交叉熵准则训练一个基准模型，配合使用一个相对较弱的语言模型生成相应的词图（Lattice）。Lattice里面除了包含与正确识别结果相对应的路径外，还包含了与正确路径足够接近的其他路径，区分性训练就是要提高模型走正确路径的概率，同时压低走相似路径的概率。</p>\n<p>近年来CTC（Connectionist Temporal Classification）在语音识别领域受到很大关注，但CTC相比传统模型的优势，需要在很大的数据集上才能体现出来，而且CTC的训练速度很慢，参数调节更困难。与区分性训练中常用的MMI（Maximum Mutual Information）准则类似，CTC训练准则的目标是最大化正确标注的条件概率，而MMI着重优化正确路径和其他相似路径的概率差。</p>\n<p>LF-MMI（Lattice-Free Maximum Mutual Information）训练准则通过在神经网络输出层计算出来所有可能的标注序列，根据这些标注序列计算出相应的MMI信息和相关的梯度，然后通过梯度传播算法完成训练。</p>\n<p>LF-MMI训练准则能够在训练过程中直接计算所有可能路径的后验概率（Posterior Probability），省去了区分性训练前需要提前生成Lattice的麻烦，所以这种方法被叫做Lattice-Free MMI。</p>\n<p><strong>Chain Model在LF-MMI训练方法的基础上，还能够使用三分之一甚至更低的帧率、更简单的HMM拓扑结构来降低解码时间。</strong></p>\n<p>所谓的Chain Model就是结合了低帧率输出、优化过后的HMM拓扑结构和LF-MMI训练方法的语音识别系统。从实际效果来看，相对于主流的交叉熵模型系统，Chain Model搭配时延深度神经网络（TDNN），在语音识别系统的准确率（CER，字错误率）和解码速度上都获得了显著的提高。</p>\n<p><img src=\"/2018/05/08/kaldi-chain-model/4.png\" alt=\"\"></p>\n<h4 id=\"topo\"><a href=\"#topo\" class=\"headerlink\" title=\"topo\"></a>topo</h4><p>tdnn的输出帧速率是常规帧速率的1/3。这样做是因为从tdnn的网络结构来看相邻节点之间的变化较少，而且包含了大量重复信息，因此可以每隔几帧才计算一帧的结果，从而加速训练和解码过程。通过选择合适的时间步长，可以在大幅减少运算量的同时，没有漏掉任何历史信息，从而在识别准确性和运算量之间取得平衡。</p>\n<p>tdnn的输入特征是每秒100帧（每10毫秒一帧）的原始帧速率，输出的帧速率降低之后是每30毫秒一帧，所以需要修改hmm拓扑结构。传统的hmm拓扑是一种从左到右的3-state结构，可以至少在三帧内穿越。tdnn使用的拓扑结构可以在一帧内穿越，具有只能出现一次的状态，然后有可能出现零次或多次的另一种状态。所以单个HMM可以发出a或ab或abb等不同的状态，其中b可以理解为ctc中的blank。</p>\n<p>使用新的拓扑结构和基于GMM模型相同的过程来获得状态聚类。</p>\n<h4 id=\"Training-on-frame-shifted-data\"><a href=\"#Training-on-frame-shifted-data\" class=\"headerlink\" title=\"Training on frame-shifted data\"></a>Training on frame-shifted data</h4><p>我们在之前已经有产生扰动数据的方法来人为地增加我们训练的数据量，在chain model中我们还可以额外的通过帧移位的方式来增加数据。</p>\n<p>tdnn的输出帧速率是常规帧速率的三分之一（可配置），这意味着我们只在t值为3的倍数时评估网络的输出，因此我们可以通过对训练数据进行帧移动来生成不同版本的训练数据，例如移动0,1和2帧。这是在训练脚本中自动完成的，当我们从磁盘读取训练示例时，nnet3-chain-copy-egs具有由脚本设置的-frame-shift选项。这其实影响的是epoch的数量，例如用户请求4个epoch，那么实际上训练12个epoch，我们只是在3个不同版本的数据上这样做。实际上，选项–frame-shift = t选项的作用是将输入帧移动t，并将输出帧按3到t的最接近的多重值移动。 （通常它可能不是3，是名为–frame-subsampling-factor的配置变量）。</p>\n<p>参考：<br><a href=\"http://www.zongchang.net/a/kuaibao/20727.html\" target=\"_blank\" rel=\"noopener\">http://www.zongchang.net/a/kuaibao/20727.html</a><br><a href=\"https://www.isca-speech.org/archive/Interspeech_2016/pdfs/0595.PDF\" target=\"_blank\" rel=\"noopener\">Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI</a></p>"},{"title":"linux解压缩","author":"liuyan","catalog":true,"date":"2016-11-03T11:29:45.000Z","urlname":null,"_content":"\n.tar\n压缩：tar cvf FileName.tar FileName\n解压：tar xvf FileName.tar\n\n.gz\n解压1：gunzip FileName.gz \n解压2：gzip -d FileName.gz \n压缩：gzip FileName \n\n.tar.gz \n解压：tar zxvf FileName.tar.gz \n压缩：tar zcvf FileName.tar.gz DirName \n\n.bz2 \n解压1：bzip2 -d FileName.bz2 \n解压2：bunzip2 FileName.bz2 \n压缩： bzip2 -z FileName \n\n<!-- more -->\n\n.tar.bz2 \n解压：tar jxvf FileName.tar.bz2 \n压缩：tar jcvf FileName.tar.bz2 DirName \n\n.bz \n解压1：bzip2 -d FileName.bz \n解压2：bunzip2 FileName.bz \n压缩：未知 \n\n.tar.bz \n解压：tar jxvf FileName.tar.bz \n压缩：未知 \n\n.Z \n解压：uncompress FileName.Z \n压缩：compress FileName \n\n.tar.Z \n解压：tar Zxvf FileName.tar.Z \n压缩：tar Zcvf FileName.tar.Z DirName \n\n.tgz \n解压：tar zxvf FileName.tgz \n压缩：未知 \n\n.tar.tgz \n解压：tar zxvf FileName.tar.tgz \n压缩：tar zcvf FileName.tar.tgz FileName \n\n.zip \n解压：unzip FileName.zip \n压缩：zip FileName.zip DirName \n\n.rar \n解压：rar a FileName.rar \n压缩：rar e FileName.rar \n\n","source":"_posts/linux解压缩.md","raw":"---\ntitle:      linux解压缩\nauthor:     liuyan\ncatalog:    true\ntags:\n  - linux\ndate: 2016-11-03 19:29:45\nurlname:\ncategories: linux\n---\n\n.tar\n压缩：tar cvf FileName.tar FileName\n解压：tar xvf FileName.tar\n\n.gz\n解压1：gunzip FileName.gz \n解压2：gzip -d FileName.gz \n压缩：gzip FileName \n\n.tar.gz \n解压：tar zxvf FileName.tar.gz \n压缩：tar zcvf FileName.tar.gz DirName \n\n.bz2 \n解压1：bzip2 -d FileName.bz2 \n解压2：bunzip2 FileName.bz2 \n压缩： bzip2 -z FileName \n\n<!-- more -->\n\n.tar.bz2 \n解压：tar jxvf FileName.tar.bz2 \n压缩：tar jcvf FileName.tar.bz2 DirName \n\n.bz \n解压1：bzip2 -d FileName.bz \n解压2：bunzip2 FileName.bz \n压缩：未知 \n\n.tar.bz \n解压：tar jxvf FileName.tar.bz \n压缩：未知 \n\n.Z \n解压：uncompress FileName.Z \n压缩：compress FileName \n\n.tar.Z \n解压：tar Zxvf FileName.tar.Z \n压缩：tar Zcvf FileName.tar.Z DirName \n\n.tgz \n解压：tar zxvf FileName.tgz \n压缩：未知 \n\n.tar.tgz \n解压：tar zxvf FileName.tar.tgz \n压缩：tar zcvf FileName.tar.tgz FileName \n\n.zip \n解压：unzip FileName.zip \n压缩：zip FileName.zip DirName \n\n.rar \n解压：rar a FileName.rar \n压缩：rar e FileName.rar \n\n","slug":"linux解压缩","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hr000hly0gv9f3r6jg","content":"<p>.tar<br>压缩：tar cvf FileName.tar FileName<br>解压：tar xvf FileName.tar</p>\n<p>.gz<br>解压1：gunzip FileName.gz<br>解压2：gzip -d FileName.gz<br>压缩：gzip FileName </p>\n<p>.tar.gz<br>解压：tar zxvf FileName.tar.gz<br>压缩：tar zcvf FileName.tar.gz DirName </p>\n<p>.bz2<br>解压1：bzip2 -d FileName.bz2<br>解压2：bunzip2 FileName.bz2<br>压缩： bzip2 -z FileName </p>\n<a id=\"more\"></a>\n<p>.tar.bz2<br>解压：tar jxvf FileName.tar.bz2<br>压缩：tar jcvf FileName.tar.bz2 DirName </p>\n<p>.bz<br>解压1：bzip2 -d FileName.bz<br>解压2：bunzip2 FileName.bz<br>压缩：未知 </p>\n<p>.tar.bz<br>解压：tar jxvf FileName.tar.bz<br>压缩：未知 </p>\n<p>.Z<br>解压：uncompress FileName.Z<br>压缩：compress FileName </p>\n<p>.tar.Z<br>解压：tar Zxvf FileName.tar.Z<br>压缩：tar Zcvf FileName.tar.Z DirName </p>\n<p>.tgz<br>解压：tar zxvf FileName.tgz<br>压缩：未知 </p>\n<p>.tar.tgz<br>解压：tar zxvf FileName.tar.tgz<br>压缩：tar zcvf FileName.tar.tgz FileName </p>\n<p>.zip<br>解压：unzip FileName.zip<br>压缩：zip FileName.zip DirName </p>\n<p>.rar<br>解压：rar a FileName.rar<br>压缩：rar e FileName.rar </p>\n","site":{"data":{}},"excerpt":"<p>.tar<br>压缩：tar cvf FileName.tar FileName<br>解压：tar xvf FileName.tar</p>\n<p>.gz<br>解压1：gunzip FileName.gz<br>解压2：gzip -d FileName.gz<br>压缩：gzip FileName </p>\n<p>.tar.gz<br>解压：tar zxvf FileName.tar.gz<br>压缩：tar zcvf FileName.tar.gz DirName </p>\n<p>.bz2<br>解压1：bzip2 -d FileName.bz2<br>解压2：bunzip2 FileName.bz2<br>压缩： bzip2 -z FileName </p>","more":"<p>.tar.bz2<br>解压：tar jxvf FileName.tar.bz2<br>压缩：tar jcvf FileName.tar.bz2 DirName </p>\n<p>.bz<br>解压1：bzip2 -d FileName.bz<br>解压2：bunzip2 FileName.bz<br>压缩：未知 </p>\n<p>.tar.bz<br>解压：tar jxvf FileName.tar.bz<br>压缩：未知 </p>\n<p>.Z<br>解压：uncompress FileName.Z<br>压缩：compress FileName </p>\n<p>.tar.Z<br>解压：tar Zxvf FileName.tar.Z<br>压缩：tar Zcvf FileName.tar.Z DirName </p>\n<p>.tgz<br>解压：tar zxvf FileName.tgz<br>压缩：未知 </p>\n<p>.tar.tgz<br>解压：tar zxvf FileName.tar.tgz<br>压缩：tar zcvf FileName.tar.tgz FileName </p>\n<p>.zip<br>解压：unzip FileName.zip<br>压缩：zip FileName.zip DirName </p>\n<p>.rar<br>解压：rar a FileName.rar<br>压缩：rar e FileName.rar </p>"},{"title":"mac常用软件插件","author":"liuyan","catalog":true,"date":"2018-01-23T11:14:11.000Z","urlname":null,"_content":"\n### 软件\n\n- mathpix snipping tool #截图生成数学公式\n- sublime2\n- iterm\n- typora\n- ipic\n- 印象笔记\n- 有道词典\n- 网易云音乐\n\n<!-- more -->\n\n### google插件\n\n- Infinity：美观实用的新建标签页\n- OneTab：整理标签\n- 印象笔记剪裁\n- Octotree\n- 淘客助手\n- google翻译\n\n","source":"_posts/mac常用软件插件.md","raw":"---\ntitle:      mac常用软件插件\nauthor:     liuyan\ncatalog:    true\ntags:\n  - 工具\ndate:       2018-01-23 19:14:11\nurlname:\ncategories: 工具\n---\n\n### 软件\n\n- mathpix snipping tool #截图生成数学公式\n- sublime2\n- iterm\n- typora\n- ipic\n- 印象笔记\n- 有道词典\n- 网易云音乐\n\n<!-- more -->\n\n### google插件\n\n- Infinity：美观实用的新建标签页\n- OneTab：整理标签\n- 印象笔记剪裁\n- Octotree\n- 淘客助手\n- google翻译\n\n","slug":"mac常用软件插件","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hu000lly0ge5hczpl3","content":"<h3 id=\"软件\"><a href=\"#软件\" class=\"headerlink\" title=\"软件\"></a>软件</h3><ul>\n<li>mathpix snipping tool #截图生成数学公式</li>\n<li>sublime2</li>\n<li>iterm</li>\n<li>typora</li>\n<li>ipic</li>\n<li>印象笔记</li>\n<li>有道词典</li>\n<li>网易云音乐</li>\n</ul>\n<a id=\"more\"></a>\n<h3 id=\"google插件\"><a href=\"#google插件\" class=\"headerlink\" title=\"google插件\"></a>google插件</h3><ul>\n<li>Infinity：美观实用的新建标签页</li>\n<li>OneTab：整理标签</li>\n<li>印象笔记剪裁</li>\n<li>Octotree</li>\n<li>淘客助手</li>\n<li>google翻译</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h3 id=\"软件\"><a href=\"#软件\" class=\"headerlink\" title=\"软件\"></a>软件</h3><ul>\n<li>mathpix snipping tool #截图生成数学公式</li>\n<li>sublime2</li>\n<li>iterm</li>\n<li>typora</li>\n<li>ipic</li>\n<li>印象笔记</li>\n<li>有道词典</li>\n<li>网易云音乐</li>\n</ul>","more":"<h3 id=\"google插件\"><a href=\"#google插件\" class=\"headerlink\" title=\"google插件\"></a>google插件</h3><ul>\n<li>Infinity：美观实用的新建标签页</li>\n<li>OneTab：整理标签</li>\n<li>印象笔记剪裁</li>\n<li>Octotree</li>\n<li>淘客助手</li>\n<li>google翻译</li>\n</ul>"},{"title":"tensorflow小技巧","author":"liuyan","catalog":true,"date":"2017-10-14T08:37:39.000Z","urlname":null,"_content":"\n### 显卡问题\n\n```sh\nimport os\nimport tensorflow as tf\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '2,3' # 指定哪张卡：0, 1, 2, ...\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True  # 随着进程逐渐增加显存占用，而不是一下占满\nsession = tf.Session(config=config, ...)\n```\n\n<!-- more -->\n\n那么如果你想要给某个操作指定2号显卡的时候，由于CUDA只能看到2块，2,3号就相当于0,1号卡(而不是'/gpu:2'和'/gpu:3')，则需要用：\n\n```sh\nwith tf.device('/gpu:0'):\n\t\"your ops here\"\n```\n\n### 查看ckpt中的网络结构和参数\n\n```sh\npython tensorflow/python/tools/inspect_checkpoint.py  \n--file_name=model.ckpt-158940 --tensor_name=unit_1_1/conv1/Weights  \n```\n\n如果你只用了file_name这个参数，那么看到的就是整体网络结构。如果你2个参数都用了，那看到的就是具体那一层的值。\n\n或者开源项目：MMdnn，先把ckpt转成给定的中间表示，再看网络结构。\n\n### 远程访问Tensorboard\n\n一般来说我们都是在服务器上使用tensorflow的，那么能不能直接在服务器上运行tensorboard呢？\n\n#### 步骤\n\n1. ssh -L 16006:127.0.0.1:6006 account@server.address\n2. tensorboard --logdir=\"tensorboard\"\n3. 在本地主机访问 <http://127.0.0.1:16006/>\n\n#### 原理\n\n建立ssh隧道，实现远程端口到本地端口的转发。\n具体来说就是将远程服务器的6006端口（tensorboard默认将数据放在6006端口）转发到本地的16006端口，在本地对16006端口的访问即是对远程6006端口的访问，当然，转发到本地某一端口不是限定的，可自由选择。\n\n","source":"_posts/tensorflow小技巧.md","raw":"---\ntitle:      tensorflow小技巧\nauthor:     liuyan\ncatalog:    true\ntags:\n  - tensorflow\n  - deep learning\ndate: 2017-10-14 16:37:39\nurlname:\ncategories: deep learning\n---\n\n### 显卡问题\n\n```sh\nimport os\nimport tensorflow as tf\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '2,3' # 指定哪张卡：0, 1, 2, ...\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True  # 随着进程逐渐增加显存占用，而不是一下占满\nsession = tf.Session(config=config, ...)\n```\n\n<!-- more -->\n\n那么如果你想要给某个操作指定2号显卡的时候，由于CUDA只能看到2块，2,3号就相当于0,1号卡(而不是'/gpu:2'和'/gpu:3')，则需要用：\n\n```sh\nwith tf.device('/gpu:0'):\n\t\"your ops here\"\n```\n\n### 查看ckpt中的网络结构和参数\n\n```sh\npython tensorflow/python/tools/inspect_checkpoint.py  \n--file_name=model.ckpt-158940 --tensor_name=unit_1_1/conv1/Weights  \n```\n\n如果你只用了file_name这个参数，那么看到的就是整体网络结构。如果你2个参数都用了，那看到的就是具体那一层的值。\n\n或者开源项目：MMdnn，先把ckpt转成给定的中间表示，再看网络结构。\n\n### 远程访问Tensorboard\n\n一般来说我们都是在服务器上使用tensorflow的，那么能不能直接在服务器上运行tensorboard呢？\n\n#### 步骤\n\n1. ssh -L 16006:127.0.0.1:6006 account@server.address\n2. tensorboard --logdir=\"tensorboard\"\n3. 在本地主机访问 <http://127.0.0.1:16006/>\n\n#### 原理\n\n建立ssh隧道，实现远程端口到本地端口的转发。\n具体来说就是将远程服务器的6006端口（tensorboard默认将数据放在6006端口）转发到本地的16006端口，在本地对16006端口的访问即是对远程6006端口的访问，当然，转发到本地某一端口不是限定的，可自由选择。\n\n","slug":"tensorflow小技巧","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2hy000oly0g19lmbkfk","content":"<h3 id=\"显卡问题\"><a href=\"#显卡问题\" class=\"headerlink\" title=\"显卡问题\"></a>显卡问题</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\"></span><br><span class=\"line\">os.environ[<span class=\"string\">'CUDA_VISIBLE_DEVICES'</span>] = <span class=\"string\">'2,3'</span> <span class=\"comment\"># 指定哪张卡：0, 1, 2, ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">config = tf.ConfigProto()</span><br><span class=\"line\">config.gpu_options.allow_growth = True  <span class=\"comment\"># 随着进程逐渐增加显存占用，而不是一下占满</span></span><br><span class=\"line\">session = tf.Session(config=config, ...)</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<p>那么如果你想要给某个操作指定2号显卡的时候，由于CUDA只能看到2块，2,3号就相当于0,1号卡(而不是’/gpu:2’和’/gpu:3’)，则需要用：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">with tf.device(<span class=\"string\">'/gpu:0'</span>):</span><br><span class=\"line\">\t<span class=\"string\">\"your ops here\"</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"查看ckpt中的网络结构和参数\"><a href=\"#查看ckpt中的网络结构和参数\" class=\"headerlink\" title=\"查看ckpt中的网络结构和参数\"></a>查看ckpt中的网络结构和参数</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python tensorflow/python/tools/inspect_checkpoint.py  </span><br><span class=\"line\">--file_name=model.ckpt-158940 --tensor_name=unit_1_1/conv1/Weights</span><br></pre></td></tr></table></figure>\n<p>如果你只用了file_name这个参数，那么看到的就是整体网络结构。如果你2个参数都用了，那看到的就是具体那一层的值。</p>\n<p>或者开源项目：MMdnn，先把ckpt转成给定的中间表示，再看网络结构。</p>\n<h3 id=\"远程访问Tensorboard\"><a href=\"#远程访问Tensorboard\" class=\"headerlink\" title=\"远程访问Tensorboard\"></a>远程访问Tensorboard</h3><p>一般来说我们都是在服务器上使用tensorflow的，那么能不能直接在服务器上运行tensorboard呢？</p>\n<h4 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h4><ol>\n<li>ssh -L 16006:127.0.0.1:6006 <a href=\"mailto:account@server.address\" target=\"_blank\" rel=\"noopener\">account@server.address</a></li>\n<li>tensorboard –logdir=”tensorboard”</li>\n<li>在本地主机访问 <a href=\"http://127.0.0.1:16006/\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:16006/</a></li>\n</ol>\n<h4 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h4><p>建立ssh隧道，实现远程端口到本地端口的转发。<br>具体来说就是将远程服务器的6006端口（tensorboard默认将数据放在6006端口）转发到本地的16006端口，在本地对16006端口的访问即是对远程6006端口的访问，当然，转发到本地某一端口不是限定的，可自由选择。</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"显卡问题\"><a href=\"#显卡问题\" class=\"headerlink\" title=\"显卡问题\"></a>显卡问题</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import os</span><br><span class=\"line\">import tensorflow as tf</span><br><span class=\"line\"></span><br><span class=\"line\">os.environ[<span class=\"string\">'CUDA_VISIBLE_DEVICES'</span>] = <span class=\"string\">'2,3'</span> <span class=\"comment\"># 指定哪张卡：0, 1, 2, ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">config = tf.ConfigProto()</span><br><span class=\"line\">config.gpu_options.allow_growth = True  <span class=\"comment\"># 随着进程逐渐增加显存占用，而不是一下占满</span></span><br><span class=\"line\">session = tf.Session(config=config, ...)</span><br></pre></td></tr></table></figure>","more":"<p>那么如果你想要给某个操作指定2号显卡的时候，由于CUDA只能看到2块，2,3号就相当于0,1号卡(而不是’/gpu:2’和’/gpu:3’)，则需要用：</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">with tf.device(<span class=\"string\">'/gpu:0'</span>):</span><br><span class=\"line\">\t<span class=\"string\">\"your ops here\"</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"查看ckpt中的网络结构和参数\"><a href=\"#查看ckpt中的网络结构和参数\" class=\"headerlink\" title=\"查看ckpt中的网络结构和参数\"></a>查看ckpt中的网络结构和参数</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python tensorflow/python/tools/inspect_checkpoint.py  </span><br><span class=\"line\">--file_name=model.ckpt-158940 --tensor_name=unit_1_1/conv1/Weights</span><br></pre></td></tr></table></figure>\n<p>如果你只用了file_name这个参数，那么看到的就是整体网络结构。如果你2个参数都用了，那看到的就是具体那一层的值。</p>\n<p>或者开源项目：MMdnn，先把ckpt转成给定的中间表示，再看网络结构。</p>\n<h3 id=\"远程访问Tensorboard\"><a href=\"#远程访问Tensorboard\" class=\"headerlink\" title=\"远程访问Tensorboard\"></a>远程访问Tensorboard</h3><p>一般来说我们都是在服务器上使用tensorflow的，那么能不能直接在服务器上运行tensorboard呢？</p>\n<h4 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h4><ol>\n<li>ssh -L 16006:127.0.0.1:6006 <a href=\"mailto:account@server.address\" target=\"_blank\" rel=\"noopener\">account@server.address</a></li>\n<li>tensorboard –logdir=”tensorboard”</li>\n<li>在本地主机访问 <a href=\"http://127.0.0.1:16006/\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:16006/</a></li>\n</ol>\n<h4 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h4><p>建立ssh隧道，实现远程端口到本地端口的转发。<br>具体来说就是将远程服务器的6006端口（tensorboard默认将数据放在6006端口）转发到本地的16006端口，在本地对16006端口的访问即是对远程6006端口的访问，当然，转发到本地某一端口不是限定的，可自由选择。</p>"},{"title":"vim和shell技巧","author":"liuyan","catalog":true,"date":"2018-01-03T11:44:05.000Z","urlname":null,"_content":"\n## linux\n\n### shell快捷键\n```shell\nctrl+a:\t\t移到行首\nctrl+e:\t\t移到行尾\nctrl+xx:\t行首到当前光标替换\nctrl+w:\t\t删除光标前一个单词相当于vim里db\nctrl+h:\t\t删除光标前一个字符（相当于backspace）\nctrl+d: \t删除光标后一个字符（相当于delete）\nctrl+u: \t删除光标左边所有\nctrl+k: \t删除光标右边所有\nctrl+l: \t清屏\n```\n\n<!-- more -->\n\n### awk获取文本某列\n```sh\nawk '{print $0}' filename    \t#完整的文件内容\nawk '{print $1}' filename    \t#取第一列\nawk '{print $1,$2}' filename \t#取前两列\nawk '{print $NF}' filename  \t#取最后一列\nawk '{print $NF-1}' filename  \t#取倒数第二列\n```\n\n### sed修改文本内容\n```sh\nsed 's/^/HEAD&/g' filename          #在每行的头添加字符\"HEAD\"\nsed 's/$/&TAIL/g' filename          #在每行的尾添加字符“TAIL”\nsed  's/a/b/g'  filename            #将文本中的\"a\"换成\"b\"\nsed -e 'nc/just do' filename        #把第n行替换成just do\nsed -e '1,10c/I can do' filename    #把1到10行替换成一行：I can do\n\n#\"^\"代表行首，\"$\"代表行尾，字符g代表每行出现的字符全部替换\n#如果想在原文件上更改，添加选项-i\n```\n\n### grep搜索文件内容\n#### 格式\n```shell\ngrep [options] PATTERN [FILE...]\n[options]主要参数：\n－c：只输出匹配行的计数\n－I：不区分大小写\n－h：查询多文件时不显示文件名\n－l：查询多文件时只输出包含匹配字符的文件名\n－n：显示匹配行及行号\n－v：显示不包含匹配文本的所有行\n```\n\n#### 实例\n```shell\nls -l | grep '^a'           #只显示以a开头的行\nls -l | grep '$a'           #只显示以a结尾的行\ngrep 'test' d*              #显示所有以d开头的文件中包含test的行\ngrep 'test' aa bb cc        #显示在aa，bb，cc文件中匹配test的行\ngrep '[a-z]\\{5\\}' aa        #显示aa中所有有5个连续小写字符的行\ngrep -i '^s' a              #不区分大小以s/S开头的行\ngrep ':[0-9]:' a            #两个冒号中间一个数字的行\n```\n\n### 环境变量\n```shell\necho $PATH（查看）\nexport PATH=/usr/local/bin:$PATH（临时添加）\n将export PATH=\"/usr/local/bin:$PATH\"添加到/etc/profile或者~/.bashrc，然后source一下（永久添加）\n```\n\n\n\n## vim\n\n### vim快捷键\n```shell\ne: 前移一个单词\nb: 后移一个单词\nhjkl \ngg: 到文件头部\nG: 到文件尾部\nctrl+d: 下翻半屏\nctrl+u: 上翻半屏\nd$ or D: 删除（剪切）当前位置到行尾的内容\nd0: 删除（剪切）当前位置到行首的内容\n%: 不仅能移动到匹配的(),{}或[]上，而且能在#if，#else， #endif之间跳跃\n*: 向下搜索光标所在词\n```\n\n### 多行缩进\n```sh\n1 //在这里按下'v'进入选择模式\n2 ...\n3 //光标移动到这里，再按一次大于号'>'缩进一次，按'6>'缩进六次，按'<'回缩。\n```\n\n### 多行注释\n```\n1 //在这里按下'v'进入选择模式\n2 ...\n3 //光标移动到这里，按'ctrl+v'（win下面'ctrl+q'）进入列模式\n4 //按大写'I'进入插入模式，输入注释符'#'或者是'//'，然后立刻按两下ESC。\n```\n\n### 多行取消注释\n```\n1 //在这里按下'ctrl+v'进入块选择模式\n2 ...\n3 //光标移动到这里，选中'//'或者'##'，之后按d即可。(删除)\n```\n\n## chrome快捷键\n\n- 跳转到下一个打开的标签页 ⌘ +Option+向右箭头键\n- 跳转到特定标签页 ⌘ +1 到 ⌘ +8\n","source":"_posts/vim和shell技巧.md","raw":"---\ntitle:      vim和shell技巧\nauthor:     liuyan\ncatalog:    true\ntags:\n  - linux \ndate:       2018-01-03 19:44:05\nurlname:\ncategories: linux\n---\n\n## linux\n\n### shell快捷键\n```shell\nctrl+a:\t\t移到行首\nctrl+e:\t\t移到行尾\nctrl+xx:\t行首到当前光标替换\nctrl+w:\t\t删除光标前一个单词相当于vim里db\nctrl+h:\t\t删除光标前一个字符（相当于backspace）\nctrl+d: \t删除光标后一个字符（相当于delete）\nctrl+u: \t删除光标左边所有\nctrl+k: \t删除光标右边所有\nctrl+l: \t清屏\n```\n\n<!-- more -->\n\n### awk获取文本某列\n```sh\nawk '{print $0}' filename    \t#完整的文件内容\nawk '{print $1}' filename    \t#取第一列\nawk '{print $1,$2}' filename \t#取前两列\nawk '{print $NF}' filename  \t#取最后一列\nawk '{print $NF-1}' filename  \t#取倒数第二列\n```\n\n### sed修改文本内容\n```sh\nsed 's/^/HEAD&/g' filename          #在每行的头添加字符\"HEAD\"\nsed 's/$/&TAIL/g' filename          #在每行的尾添加字符“TAIL”\nsed  's/a/b/g'  filename            #将文本中的\"a\"换成\"b\"\nsed -e 'nc/just do' filename        #把第n行替换成just do\nsed -e '1,10c/I can do' filename    #把1到10行替换成一行：I can do\n\n#\"^\"代表行首，\"$\"代表行尾，字符g代表每行出现的字符全部替换\n#如果想在原文件上更改，添加选项-i\n```\n\n### grep搜索文件内容\n#### 格式\n```shell\ngrep [options] PATTERN [FILE...]\n[options]主要参数：\n－c：只输出匹配行的计数\n－I：不区分大小写\n－h：查询多文件时不显示文件名\n－l：查询多文件时只输出包含匹配字符的文件名\n－n：显示匹配行及行号\n－v：显示不包含匹配文本的所有行\n```\n\n#### 实例\n```shell\nls -l | grep '^a'           #只显示以a开头的行\nls -l | grep '$a'           #只显示以a结尾的行\ngrep 'test' d*              #显示所有以d开头的文件中包含test的行\ngrep 'test' aa bb cc        #显示在aa，bb，cc文件中匹配test的行\ngrep '[a-z]\\{5\\}' aa        #显示aa中所有有5个连续小写字符的行\ngrep -i '^s' a              #不区分大小以s/S开头的行\ngrep ':[0-9]:' a            #两个冒号中间一个数字的行\n```\n\n### 环境变量\n```shell\necho $PATH（查看）\nexport PATH=/usr/local/bin:$PATH（临时添加）\n将export PATH=\"/usr/local/bin:$PATH\"添加到/etc/profile或者~/.bashrc，然后source一下（永久添加）\n```\n\n\n\n## vim\n\n### vim快捷键\n```shell\ne: 前移一个单词\nb: 后移一个单词\nhjkl \ngg: 到文件头部\nG: 到文件尾部\nctrl+d: 下翻半屏\nctrl+u: 上翻半屏\nd$ or D: 删除（剪切）当前位置到行尾的内容\nd0: 删除（剪切）当前位置到行首的内容\n%: 不仅能移动到匹配的(),{}或[]上，而且能在#if，#else， #endif之间跳跃\n*: 向下搜索光标所在词\n```\n\n### 多行缩进\n```sh\n1 //在这里按下'v'进入选择模式\n2 ...\n3 //光标移动到这里，再按一次大于号'>'缩进一次，按'6>'缩进六次，按'<'回缩。\n```\n\n### 多行注释\n```\n1 //在这里按下'v'进入选择模式\n2 ...\n3 //光标移动到这里，按'ctrl+v'（win下面'ctrl+q'）进入列模式\n4 //按大写'I'进入插入模式，输入注释符'#'或者是'//'，然后立刻按两下ESC。\n```\n\n### 多行取消注释\n```\n1 //在这里按下'ctrl+v'进入块选择模式\n2 ...\n3 //光标移动到这里，选中'//'或者'##'，之后按d即可。(删除)\n```\n\n## chrome快捷键\n\n- 跳转到下一个打开的标签页 ⌘ +Option+向右箭头键\n- 跳转到特定标签页 ⌘ +1 到 ⌘ +8\n","slug":"vim和shell技巧","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2i0000tly0gv8cvughy","content":"<h2 id=\"linux\"><a href=\"#linux\" class=\"headerlink\" title=\"linux\"></a>linux</h2><h3 id=\"shell快捷键\"><a href=\"#shell快捷键\" class=\"headerlink\" title=\"shell快捷键\"></a>shell快捷键</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctrl+a:\t\t移到行首</span><br><span class=\"line\">ctrl+e:\t\t移到行尾</span><br><span class=\"line\">ctrl+xx:\t行首到当前光标替换</span><br><span class=\"line\">ctrl+w:\t\t删除光标前一个单词相当于vim里db</span><br><span class=\"line\">ctrl+h:\t\t删除光标前一个字符（相当于backspace）</span><br><span class=\"line\">ctrl+d: \t删除光标后一个字符（相当于delete）</span><br><span class=\"line\">ctrl+u: \t删除光标左边所有</span><br><span class=\"line\">ctrl+k: \t删除光标右边所有</span><br><span class=\"line\">ctrl+l: \t清屏</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h3 id=\"awk获取文本某列\"><a href=\"#awk获取文本某列\" class=\"headerlink\" title=\"awk获取文本某列\"></a>awk获取文本某列</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">awk <span class=\"string\">'&#123;print $0&#125;'</span> filename    \t<span class=\"comment\">#完整的文件内容</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $1&#125;'</span> filename    \t<span class=\"comment\">#取第一列</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $1,$2&#125;'</span> filename \t<span class=\"comment\">#取前两列</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $NF&#125;'</span> filename  \t<span class=\"comment\">#取最后一列</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $NF-1&#125;'</span> filename  \t<span class=\"comment\">#取倒数第二列</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"sed修改文本内容\"><a href=\"#sed修改文本内容\" class=\"headerlink\" title=\"sed修改文本内容\"></a>sed修改文本内容</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed <span class=\"string\">'s/^/HEAD&amp;/g'</span> filename          <span class=\"comment\">#在每行的头添加字符\"HEAD\"</span></span><br><span class=\"line\">sed <span class=\"string\">'s/$/&amp;TAIL/g'</span> filename          <span class=\"comment\">#在每行的尾添加字符“TAIL”</span></span><br><span class=\"line\">sed  <span class=\"string\">'s/a/b/g'</span>  filename            <span class=\"comment\">#将文本中的\"a\"换成\"b\"</span></span><br><span class=\"line\">sed -e <span class=\"string\">'nc/just do'</span> filename        <span class=\"comment\">#把第n行替换成just do</span></span><br><span class=\"line\">sed -e <span class=\"string\">'1,10c/I can do'</span> filename    <span class=\"comment\">#把1到10行替换成一行：I can do</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#\"^\"代表行首，\"$\"代表行尾，字符g代表每行出现的字符全部替换</span></span><br><span class=\"line\"><span class=\"comment\">#如果想在原文件上更改，添加选项-i</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"grep搜索文件内容\"><a href=\"#grep搜索文件内容\" class=\"headerlink\" title=\"grep搜索文件内容\"></a>grep搜索文件内容</h3><h4 id=\"格式\"><a href=\"#格式\" class=\"headerlink\" title=\"格式\"></a>格式</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep [options] PATTERN [FILE...]</span><br><span class=\"line\">[options]主要参数：</span><br><span class=\"line\">－c：只输出匹配行的计数</span><br><span class=\"line\">－I：不区分大小写</span><br><span class=\"line\">－h：查询多文件时不显示文件名</span><br><span class=\"line\">－l：查询多文件时只输出包含匹配字符的文件名</span><br><span class=\"line\">－n：显示匹配行及行号</span><br><span class=\"line\">－v：显示不包含匹配文本的所有行</span><br></pre></td></tr></table></figure>\n<h4 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls -l | grep '^a'           #只显示以a开头的行</span><br><span class=\"line\">ls -l | grep '$a'           #只显示以a结尾的行</span><br><span class=\"line\">grep 'test' d*              #显示所有以d开头的文件中包含test的行</span><br><span class=\"line\">grep 'test' aa bb cc        #显示在aa，bb，cc文件中匹配test的行</span><br><span class=\"line\">grep '[a-z]\\&#123;5\\&#125;' aa        #显示aa中所有有5个连续小写字符的行</span><br><span class=\"line\">grep -i '^s' a              #不区分大小以s/S开头的行</span><br><span class=\"line\">grep ':[0-9]:' a            #两个冒号中间一个数字的行</span><br></pre></td></tr></table></figure>\n<h3 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a>环境变量</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo $PATH（查看）</span><br><span class=\"line\">export PATH=/usr/local/bin:$PATH（临时添加）</span><br><span class=\"line\">将export PATH=\"/usr/local/bin:$PATH\"添加到/etc/profile或者~/.bashrc，然后source一下（永久添加）</span><br></pre></td></tr></table></figure>\n<h2 id=\"vim\"><a href=\"#vim\" class=\"headerlink\" title=\"vim\"></a>vim</h2><h3 id=\"vim快捷键\"><a href=\"#vim快捷键\" class=\"headerlink\" title=\"vim快捷键\"></a>vim快捷键</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">e: 前移一个单词</span><br><span class=\"line\">b: 后移一个单词</span><br><span class=\"line\">hjkl </span><br><span class=\"line\">gg: 到文件头部</span><br><span class=\"line\">G: 到文件尾部</span><br><span class=\"line\">ctrl+d: 下翻半屏</span><br><span class=\"line\">ctrl+u: 上翻半屏</span><br><span class=\"line\"><span class=\"meta\">d$</span><span class=\"bash\"> or D: 删除（剪切）当前位置到行尾的内容</span></span><br><span class=\"line\">d0: 删除（剪切）当前位置到行首的内容</span><br><span class=\"line\"><span class=\"meta\">%</span><span class=\"bash\">: 不仅能移动到匹配的(),&#123;&#125;或[]上，而且能在<span class=\"comment\">#if，#else， #endif之间跳跃</span></span></span><br><span class=\"line\">*: 向下搜索光标所在词</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行缩进\"><a href=\"#多行缩进\" class=\"headerlink\" title=\"多行缩进\"></a>多行缩进</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 //在这里按下<span class=\"string\">'v'</span>进入选择模式</span><br><span class=\"line\">2 ...</span><br><span class=\"line\">3 //光标移动到这里，再按一次大于号<span class=\"string\">'&gt;'</span>缩进一次，按<span class=\"string\">'6&gt;'</span>缩进六次，按<span class=\"string\">'&lt;'</span>回缩。</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行注释\"><a href=\"#多行注释\" class=\"headerlink\" title=\"多行注释\"></a>多行注释</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 //在这里按下&apos;v&apos;进入选择模式</span><br><span class=\"line\">2 ...</span><br><span class=\"line\">3 //光标移动到这里，按&apos;ctrl+v&apos;（win下面&apos;ctrl+q&apos;）进入列模式</span><br><span class=\"line\">4 //按大写&apos;I&apos;进入插入模式，输入注释符&apos;#&apos;或者是&apos;//&apos;，然后立刻按两下ESC。</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行取消注释\"><a href=\"#多行取消注释\" class=\"headerlink\" title=\"多行取消注释\"></a>多行取消注释</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 //在这里按下&apos;ctrl+v&apos;进入块选择模式</span><br><span class=\"line\">2 ...</span><br><span class=\"line\">3 //光标移动到这里，选中&apos;//&apos;或者&apos;##&apos;，之后按d即可。(删除)</span><br></pre></td></tr></table></figure>\n<h2 id=\"chrome快捷键\"><a href=\"#chrome快捷键\" class=\"headerlink\" title=\"chrome快捷键\"></a>chrome快捷键</h2><ul>\n<li>跳转到下一个打开的标签页 ⌘ +Option+向右箭头键</li>\n<li>跳转到特定标签页 ⌘ +1 到 ⌘ +8</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"linux\"><a href=\"#linux\" class=\"headerlink\" title=\"linux\"></a>linux</h2><h3 id=\"shell快捷键\"><a href=\"#shell快捷键\" class=\"headerlink\" title=\"shell快捷键\"></a>shell快捷键</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctrl+a:\t\t移到行首</span><br><span class=\"line\">ctrl+e:\t\t移到行尾</span><br><span class=\"line\">ctrl+xx:\t行首到当前光标替换</span><br><span class=\"line\">ctrl+w:\t\t删除光标前一个单词相当于vim里db</span><br><span class=\"line\">ctrl+h:\t\t删除光标前一个字符（相当于backspace）</span><br><span class=\"line\">ctrl+d: \t删除光标后一个字符（相当于delete）</span><br><span class=\"line\">ctrl+u: \t删除光标左边所有</span><br><span class=\"line\">ctrl+k: \t删除光标右边所有</span><br><span class=\"line\">ctrl+l: \t清屏</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"awk获取文本某列\"><a href=\"#awk获取文本某列\" class=\"headerlink\" title=\"awk获取文本某列\"></a>awk获取文本某列</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">awk <span class=\"string\">'&#123;print $0&#125;'</span> filename    \t<span class=\"comment\">#完整的文件内容</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $1&#125;'</span> filename    \t<span class=\"comment\">#取第一列</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $1,$2&#125;'</span> filename \t<span class=\"comment\">#取前两列</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $NF&#125;'</span> filename  \t<span class=\"comment\">#取最后一列</span></span><br><span class=\"line\">awk <span class=\"string\">'&#123;print $NF-1&#125;'</span> filename  \t<span class=\"comment\">#取倒数第二列</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"sed修改文本内容\"><a href=\"#sed修改文本内容\" class=\"headerlink\" title=\"sed修改文本内容\"></a>sed修改文本内容</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed <span class=\"string\">'s/^/HEAD&amp;/g'</span> filename          <span class=\"comment\">#在每行的头添加字符\"HEAD\"</span></span><br><span class=\"line\">sed <span class=\"string\">'s/$/&amp;TAIL/g'</span> filename          <span class=\"comment\">#在每行的尾添加字符“TAIL”</span></span><br><span class=\"line\">sed  <span class=\"string\">'s/a/b/g'</span>  filename            <span class=\"comment\">#将文本中的\"a\"换成\"b\"</span></span><br><span class=\"line\">sed -e <span class=\"string\">'nc/just do'</span> filename        <span class=\"comment\">#把第n行替换成just do</span></span><br><span class=\"line\">sed -e <span class=\"string\">'1,10c/I can do'</span> filename    <span class=\"comment\">#把1到10行替换成一行：I can do</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#\"^\"代表行首，\"$\"代表行尾，字符g代表每行出现的字符全部替换</span></span><br><span class=\"line\"><span class=\"comment\">#如果想在原文件上更改，添加选项-i</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"grep搜索文件内容\"><a href=\"#grep搜索文件内容\" class=\"headerlink\" title=\"grep搜索文件内容\"></a>grep搜索文件内容</h3><h4 id=\"格式\"><a href=\"#格式\" class=\"headerlink\" title=\"格式\"></a>格式</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep [options] PATTERN [FILE...]</span><br><span class=\"line\">[options]主要参数：</span><br><span class=\"line\">－c：只输出匹配行的计数</span><br><span class=\"line\">－I：不区分大小写</span><br><span class=\"line\">－h：查询多文件时不显示文件名</span><br><span class=\"line\">－l：查询多文件时只输出包含匹配字符的文件名</span><br><span class=\"line\">－n：显示匹配行及行号</span><br><span class=\"line\">－v：显示不包含匹配文本的所有行</span><br></pre></td></tr></table></figure>\n<h4 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls -l | grep '^a'           #只显示以a开头的行</span><br><span class=\"line\">ls -l | grep '$a'           #只显示以a结尾的行</span><br><span class=\"line\">grep 'test' d*              #显示所有以d开头的文件中包含test的行</span><br><span class=\"line\">grep 'test' aa bb cc        #显示在aa，bb，cc文件中匹配test的行</span><br><span class=\"line\">grep '[a-z]\\&#123;5\\&#125;' aa        #显示aa中所有有5个连续小写字符的行</span><br><span class=\"line\">grep -i '^s' a              #不区分大小以s/S开头的行</span><br><span class=\"line\">grep ':[0-9]:' a            #两个冒号中间一个数字的行</span><br></pre></td></tr></table></figure>\n<h3 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a>环境变量</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo $PATH（查看）</span><br><span class=\"line\">export PATH=/usr/local/bin:$PATH（临时添加）</span><br><span class=\"line\">将export PATH=\"/usr/local/bin:$PATH\"添加到/etc/profile或者~/.bashrc，然后source一下（永久添加）</span><br></pre></td></tr></table></figure>\n<h2 id=\"vim\"><a href=\"#vim\" class=\"headerlink\" title=\"vim\"></a>vim</h2><h3 id=\"vim快捷键\"><a href=\"#vim快捷键\" class=\"headerlink\" title=\"vim快捷键\"></a>vim快捷键</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">e: 前移一个单词</span><br><span class=\"line\">b: 后移一个单词</span><br><span class=\"line\">hjkl </span><br><span class=\"line\">gg: 到文件头部</span><br><span class=\"line\">G: 到文件尾部</span><br><span class=\"line\">ctrl+d: 下翻半屏</span><br><span class=\"line\">ctrl+u: 上翻半屏</span><br><span class=\"line\"><span class=\"meta\">d$</span><span class=\"bash\"> or D: 删除（剪切）当前位置到行尾的内容</span></span><br><span class=\"line\">d0: 删除（剪切）当前位置到行首的内容</span><br><span class=\"line\"><span class=\"meta\">%</span><span class=\"bash\">: 不仅能移动到匹配的(),&#123;&#125;或[]上，而且能在<span class=\"comment\">#if，#else， #endif之间跳跃</span></span></span><br><span class=\"line\">*: 向下搜索光标所在词</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行缩进\"><a href=\"#多行缩进\" class=\"headerlink\" title=\"多行缩进\"></a>多行缩进</h3><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 //在这里按下<span class=\"string\">'v'</span>进入选择模式</span><br><span class=\"line\">2 ...</span><br><span class=\"line\">3 //光标移动到这里，再按一次大于号<span class=\"string\">'&gt;'</span>缩进一次，按<span class=\"string\">'6&gt;'</span>缩进六次，按<span class=\"string\">'&lt;'</span>回缩。</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行注释\"><a href=\"#多行注释\" class=\"headerlink\" title=\"多行注释\"></a>多行注释</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 //在这里按下&apos;v&apos;进入选择模式</span><br><span class=\"line\">2 ...</span><br><span class=\"line\">3 //光标移动到这里，按&apos;ctrl+v&apos;（win下面&apos;ctrl+q&apos;）进入列模式</span><br><span class=\"line\">4 //按大写&apos;I&apos;进入插入模式，输入注释符&apos;#&apos;或者是&apos;//&apos;，然后立刻按两下ESC。</span><br></pre></td></tr></table></figure>\n<h3 id=\"多行取消注释\"><a href=\"#多行取消注释\" class=\"headerlink\" title=\"多行取消注释\"></a>多行取消注释</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 //在这里按下&apos;ctrl+v&apos;进入块选择模式</span><br><span class=\"line\">2 ...</span><br><span class=\"line\">3 //光标移动到这里，选中&apos;//&apos;或者&apos;##&apos;，之后按d即可。(删除)</span><br></pre></td></tr></table></figure>\n<h2 id=\"chrome快捷键\"><a href=\"#chrome快捷键\" class=\"headerlink\" title=\"chrome快捷键\"></a>chrome快捷键</h2><ul>\n<li>跳转到下一个打开的标签页 ⌘ +Option+向右箭头键</li>\n<li>跳转到特定标签页 ⌘ +1 到 ⌘ +8</li>\n</ul>"},{"title":"viterbi以及forward-backword算法","author":"liuyan","catalog":true,"date":"2019-01-07T09:05:01.000Z","urlname":null,"_content":"\n### viterbi算法\n\n维特比算法说白了就是动态规划实现最短路径，只要知道动态规划是通过空间换时间的一种方法就可以了。HMM的解码部分使用的是viterbi算法。\n\n![](1.png)\n\n假设上图每一列分别有$ n _ {1},...,n _ {n} $个节点，如果不使用动态的话，那么计算最短路径的时间复杂度就是$ O(n _ {1} \\* n _ {2} \\* ... \\* n _ {n}) $。\n\n维特比算法的精髓就是，既然知道到第i列所有节点Xj{j=1,2,3…}的最短路径，那么到第i+1列节点的最短路径就等于到第i列j个节点的最短路径+第i列j个节点到第i+1列各个节点的距离的最小值。\n\n分析一下复杂度，假设整个有向无环图中每一列节点最多有D个（也就是图的宽度为D），并且图一共有N列，那么，每次计算至多计算D\\*D次（i列的D个节点到i+1列D个节点的距离）。至多计算N次。那么时间复杂度为O（ND^2），远远小于穷举法O（D^N）。\n\n<!-- more -->\n\n### 前向后向算法\n\n#### 前向算法\n\n##### 前向概率\n\n> **定义**：给定隐尔马科夫模型$ \\lambda $，定义到时刻t为止的观测序列为$ o _ {1},o _ {2},...,o _ {t} $且状态为$ q _ {i} $的概率为前向概率，记作：\n\n$$\n\\alpha _ { t } ( i ) = P \\left( o _ { 1 } , o _ { 2 } , \\cdots , o _ { t } , i _ { t } = q _ { i } | \\lambda \\right)\n$$\n\n可以递推地求得前向概率$ \\alpha _ {t} (i) $及观测序列概率$ p(o|\\alpha ) $。\n\n##### 算法流程\n\n输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $。\n\n输出：观测序列概率$ p(o|\\alpha ) $。\n\n1. 初始值\n\n$$\n\\alpha _ { 1 } ( i ) = \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) , \\quad i = 1,2 , \\cdots , N\n$$\n\n分别为初始状态概率，发射概率。\n\n2. 递推公式\n\n$$\n\\alpha _ { t + 1 } ( i ) = \\left[ \\sum _ { j = 1 } ^ { N } \\alpha _ { t } ( j ) a _ { ji } \\right] b _ { i } \\left( o _ { t + 1 } \\right) , \\quad i = 1,2 , \\cdots , N\n$$\n\n大括号里面代表上层所有节点到该层特定节点的连接，然后乘以发射概率。\n\n3. 终止\n\n$$\nP ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\alpha _ { T } ( i )\n$$\n\n由于到了时间T，一共有N种状态发射了最后那个观测，所以最终的结果要将这些概率加起来。\n\n#### 后向算法\n\n##### 后向概率\n\n> **定义**：给定隐马尔可夫模型$ \\lambda $，定义在时刻t状态为$ q _ {i} $的条件下，从t+1到T的部分观测序列为$ o _ {t+1}, o _ {t+2},...,o _ {T} $的概率为**后向概率**，记作：\n\n$$\n\\beta _ { i } ( i ) = P \\left( o _ { i + 1 } , o _ { i + 2 } , \\cdots , o _ { T } | i _ { t } = q _ { i } , \\lambda \\right)\n$$\n\n可以用递推的方法求得后向概率,$ \\beta _ {t} (i) $及观测序列概率$ p(o|\\lambda ) $。\n\n##### 算法流程\n\n输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $\n\n输出：观测序列概率$ p(o|\\lambda ) $\n\n1. 初始值\n\n$$\n\\beta _ { T } ( i ) = 1 , \\quad i = 1,2 , \\cdots , N\n$$\n\n根据定义，从T+1到T的部分观测序列其实不存在，所以硬性规定这个值是1。\n\n2. 递推公式\n\n$$\n\\beta _ { t } ( i ) = \\sum _ { j = 1 } ^ { N } a _ { ij } b _ { j } \\left( o _ { t+1 } \\right) \\beta _ { t + 1} ( j ) , \\quad i = 1,2 , \\cdots , N\n$$\n\n$ a _ {ij} $表示状态i转移到j的概率，$ b _ {j} $表示发射$ o _ {t+1} $，$ \\beta _ {t+1} (j) $表示j后面的序列对应的后向概率。\n\n3. 终止\n\n$$\nP ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) \\beta _ { 1 } ( i )\n$$\n\n最后的求和是因为，在第一个时间点上有N种后向概率都能输出从2到T的观测序列，所以乘上输出O1的概率后求和得到最终结果。\n\n\n![](2.png)\n\n### HMM模型的三个基本问题\n\n- 给定一个模型，如何计算某个特定的输出序列的概率？ \n    **Forward-Backward算法**\n\n- 给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列？\n    **维特比算法**\n\n- 给定足够量的观测数据，如何估计隐含马尔可夫模型的参数？\n    **baum-welch算法**\n","source":"_posts/viterbi以及forward-backword算法.md","raw":"---\ntitle:      viterbi以及forward-backword算法\nauthor:     liuyan\ncatalog:    true\ntags:\n  - 语音识别\n  - viterbi\ndate:       2019-01-07 17:05:01\nurlname:\ncategories: 语音识别\n---\n\n### viterbi算法\n\n维特比算法说白了就是动态规划实现最短路径，只要知道动态规划是通过空间换时间的一种方法就可以了。HMM的解码部分使用的是viterbi算法。\n\n![](1.png)\n\n假设上图每一列分别有$ n _ {1},...,n _ {n} $个节点，如果不使用动态的话，那么计算最短路径的时间复杂度就是$ O(n _ {1} \\* n _ {2} \\* ... \\* n _ {n}) $。\n\n维特比算法的精髓就是，既然知道到第i列所有节点Xj{j=1,2,3…}的最短路径，那么到第i+1列节点的最短路径就等于到第i列j个节点的最短路径+第i列j个节点到第i+1列各个节点的距离的最小值。\n\n分析一下复杂度，假设整个有向无环图中每一列节点最多有D个（也就是图的宽度为D），并且图一共有N列，那么，每次计算至多计算D\\*D次（i列的D个节点到i+1列D个节点的距离）。至多计算N次。那么时间复杂度为O（ND^2），远远小于穷举法O（D^N）。\n\n<!-- more -->\n\n### 前向后向算法\n\n#### 前向算法\n\n##### 前向概率\n\n> **定义**：给定隐尔马科夫模型$ \\lambda $，定义到时刻t为止的观测序列为$ o _ {1},o _ {2},...,o _ {t} $且状态为$ q _ {i} $的概率为前向概率，记作：\n\n$$\n\\alpha _ { t } ( i ) = P \\left( o _ { 1 } , o _ { 2 } , \\cdots , o _ { t } , i _ { t } = q _ { i } | \\lambda \\right)\n$$\n\n可以递推地求得前向概率$ \\alpha _ {t} (i) $及观测序列概率$ p(o|\\alpha ) $。\n\n##### 算法流程\n\n输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $。\n\n输出：观测序列概率$ p(o|\\alpha ) $。\n\n1. 初始值\n\n$$\n\\alpha _ { 1 } ( i ) = \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) , \\quad i = 1,2 , \\cdots , N\n$$\n\n分别为初始状态概率，发射概率。\n\n2. 递推公式\n\n$$\n\\alpha _ { t + 1 } ( i ) = \\left[ \\sum _ { j = 1 } ^ { N } \\alpha _ { t } ( j ) a _ { ji } \\right] b _ { i } \\left( o _ { t + 1 } \\right) , \\quad i = 1,2 , \\cdots , N\n$$\n\n大括号里面代表上层所有节点到该层特定节点的连接，然后乘以发射概率。\n\n3. 终止\n\n$$\nP ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\alpha _ { T } ( i )\n$$\n\n由于到了时间T，一共有N种状态发射了最后那个观测，所以最终的结果要将这些概率加起来。\n\n#### 后向算法\n\n##### 后向概率\n\n> **定义**：给定隐马尔可夫模型$ \\lambda $，定义在时刻t状态为$ q _ {i} $的条件下，从t+1到T的部分观测序列为$ o _ {t+1}, o _ {t+2},...,o _ {T} $的概率为**后向概率**，记作：\n\n$$\n\\beta _ { i } ( i ) = P \\left( o _ { i + 1 } , o _ { i + 2 } , \\cdots , o _ { T } | i _ { t } = q _ { i } , \\lambda \\right)\n$$\n\n可以用递推的方法求得后向概率,$ \\beta _ {t} (i) $及观测序列概率$ p(o|\\lambda ) $。\n\n##### 算法流程\n\n输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $\n\n输出：观测序列概率$ p(o|\\lambda ) $\n\n1. 初始值\n\n$$\n\\beta _ { T } ( i ) = 1 , \\quad i = 1,2 , \\cdots , N\n$$\n\n根据定义，从T+1到T的部分观测序列其实不存在，所以硬性规定这个值是1。\n\n2. 递推公式\n\n$$\n\\beta _ { t } ( i ) = \\sum _ { j = 1 } ^ { N } a _ { ij } b _ { j } \\left( o _ { t+1 } \\right) \\beta _ { t + 1} ( j ) , \\quad i = 1,2 , \\cdots , N\n$$\n\n$ a _ {ij} $表示状态i转移到j的概率，$ b _ {j} $表示发射$ o _ {t+1} $，$ \\beta _ {t+1} (j) $表示j后面的序列对应的后向概率。\n\n3. 终止\n\n$$\nP ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) \\beta _ { 1 } ( i )\n$$\n\n最后的求和是因为，在第一个时间点上有N种后向概率都能输出从2到T的观测序列，所以乘上输出O1的概率后求和得到最终结果。\n\n\n![](2.png)\n\n### HMM模型的三个基本问题\n\n- 给定一个模型，如何计算某个特定的输出序列的概率？ \n    **Forward-Backward算法**\n\n- 给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列？\n    **维特比算法**\n\n- 给定足够量的观测数据，如何估计隐含马尔可夫模型的参数？\n    **baum-welch算法**\n","slug":"viterbi以及forward-backword算法","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2i2000wly0gbuca4juk","content":"<h3 id=\"viterbi算法\"><a href=\"#viterbi算法\" class=\"headerlink\" title=\"viterbi算法\"></a>viterbi算法</h3><p>维特比算法说白了就是动态规划实现最短路径，只要知道动态规划是通过空间换时间的一种方法就可以了。HMM的解码部分使用的是viterbi算法。</p>\n<p><img src=\"/2019/01/07/viterbi以及forward-backword算法/1.png\" alt=\"\"></p>\n<p>假设上图每一列分别有$ n _ {1},…,n _ {n} $个节点，如果不使用动态的话，那么计算最短路径的时间复杂度就是$ O(n _ {1} * n _ {2} * … * n _ {n}) $。</p>\n<p>维特比算法的精髓就是，既然知道到第i列所有节点Xj{j=1,2,3…}的最短路径，那么到第i+1列节点的最短路径就等于到第i列j个节点的最短路径+第i列j个节点到第i+1列各个节点的距离的最小值。</p>\n<p>分析一下复杂度，假设整个有向无环图中每一列节点最多有D个（也就是图的宽度为D），并且图一共有N列，那么，每次计算至多计算D*D次（i列的D个节点到i+1列D个节点的距离）。至多计算N次。那么时间复杂度为O（ND^2），远远小于穷举法O（D^N）。</p>\n<a id=\"more\"></a>\n<h3 id=\"前向后向算法\"><a href=\"#前向后向算法\" class=\"headerlink\" title=\"前向后向算法\"></a>前向后向算法</h3><h4 id=\"前向算法\"><a href=\"#前向算法\" class=\"headerlink\" title=\"前向算法\"></a>前向算法</h4><h5 id=\"前向概率\"><a href=\"#前向概率\" class=\"headerlink\" title=\"前向概率\"></a>前向概率</h5><blockquote>\n<p><strong>定义</strong>：给定隐尔马科夫模型$ \\lambda $，定义到时刻t为止的观测序列为$ o _ {1},o _ {2},…,o _ {t} $且状态为$ q _ {i} $的概率为前向概率，记作：</p>\n</blockquote>\n<p>$$<br>\\alpha _ { t } ( i ) = P \\left( o _ { 1 } , o _ { 2 } , \\cdots , o _ { t } , i _ { t } = q _ { i } | \\lambda \\right)<br>$$</p>\n<p>可以递推地求得前向概率$ \\alpha _ {t} (i) $及观测序列概率$ p(o|\\alpha ) $。</p>\n<h5 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h5><p>输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $。</p>\n<p>输出：观测序列概率$ p(o|\\alpha ) $。</p>\n<ol>\n<li>初始值</li>\n</ol>\n<p>$$<br>\\alpha _ { 1 } ( i ) = \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>分别为初始状态概率，发射概率。</p>\n<ol start=\"2\">\n<li>递推公式</li>\n</ol>\n<p>$$<br>\\alpha _ { t + 1 } ( i ) = \\left[ \\sum _ { j = 1 } ^ { N } \\alpha _ { t } ( j ) a _ { ji } \\right] b _ { i } \\left( o _ { t + 1 } \\right) , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>大括号里面代表上层所有节点到该层特定节点的连接，然后乘以发射概率。</p>\n<ol start=\"3\">\n<li>终止</li>\n</ol>\n<p>$$<br>P ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\alpha _ { T } ( i )<br>$$</p>\n<p>由于到了时间T，一共有N种状态发射了最后那个观测，所以最终的结果要将这些概率加起来。</p>\n<h4 id=\"后向算法\"><a href=\"#后向算法\" class=\"headerlink\" title=\"后向算法\"></a>后向算法</h4><h5 id=\"后向概率\"><a href=\"#后向概率\" class=\"headerlink\" title=\"后向概率\"></a>后向概率</h5><blockquote>\n<p><strong>定义</strong>：给定隐马尔可夫模型$ \\lambda $，定义在时刻t状态为$ q _ {i} $的条件下，从t+1到T的部分观测序列为$ o _ {t+1}, o _ {t+2},…,o _ {T} $的概率为<strong>后向概率</strong>，记作：</p>\n</blockquote>\n<p>$$<br>\\beta _ { i } ( i ) = P \\left( o _ { i + 1 } , o _ { i + 2 } , \\cdots , o _ { T } | i _ { t } = q _ { i } , \\lambda \\right)<br>$$</p>\n<p>可以用递推的方法求得后向概率,$ \\beta _ {t} (i) $及观测序列概率$ p(o|\\lambda ) $。</p>\n<h5 id=\"算法流程-1\"><a href=\"#算法流程-1\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h5><p>输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $</p>\n<p>输出：观测序列概率$ p(o|\\lambda ) $</p>\n<ol>\n<li>初始值</li>\n</ol>\n<p>$$<br>\\beta _ { T } ( i ) = 1 , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>根据定义，从T+1到T的部分观测序列其实不存在，所以硬性规定这个值是1。</p>\n<ol start=\"2\">\n<li>递推公式</li>\n</ol>\n<p>$$<br>\\beta _ { t } ( i ) = \\sum _ { j = 1 } ^ { N } a _ { ij } b _ { j } \\left( o _ { t+1 } \\right) \\beta _ { t + 1} ( j ) , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>$ a _ {ij} $表示状态i转移到j的概率，$ b _ {j} $表示发射$ o _ {t+1} $，$ \\beta _ {t+1} (j) $表示j后面的序列对应的后向概率。</p>\n<ol start=\"3\">\n<li>终止</li>\n</ol>\n<p>$$<br>P ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) \\beta _ { 1 } ( i )<br>$$</p>\n<p>最后的求和是因为，在第一个时间点上有N种后向概率都能输出从2到T的观测序列，所以乘上输出O1的概率后求和得到最终结果。</p>\n<p><img src=\"/2019/01/07/viterbi以及forward-backword算法/2.png\" alt=\"\"></p>\n<h3 id=\"HMM模型的三个基本问题\"><a href=\"#HMM模型的三个基本问题\" class=\"headerlink\" title=\"HMM模型的三个基本问题\"></a>HMM模型的三个基本问题</h3><ul>\n<li><p>给定一个模型，如何计算某个特定的输出序列的概率？<br>  <strong>Forward-Backward算法</strong></p>\n</li>\n<li><p>给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列？<br>  <strong>维特比算法</strong></p>\n</li>\n<li><p>给定足够量的观测数据，如何估计隐含马尔可夫模型的参数？<br>  <strong>baum-welch算法</strong></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h3 id=\"viterbi算法\"><a href=\"#viterbi算法\" class=\"headerlink\" title=\"viterbi算法\"></a>viterbi算法</h3><p>维特比算法说白了就是动态规划实现最短路径，只要知道动态规划是通过空间换时间的一种方法就可以了。HMM的解码部分使用的是viterbi算法。</p>\n<p><img src=\"/2019/01/07/viterbi以及forward-backword算法/1.png\" alt=\"\"></p>\n<p>假设上图每一列分别有$ n _ {1},…,n _ {n} $个节点，如果不使用动态的话，那么计算最短路径的时间复杂度就是$ O(n _ {1} * n _ {2} * … * n _ {n}) $。</p>\n<p>维特比算法的精髓就是，既然知道到第i列所有节点Xj{j=1,2,3…}的最短路径，那么到第i+1列节点的最短路径就等于到第i列j个节点的最短路径+第i列j个节点到第i+1列各个节点的距离的最小值。</p>\n<p>分析一下复杂度，假设整个有向无环图中每一列节点最多有D个（也就是图的宽度为D），并且图一共有N列，那么，每次计算至多计算D*D次（i列的D个节点到i+1列D个节点的距离）。至多计算N次。那么时间复杂度为O（ND^2），远远小于穷举法O（D^N）。</p>","more":"<h3 id=\"前向后向算法\"><a href=\"#前向后向算法\" class=\"headerlink\" title=\"前向后向算法\"></a>前向后向算法</h3><h4 id=\"前向算法\"><a href=\"#前向算法\" class=\"headerlink\" title=\"前向算法\"></a>前向算法</h4><h5 id=\"前向概率\"><a href=\"#前向概率\" class=\"headerlink\" title=\"前向概率\"></a>前向概率</h5><blockquote>\n<p><strong>定义</strong>：给定隐尔马科夫模型$ \\lambda $，定义到时刻t为止的观测序列为$ o _ {1},o _ {2},…,o _ {t} $且状态为$ q _ {i} $的概率为前向概率，记作：</p>\n</blockquote>\n<p>$$<br>\\alpha _ { t } ( i ) = P \\left( o _ { 1 } , o _ { 2 } , \\cdots , o _ { t } , i _ { t } = q _ { i } | \\lambda \\right)<br>$$</p>\n<p>可以递推地求得前向概率$ \\alpha _ {t} (i) $及观测序列概率$ p(o|\\alpha ) $。</p>\n<h5 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h5><p>输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $。</p>\n<p>输出：观测序列概率$ p(o|\\alpha ) $。</p>\n<ol>\n<li>初始值</li>\n</ol>\n<p>$$<br>\\alpha _ { 1 } ( i ) = \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>分别为初始状态概率，发射概率。</p>\n<ol start=\"2\">\n<li>递推公式</li>\n</ol>\n<p>$$<br>\\alpha _ { t + 1 } ( i ) = \\left[ \\sum _ { j = 1 } ^ { N } \\alpha _ { t } ( j ) a _ { ji } \\right] b _ { i } \\left( o _ { t + 1 } \\right) , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>大括号里面代表上层所有节点到该层特定节点的连接，然后乘以发射概率。</p>\n<ol start=\"3\">\n<li>终止</li>\n</ol>\n<p>$$<br>P ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\alpha _ { T } ( i )<br>$$</p>\n<p>由于到了时间T，一共有N种状态发射了最后那个观测，所以最终的结果要将这些概率加起来。</p>\n<h4 id=\"后向算法\"><a href=\"#后向算法\" class=\"headerlink\" title=\"后向算法\"></a>后向算法</h4><h5 id=\"后向概率\"><a href=\"#后向概率\" class=\"headerlink\" title=\"后向概率\"></a>后向概率</h5><blockquote>\n<p><strong>定义</strong>：给定隐马尔可夫模型$ \\lambda $，定义在时刻t状态为$ q _ {i} $的条件下，从t+1到T的部分观测序列为$ o _ {t+1}, o _ {t+2},…,o _ {T} $的概率为<strong>后向概率</strong>，记作：</p>\n</blockquote>\n<p>$$<br>\\beta _ { i } ( i ) = P \\left( o _ { i + 1 } , o _ { i + 2 } , \\cdots , o _ { T } | i _ { t } = q _ { i } , \\lambda \\right)<br>$$</p>\n<p>可以用递推的方法求得后向概率,$ \\beta _ {t} (i) $及观测序列概率$ p(o|\\lambda ) $。</p>\n<h5 id=\"算法流程-1\"><a href=\"#算法流程-1\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h5><p>输入：隐马尔可夫模型$ \\lambda $，观测序列$ O $</p>\n<p>输出：观测序列概率$ p(o|\\lambda ) $</p>\n<ol>\n<li>初始值</li>\n</ol>\n<p>$$<br>\\beta _ { T } ( i ) = 1 , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>根据定义，从T+1到T的部分观测序列其实不存在，所以硬性规定这个值是1。</p>\n<ol start=\"2\">\n<li>递推公式</li>\n</ol>\n<p>$$<br>\\beta _ { t } ( i ) = \\sum _ { j = 1 } ^ { N } a _ { ij } b _ { j } \\left( o _ { t+1 } \\right) \\beta _ { t + 1} ( j ) , \\quad i = 1,2 , \\cdots , N<br>$$</p>\n<p>$ a _ {ij} $表示状态i转移到j的概率，$ b _ {j} $表示发射$ o _ {t+1} $，$ \\beta _ {t+1} (j) $表示j后面的序列对应的后向概率。</p>\n<ol start=\"3\">\n<li>终止</li>\n</ol>\n<p>$$<br>P ( O | \\lambda ) = \\sum _ { i = 1 } ^ { N } \\pi _ { i } b _ { i } \\left( o _ { 1 } \\right) \\beta _ { 1 } ( i )<br>$$</p>\n<p>最后的求和是因为，在第一个时间点上有N种后向概率都能输出从2到T的观测序列，所以乘上输出O1的概率后求和得到最终结果。</p>\n<p><img src=\"/2019/01/07/viterbi以及forward-backword算法/2.png\" alt=\"\"></p>\n<h3 id=\"HMM模型的三个基本问题\"><a href=\"#HMM模型的三个基本问题\" class=\"headerlink\" title=\"HMM模型的三个基本问题\"></a>HMM模型的三个基本问题</h3><ul>\n<li><p>给定一个模型，如何计算某个特定的输出序列的概率？<br>  <strong>Forward-Backward算法</strong></p>\n</li>\n<li><p>给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列？<br>  <strong>维特比算法</strong></p>\n</li>\n<li><p>给定足够量的观测数据，如何估计隐含马尔可夫模型的参数？<br>  <strong>baum-welch算法</strong></p>\n</li>\n</ul>"},{"title":"语音基础概念","author":"liuyan","catalog":true,"date":"2017-11-07T09:37:58.000Z","urlname":null,"_content":"\n### 信噪比(signal-noise ratio,SNR)\n\n信噪比定义为信号能量与噪声能量的比值，常常用分贝数(DB)表示。设备的信噪比越高表明它产生的杂音越少。一般来说，信噪比越大，说明混在信号里的噪声越小，声音回放的音质量越高，否则相反。\n\n<!-- more -->\n\n### 短时过零率\n\n短时平均过零率是语音信号时域分析中的一种特征参数。它是指每帧内信号通过零值的次数。在离散时间语音信号情况下，如果相邻的采样具有不同的代数符号就称为发生了过零，因此可以计算过零的次数。单位时间内过零的次数就称为过零率。在语音信号处理中，常将短时平均能量和短时平均过零率结合起来进行语音段起始点的检测，即**端点检测**。\n\n### 短时能量\n\n短时能量体现的是信号在不同时刻的强弱程度。\n\n### 语谱图\n\n语谱图的x是时间，y轴是频率，z轴是幅度。幅度用亮色如红色表示高，用深色表示低。利用语谱图可以查看指定频率端的能量分布。\n\n![](1.png)\n\n### wav头文件\n\n![](2.png)\n\n","source":"_posts/语音基础概念.md","raw":"---\ntitle:      语音基础概念\nauthor:     liuyan\ncatalog:    true\ntags:\n  - 语音识别\ndate:       2017-11-07 17:37:58\nurlname:\ncategories: 语音识别\n---\n\n### 信噪比(signal-noise ratio,SNR)\n\n信噪比定义为信号能量与噪声能量的比值，常常用分贝数(DB)表示。设备的信噪比越高表明它产生的杂音越少。一般来说，信噪比越大，说明混在信号里的噪声越小，声音回放的音质量越高，否则相反。\n\n<!-- more -->\n\n### 短时过零率\n\n短时平均过零率是语音信号时域分析中的一种特征参数。它是指每帧内信号通过零值的次数。在离散时间语音信号情况下，如果相邻的采样具有不同的代数符号就称为发生了过零，因此可以计算过零的次数。单位时间内过零的次数就称为过零率。在语音信号处理中，常将短时平均能量和短时平均过零率结合起来进行语音段起始点的检测，即**端点检测**。\n\n### 短时能量\n\n短时能量体现的是信号在不同时刻的强弱程度。\n\n### 语谱图\n\n语谱图的x是时间，y轴是频率，z轴是幅度。幅度用亮色如红色表示高，用深色表示低。利用语谱图可以查看指定频率端的能量分布。\n\n![](1.png)\n\n### wav头文件\n\n![](2.png)\n\n","slug":"语音基础概念","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2i3000zly0gh9lnj3z9","content":"<h3 id=\"信噪比-signal-noise-ratio-SNR\"><a href=\"#信噪比-signal-noise-ratio-SNR\" class=\"headerlink\" title=\"信噪比(signal-noise ratio,SNR)\"></a>信噪比(signal-noise ratio,SNR)</h3><p>信噪比定义为信号能量与噪声能量的比值，常常用分贝数(DB)表示。设备的信噪比越高表明它产生的杂音越少。一般来说，信噪比越大，说明混在信号里的噪声越小，声音回放的音质量越高，否则相反。</p>\n<a id=\"more\"></a>\n<h3 id=\"短时过零率\"><a href=\"#短时过零率\" class=\"headerlink\" title=\"短时过零率\"></a>短时过零率</h3><p>短时平均过零率是语音信号时域分析中的一种特征参数。它是指每帧内信号通过零值的次数。在离散时间语音信号情况下，如果相邻的采样具有不同的代数符号就称为发生了过零，因此可以计算过零的次数。单位时间内过零的次数就称为过零率。在语音信号处理中，常将短时平均能量和短时平均过零率结合起来进行语音段起始点的检测，即<strong>端点检测</strong>。</p>\n<h3 id=\"短时能量\"><a href=\"#短时能量\" class=\"headerlink\" title=\"短时能量\"></a>短时能量</h3><p>短时能量体现的是信号在不同时刻的强弱程度。</p>\n<h3 id=\"语谱图\"><a href=\"#语谱图\" class=\"headerlink\" title=\"语谱图\"></a>语谱图</h3><p>语谱图的x是时间，y轴是频率，z轴是幅度。幅度用亮色如红色表示高，用深色表示低。利用语谱图可以查看指定频率端的能量分布。</p>\n<p><img src=\"/2017/11/07/语音基础概念/1.png\" alt=\"\"></p>\n<h3 id=\"wav头文件\"><a href=\"#wav头文件\" class=\"headerlink\" title=\"wav头文件\"></a>wav头文件</h3><p><img src=\"/2017/11/07/语音基础概念/2.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"信噪比-signal-noise-ratio-SNR\"><a href=\"#信噪比-signal-noise-ratio-SNR\" class=\"headerlink\" title=\"信噪比(signal-noise ratio,SNR)\"></a>信噪比(signal-noise ratio,SNR)</h3><p>信噪比定义为信号能量与噪声能量的比值，常常用分贝数(DB)表示。设备的信噪比越高表明它产生的杂音越少。一般来说，信噪比越大，说明混在信号里的噪声越小，声音回放的音质量越高，否则相反。</p>","more":"<h3 id=\"短时过零率\"><a href=\"#短时过零率\" class=\"headerlink\" title=\"短时过零率\"></a>短时过零率</h3><p>短时平均过零率是语音信号时域分析中的一种特征参数。它是指每帧内信号通过零值的次数。在离散时间语音信号情况下，如果相邻的采样具有不同的代数符号就称为发生了过零，因此可以计算过零的次数。单位时间内过零的次数就称为过零率。在语音信号处理中，常将短时平均能量和短时平均过零率结合起来进行语音段起始点的检测，即<strong>端点检测</strong>。</p>\n<h3 id=\"短时能量\"><a href=\"#短时能量\" class=\"headerlink\" title=\"短时能量\"></a>短时能量</h3><p>短时能量体现的是信号在不同时刻的强弱程度。</p>\n<h3 id=\"语谱图\"><a href=\"#语谱图\" class=\"headerlink\" title=\"语谱图\"></a>语谱图</h3><p>语谱图的x是时间，y轴是频率，z轴是幅度。幅度用亮色如红色表示高，用深色表示低。利用语谱图可以查看指定频率端的能量分布。</p>\n<p><img src=\"/2017/11/07/语音基础概念/1.png\" alt=\"\"></p>\n<h3 id=\"wav头文件\"><a href=\"#wav头文件\" class=\"headerlink\" title=\"wav头文件\"></a>wav头文件</h3><p><img src=\"/2017/11/07/语音基础概念/2.png\" alt=\"\"></p>"},{"title":"fbank和mfcc特征提取","author":"liuyan","catalog":true,"date":"2017-10-07T13:04:11.000Z","urlname":null,"_content":"\n## 语音参数提取特征\n\n分帧 ——> 预增强 ——> 加窗 ——> 添加噪声 ——> FFT ——> Mel滤波 ——> 对数运算——> DCT\n\n### 分帧\n\n我们需要将不定长的音频切分成固定长度的小段，这一步称为分帧。一般取10-30ms为一帧，为了避免窗边界对信号的遗漏，因此对帧做偏移时候，要有帧迭(帧与帧之间需要重叠一部分)。 一般取帧长的一半作为帧移，也就是每次位移一帧的二分之一后再取下一帧，这样可以避免帧与帧之间的特性变化太大。通常的选择是25ms每帧，帧迭为10ms。接下来的操作是对单帧进行的。\n\n要分帧是因为语音信号是快速变化的，而傅里叶变换适用于分析平稳的信号。在语音识别中，一般把帧长取为10~30ms，这样一帧内既有足够多的周期，又不会变化太剧烈。每帧信号通常要与一个平滑的窗函数相乘，让帧两端平滑地衰减到零，这样可以降低傅里叶变换后旁瓣的强度，取得更高质量的频谱。帧和帧之间的时间差常常取为10ms，这样帧与帧之间会有重叠，否则，由于帧与帧连接处的信号会因为加窗而被弱化，这部分的信息就丢失了。傅里叶变换是逐帧进行的，为的是取得每一帧的频谱。一般只保留幅度谱，丢弃相位谱。\n\n<!-- more -->\n\n### 预增强 \n\n预增强以帧为单位进行，目的在于加强高频。数学公式如下：\n$$\ns ( n ) = s ( n ) - k * s ( n - 1 ) , \\quad \\forall n \\in \\mathbb { N }\n$$\nk是预增强系数，范围为[0, 1)，常用0.97，N是每一帧的长度，从公式可以看出每一帧的第一个数需要特殊处理。\n\n### 加窗 \n\n语音在长范围内是不停变动的，没有固定的特性无法做处理，所以将每一帧代入窗函数，窗外的值设定为0，其目的是消除各个帧两端可能会造成的信号不连续性。常用的窗函数有方窗、汉明窗等，根据窗函数的频域特性，常采用汉明窗，其对应的窗函数如下： \n\n$$\ns _ { n } ^ { \\prime } = ( 0.54 - 0.46 \\cos ( \\frac { 2 \\pi ( n - 1 ) } { N - 137 } ) ) s _ { n }\n$$\n\n加窗过程其实就是将data[0:n-1]与w[0:n-1]对应相乘。 \n\n注意：预增强和加窗同时使用时，要首先进行预增强\n\n### 添加随机噪声 \n\n有时候我们需要进行数据增强，会手动合成一些音频。某些人工合成(使用软件)的音频可能会造成一些数字错误，诸如underflow或者overflow。 这种情况下，通过添加随机噪声可以解决这一类问题。公式如下： \n$$\ns ( n ) = s ( n ) + q * r a n d()\n$$\nq用于控制添加噪声的强度，rand() 产生\\[ -1.0, 1.0 )的随机数。 \n\n注意：Kaldi中是在分帧之后的下一步添加随机噪声\n\n\n## fbank\n\n人耳对声音频谱的响应是非线性的，经验表明：如果我们能够设计一种前端处理算法，以类似于人耳的方式对音频进行处理，可以提高语音识别的性能。FilterBank就是这样的一种算法。FBank特征提取要在预处理之后进行，这时语音已经分帧，我们需要逐帧提取FBank特征。\n\n\n### 快速傅里叶变换(fft) \n\n我们分帧之后得到的仍然是时域信号，为了提取fbank特征，首先需要将时域信号转换为频域信号。傅里叶变换可以将信号从时域转到频域。傅里叶变换可以分为连续傅里叶变换和离散傅里叶变换，因为我们用的是数字音频（而非模拟音频），所以我们用到的是离散傅里叶变换。数学公式如下：\n$$\nX ( k ) = \\sum _ { j = 1 } ^ { N } x ( j ) w _ { N } ^ { ( j - 1 ) ( k - 1 ) }\n$$\n公式比较难以理解，可以想象一下傅里叶级数，一个函数可以用其他基本函数组合逼近。从公式可以看出，傅里叶变化的计算复杂度较高，因此我们通常使用的是快速傅里叶变换（fft）。\n\n信号频率 : 组合产生复杂信号的简单信号的频率，通常简单信号平率范围很广\n\n采样频率 : 模拟到数字的转换过程中，需要对模拟信号进行采样，每秒内的采样点数量就是采样频率\n\nNyquist定理(奈奎斯特): 如果想要从数字信号无损转到模拟信号，我们需要以最高信号频率的2倍的采样频率进行采样。通常人的声音的频率大概在3kHz~4kHz ，因此语音识别通常使用8k或者16k的wav提取特征。16kHz采样率的音频，傅里叶变换之后的频率范围为0-8KHz。\n\n### 计算能量谱\n\n傅里叶变换完成后，我们得到的是频域信号，每个频带范围的能量大小不一，不同音素的能量谱不一样。有两种计算方法：\n\n- magnitude = sqrt(real\\*real + image\\*image)\n- power = real\\*real + image\\*image \n\n注意：htk同时支持这两种方式，kaldi只支持第二种\n\n### Mel滤波\n\nMel滤波的过程如下图： \n\n![](1.png)\n\n图中三角窗口表示滤波窗口。三角窗口可以覆盖从0到Nyquist的整个频率范围，通常我们会设定频率上限和下限，屏蔽掉某些不需要或者有噪声的频率范围。三角形的数量表示Mel滤波之后特征向量的维度,一般取40个。\n$$\nM ( b ) = \\sum _ { j = 1 } ^ { b _ { j } } m e l _ { b } ( j ) * m _ { b } ( j )\n$$\n关于这一部分的详细情况，每个三角形对应的滤波系数可以查看\n[Mel系数计算](http://kaldi-asr.org/doc/mel-computations_8cc_source.html)， 滤波计算参考[滤波计算](http://kaldi-asr.org/doc/feature-fbank_8cc_source.html)\n\nmel倒谱公式：\n$$\nM e l ( f ) = 2595 * \\log _ { 10 } \\left( 1 + \\frac { f } { 700 } \\right)\n$$\n\n### 对数运算\n\n$$\nM _ { \\log } ( b ) = \\log ( M ( b ) )\n$$\n\n这一步就是取上一步结果的对数。简单点理解，它是对纵轴的放缩，可以放大低能量处的能量差异；更深层次地，这是在模仿倒谱（cepstrum）的计算步骤。\n\n## mfcc\nFBank特征已经很贴近人耳的响应特性，但是仍有一些不足：FBank特征相邻的特征高度相关（相邻滤波器组有重叠），因此当我们用HMM对音素建模的时候，几乎总需要首先进行倒谱转换，通过这样得到MFCC特征。\n\nMFCC特征的提取是在FBank特征的基础上再进行离散余弦变换， 因此前面几步和FBank一样.\n\n### 离散余弦变换(DCT)\n\n假设做完取Log之后，我们得到N维的特征向量Mlog。离散余弦变换公式如下：\n\n![](2.png)\n\nN是取Log之后的特征维度，M 是 DCT(离散余弦变换)之后的特征维度。DCT的实质是去除各维信号之间的相关性，将信号映射到低维空间。\n\n离散余弦变换（discrete cosine transform，DCT）是傅里叶变换的一个变种，好处是结果是实数，没有虚部。DCT还有一个特点是，对于一般的语音信号，这一步的结果的前几个系数特别大，后面的系数比较小，可以忽略。上面说了一般取40个三角形，所以DCT的结果也是40个点；实际中，一般仅保留前12~20个，这就进一步压缩了数据。\n\n## 均值方差归一化(CMVN)\n\n实际情况下，受不同麦克风及音频通道的影响，会导致相同音素的特征差别比较大，通过CMVN可以得到均值为0，方差为1的标准特征。均值方差可以以一段语音为单位计算，但更好的是在一个较大的数据集上进行计算，这样识别效果会更加稳健。Kaldi中计算均值和方差的代码[compute-cmvn-stats.cc](http://kaldi-asr.org/doc/compute-cmvn-stats_8cc_source.html)， 归一化[apply-cmvn.cc](http://kaldi-asr.org/doc/apply-cmvn_8cc_source.html)。\n\n## FBank与MFCC对比\n\n- 计算量：MFCC是在FBank的基础上进行的，所以MFCC的计算量更大\n- 特征区分度：FBank特征相关性较高，MFCC具有更好的判别度，这也是在大多数语音识别论文中用的是MFCC，而不是FBank的原因\n\n使用对角协方差矩阵的GMM由于忽略了不同特征维度的相关性，MFCC更适合用来做特征。\n\nDNN/CNN可以更好的利用这些相关性，把MFCC的离散余弦变换(DCT)省略，使用fbank特征可以更多地降低WER。\n","source":"_posts/fbank和mfcc特征提取.md","raw":"---\ntitle:      fbank和mfcc特征提取\nauthor:     liuyan\ncatalog:    true\ntags:\n  - 语音识别\n  - 特征提取\ndate:       2017-10-07 21:04:11\nurlname:\ncategories: 语音识别\n---\n\n## 语音参数提取特征\n\n分帧 ——> 预增强 ——> 加窗 ——> 添加噪声 ——> FFT ——> Mel滤波 ——> 对数运算——> DCT\n\n### 分帧\n\n我们需要将不定长的音频切分成固定长度的小段，这一步称为分帧。一般取10-30ms为一帧，为了避免窗边界对信号的遗漏，因此对帧做偏移时候，要有帧迭(帧与帧之间需要重叠一部分)。 一般取帧长的一半作为帧移，也就是每次位移一帧的二分之一后再取下一帧，这样可以避免帧与帧之间的特性变化太大。通常的选择是25ms每帧，帧迭为10ms。接下来的操作是对单帧进行的。\n\n要分帧是因为语音信号是快速变化的，而傅里叶变换适用于分析平稳的信号。在语音识别中，一般把帧长取为10~30ms，这样一帧内既有足够多的周期，又不会变化太剧烈。每帧信号通常要与一个平滑的窗函数相乘，让帧两端平滑地衰减到零，这样可以降低傅里叶变换后旁瓣的强度，取得更高质量的频谱。帧和帧之间的时间差常常取为10ms，这样帧与帧之间会有重叠，否则，由于帧与帧连接处的信号会因为加窗而被弱化，这部分的信息就丢失了。傅里叶变换是逐帧进行的，为的是取得每一帧的频谱。一般只保留幅度谱，丢弃相位谱。\n\n<!-- more -->\n\n### 预增强 \n\n预增强以帧为单位进行，目的在于加强高频。数学公式如下：\n$$\ns ( n ) = s ( n ) - k * s ( n - 1 ) , \\quad \\forall n \\in \\mathbb { N }\n$$\nk是预增强系数，范围为[0, 1)，常用0.97，N是每一帧的长度，从公式可以看出每一帧的第一个数需要特殊处理。\n\n### 加窗 \n\n语音在长范围内是不停变动的，没有固定的特性无法做处理，所以将每一帧代入窗函数，窗外的值设定为0，其目的是消除各个帧两端可能会造成的信号不连续性。常用的窗函数有方窗、汉明窗等，根据窗函数的频域特性，常采用汉明窗，其对应的窗函数如下： \n\n$$\ns _ { n } ^ { \\prime } = ( 0.54 - 0.46 \\cos ( \\frac { 2 \\pi ( n - 1 ) } { N - 137 } ) ) s _ { n }\n$$\n\n加窗过程其实就是将data[0:n-1]与w[0:n-1]对应相乘。 \n\n注意：预增强和加窗同时使用时，要首先进行预增强\n\n### 添加随机噪声 \n\n有时候我们需要进行数据增强，会手动合成一些音频。某些人工合成(使用软件)的音频可能会造成一些数字错误，诸如underflow或者overflow。 这种情况下，通过添加随机噪声可以解决这一类问题。公式如下： \n$$\ns ( n ) = s ( n ) + q * r a n d()\n$$\nq用于控制添加噪声的强度，rand() 产生\\[ -1.0, 1.0 )的随机数。 \n\n注意：Kaldi中是在分帧之后的下一步添加随机噪声\n\n\n## fbank\n\n人耳对声音频谱的响应是非线性的，经验表明：如果我们能够设计一种前端处理算法，以类似于人耳的方式对音频进行处理，可以提高语音识别的性能。FilterBank就是这样的一种算法。FBank特征提取要在预处理之后进行，这时语音已经分帧，我们需要逐帧提取FBank特征。\n\n\n### 快速傅里叶变换(fft) \n\n我们分帧之后得到的仍然是时域信号，为了提取fbank特征，首先需要将时域信号转换为频域信号。傅里叶变换可以将信号从时域转到频域。傅里叶变换可以分为连续傅里叶变换和离散傅里叶变换，因为我们用的是数字音频（而非模拟音频），所以我们用到的是离散傅里叶变换。数学公式如下：\n$$\nX ( k ) = \\sum _ { j = 1 } ^ { N } x ( j ) w _ { N } ^ { ( j - 1 ) ( k - 1 ) }\n$$\n公式比较难以理解，可以想象一下傅里叶级数，一个函数可以用其他基本函数组合逼近。从公式可以看出，傅里叶变化的计算复杂度较高，因此我们通常使用的是快速傅里叶变换（fft）。\n\n信号频率 : 组合产生复杂信号的简单信号的频率，通常简单信号平率范围很广\n\n采样频率 : 模拟到数字的转换过程中，需要对模拟信号进行采样，每秒内的采样点数量就是采样频率\n\nNyquist定理(奈奎斯特): 如果想要从数字信号无损转到模拟信号，我们需要以最高信号频率的2倍的采样频率进行采样。通常人的声音的频率大概在3kHz~4kHz ，因此语音识别通常使用8k或者16k的wav提取特征。16kHz采样率的音频，傅里叶变换之后的频率范围为0-8KHz。\n\n### 计算能量谱\n\n傅里叶变换完成后，我们得到的是频域信号，每个频带范围的能量大小不一，不同音素的能量谱不一样。有两种计算方法：\n\n- magnitude = sqrt(real\\*real + image\\*image)\n- power = real\\*real + image\\*image \n\n注意：htk同时支持这两种方式，kaldi只支持第二种\n\n### Mel滤波\n\nMel滤波的过程如下图： \n\n![](1.png)\n\n图中三角窗口表示滤波窗口。三角窗口可以覆盖从0到Nyquist的整个频率范围，通常我们会设定频率上限和下限，屏蔽掉某些不需要或者有噪声的频率范围。三角形的数量表示Mel滤波之后特征向量的维度,一般取40个。\n$$\nM ( b ) = \\sum _ { j = 1 } ^ { b _ { j } } m e l _ { b } ( j ) * m _ { b } ( j )\n$$\n关于这一部分的详细情况，每个三角形对应的滤波系数可以查看\n[Mel系数计算](http://kaldi-asr.org/doc/mel-computations_8cc_source.html)， 滤波计算参考[滤波计算](http://kaldi-asr.org/doc/feature-fbank_8cc_source.html)\n\nmel倒谱公式：\n$$\nM e l ( f ) = 2595 * \\log _ { 10 } \\left( 1 + \\frac { f } { 700 } \\right)\n$$\n\n### 对数运算\n\n$$\nM _ { \\log } ( b ) = \\log ( M ( b ) )\n$$\n\n这一步就是取上一步结果的对数。简单点理解，它是对纵轴的放缩，可以放大低能量处的能量差异；更深层次地，这是在模仿倒谱（cepstrum）的计算步骤。\n\n## mfcc\nFBank特征已经很贴近人耳的响应特性，但是仍有一些不足：FBank特征相邻的特征高度相关（相邻滤波器组有重叠），因此当我们用HMM对音素建模的时候，几乎总需要首先进行倒谱转换，通过这样得到MFCC特征。\n\nMFCC特征的提取是在FBank特征的基础上再进行离散余弦变换， 因此前面几步和FBank一样.\n\n### 离散余弦变换(DCT)\n\n假设做完取Log之后，我们得到N维的特征向量Mlog。离散余弦变换公式如下：\n\n![](2.png)\n\nN是取Log之后的特征维度，M 是 DCT(离散余弦变换)之后的特征维度。DCT的实质是去除各维信号之间的相关性，将信号映射到低维空间。\n\n离散余弦变换（discrete cosine transform，DCT）是傅里叶变换的一个变种，好处是结果是实数，没有虚部。DCT还有一个特点是，对于一般的语音信号，这一步的结果的前几个系数特别大，后面的系数比较小，可以忽略。上面说了一般取40个三角形，所以DCT的结果也是40个点；实际中，一般仅保留前12~20个，这就进一步压缩了数据。\n\n## 均值方差归一化(CMVN)\n\n实际情况下，受不同麦克风及音频通道的影响，会导致相同音素的特征差别比较大，通过CMVN可以得到均值为0，方差为1的标准特征。均值方差可以以一段语音为单位计算，但更好的是在一个较大的数据集上进行计算，这样识别效果会更加稳健。Kaldi中计算均值和方差的代码[compute-cmvn-stats.cc](http://kaldi-asr.org/doc/compute-cmvn-stats_8cc_source.html)， 归一化[apply-cmvn.cc](http://kaldi-asr.org/doc/apply-cmvn_8cc_source.html)。\n\n## FBank与MFCC对比\n\n- 计算量：MFCC是在FBank的基础上进行的，所以MFCC的计算量更大\n- 特征区分度：FBank特征相关性较高，MFCC具有更好的判别度，这也是在大多数语音识别论文中用的是MFCC，而不是FBank的原因\n\n使用对角协方差矩阵的GMM由于忽略了不同特征维度的相关性，MFCC更适合用来做特征。\n\nDNN/CNN可以更好的利用这些相关性，把MFCC的离散余弦变换(DCT)省略，使用fbank特征可以更多地降低WER。\n","slug":"fbank和mfcc特征提取","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2na002hly0gox83ppg5","content":"<h2 id=\"语音参数提取特征\"><a href=\"#语音参数提取特征\" class=\"headerlink\" title=\"语音参数提取特征\"></a>语音参数提取特征</h2><p>分帧 ——&gt; 预增强 ——&gt; 加窗 ——&gt; 添加噪声 ——&gt; FFT ——&gt; Mel滤波 ——&gt; 对数运算——&gt; DCT</p>\n<h3 id=\"分帧\"><a href=\"#分帧\" class=\"headerlink\" title=\"分帧\"></a>分帧</h3><p>我们需要将不定长的音频切分成固定长度的小段，这一步称为分帧。一般取10-30ms为一帧，为了避免窗边界对信号的遗漏，因此对帧做偏移时候，要有帧迭(帧与帧之间需要重叠一部分)。 一般取帧长的一半作为帧移，也就是每次位移一帧的二分之一后再取下一帧，这样可以避免帧与帧之间的特性变化太大。通常的选择是25ms每帧，帧迭为10ms。接下来的操作是对单帧进行的。</p>\n<p>要分帧是因为语音信号是快速变化的，而傅里叶变换适用于分析平稳的信号。在语音识别中，一般把帧长取为10~30ms，这样一帧内既有足够多的周期，又不会变化太剧烈。每帧信号通常要与一个平滑的窗函数相乘，让帧两端平滑地衰减到零，这样可以降低傅里叶变换后旁瓣的强度，取得更高质量的频谱。帧和帧之间的时间差常常取为10ms，这样帧与帧之间会有重叠，否则，由于帧与帧连接处的信号会因为加窗而被弱化，这部分的信息就丢失了。傅里叶变换是逐帧进行的，为的是取得每一帧的频谱。一般只保留幅度谱，丢弃相位谱。</p>\n<a id=\"more\"></a>\n<h3 id=\"预增强\"><a href=\"#预增强\" class=\"headerlink\" title=\"预增强\"></a>预增强</h3><p>预增强以帧为单位进行，目的在于加强高频。数学公式如下：<br>$$<br>s ( n ) = s ( n ) - k * s ( n - 1 ) , \\quad \\forall n \\in \\mathbb { N }<br>$$<br>k是预增强系数，范围为[0, 1)，常用0.97，N是每一帧的长度，从公式可以看出每一帧的第一个数需要特殊处理。</p>\n<h3 id=\"加窗\"><a href=\"#加窗\" class=\"headerlink\" title=\"加窗\"></a>加窗</h3><p>语音在长范围内是不停变动的，没有固定的特性无法做处理，所以将每一帧代入窗函数，窗外的值设定为0，其目的是消除各个帧两端可能会造成的信号不连续性。常用的窗函数有方窗、汉明窗等，根据窗函数的频域特性，常采用汉明窗，其对应的窗函数如下： </p>\n<p>$$<br>s _ { n } ^ { \\prime } = ( 0.54 - 0.46 \\cos ( \\frac { 2 \\pi ( n - 1 ) } { N - 137 } ) ) s _ { n }<br>$$</p>\n<p>加窗过程其实就是将data[0:n-1]与w[0:n-1]对应相乘。 </p>\n<p>注意：预增强和加窗同时使用时，要首先进行预增强</p>\n<h3 id=\"添加随机噪声\"><a href=\"#添加随机噪声\" class=\"headerlink\" title=\"添加随机噪声\"></a>添加随机噪声</h3><p>有时候我们需要进行数据增强，会手动合成一些音频。某些人工合成(使用软件)的音频可能会造成一些数字错误，诸如underflow或者overflow。 这种情况下，通过添加随机噪声可以解决这一类问题。公式如下：<br>$$<br>s ( n ) = s ( n ) + q * r a n d()<br>$$<br>q用于控制添加噪声的强度，rand() 产生[ -1.0, 1.0 )的随机数。 </p>\n<p>注意：Kaldi中是在分帧之后的下一步添加随机噪声</p>\n<h2 id=\"fbank\"><a href=\"#fbank\" class=\"headerlink\" title=\"fbank\"></a>fbank</h2><p>人耳对声音频谱的响应是非线性的，经验表明：如果我们能够设计一种前端处理算法，以类似于人耳的方式对音频进行处理，可以提高语音识别的性能。FilterBank就是这样的一种算法。FBank特征提取要在预处理之后进行，这时语音已经分帧，我们需要逐帧提取FBank特征。</p>\n<h3 id=\"快速傅里叶变换-fft\"><a href=\"#快速傅里叶变换-fft\" class=\"headerlink\" title=\"快速傅里叶变换(fft)\"></a>快速傅里叶变换(fft)</h3><p>我们分帧之后得到的仍然是时域信号，为了提取fbank特征，首先需要将时域信号转换为频域信号。傅里叶变换可以将信号从时域转到频域。傅里叶变换可以分为连续傅里叶变换和离散傅里叶变换，因为我们用的是数字音频（而非模拟音频），所以我们用到的是离散傅里叶变换。数学公式如下：<br>$$<br>X ( k ) = \\sum _ { j = 1 } ^ { N } x ( j ) w _ { N } ^ { ( j - 1 ) ( k - 1 ) }<br>$$<br>公式比较难以理解，可以想象一下傅里叶级数，一个函数可以用其他基本函数组合逼近。从公式可以看出，傅里叶变化的计算复杂度较高，因此我们通常使用的是快速傅里叶变换（fft）。</p>\n<p>信号频率 : 组合产生复杂信号的简单信号的频率，通常简单信号平率范围很广</p>\n<p>采样频率 : 模拟到数字的转换过程中，需要对模拟信号进行采样，每秒内的采样点数量就是采样频率</p>\n<p>Nyquist定理(奈奎斯特): 如果想要从数字信号无损转到模拟信号，我们需要以最高信号频率的2倍的采样频率进行采样。通常人的声音的频率大概在3kHz~4kHz ，因此语音识别通常使用8k或者16k的wav提取特征。16kHz采样率的音频，傅里叶变换之后的频率范围为0-8KHz。</p>\n<h3 id=\"计算能量谱\"><a href=\"#计算能量谱\" class=\"headerlink\" title=\"计算能量谱\"></a>计算能量谱</h3><p>傅里叶变换完成后，我们得到的是频域信号，每个频带范围的能量大小不一，不同音素的能量谱不一样。有两种计算方法：</p>\n<ul>\n<li>magnitude = sqrt(real*real + image*image)</li>\n<li>power = real*real + image*image </li>\n</ul>\n<p>注意：htk同时支持这两种方式，kaldi只支持第二种</p>\n<h3 id=\"Mel滤波\"><a href=\"#Mel滤波\" class=\"headerlink\" title=\"Mel滤波\"></a>Mel滤波</h3><p>Mel滤波的过程如下图： </p>\n<p><img src=\"/2017/10/07/fbank和mfcc特征提取/1.png\" alt=\"\"></p>\n<p>图中三角窗口表示滤波窗口。三角窗口可以覆盖从0到Nyquist的整个频率范围，通常我们会设定频率上限和下限，屏蔽掉某些不需要或者有噪声的频率范围。三角形的数量表示Mel滤波之后特征向量的维度,一般取40个。<br>$$<br>M ( b ) = \\sum _ { j = 1 } ^ { b _ { j } } m e l _ { b } ( j ) * m _ { b } ( j )<br>$$<br>关于这一部分的详细情况，每个三角形对应的滤波系数可以查看<br><a href=\"http://kaldi-asr.org/doc/mel-computations_8cc_source.html\" target=\"_blank\" rel=\"noopener\">Mel系数计算</a>， 滤波计算参考<a href=\"http://kaldi-asr.org/doc/feature-fbank_8cc_source.html\" target=\"_blank\" rel=\"noopener\">滤波计算</a></p>\n<p>mel倒谱公式：<br>$$<br>M e l ( f ) = 2595 * \\log _ { 10 } \\left( 1 + \\frac { f } { 700 } \\right)<br>$$</p>\n<h3 id=\"对数运算\"><a href=\"#对数运算\" class=\"headerlink\" title=\"对数运算\"></a>对数运算</h3><p>$$<br>M _ { \\log } ( b ) = \\log ( M ( b ) )<br>$$</p>\n<p>这一步就是取上一步结果的对数。简单点理解，它是对纵轴的放缩，可以放大低能量处的能量差异；更深层次地，这是在模仿倒谱（cepstrum）的计算步骤。</p>\n<h2 id=\"mfcc\"><a href=\"#mfcc\" class=\"headerlink\" title=\"mfcc\"></a>mfcc</h2><p>FBank特征已经很贴近人耳的响应特性，但是仍有一些不足：FBank特征相邻的特征高度相关（相邻滤波器组有重叠），因此当我们用HMM对音素建模的时候，几乎总需要首先进行倒谱转换，通过这样得到MFCC特征。</p>\n<p>MFCC特征的提取是在FBank特征的基础上再进行离散余弦变换， 因此前面几步和FBank一样.</p>\n<h3 id=\"离散余弦变换-DCT\"><a href=\"#离散余弦变换-DCT\" class=\"headerlink\" title=\"离散余弦变换(DCT)\"></a>离散余弦变换(DCT)</h3><p>假设做完取Log之后，我们得到N维的特征向量Mlog。离散余弦变换公式如下：</p>\n<p><img src=\"/2017/10/07/fbank和mfcc特征提取/2.png\" alt=\"\"></p>\n<p>N是取Log之后的特征维度，M 是 DCT(离散余弦变换)之后的特征维度。DCT的实质是去除各维信号之间的相关性，将信号映射到低维空间。</p>\n<p>离散余弦变换（discrete cosine transform，DCT）是傅里叶变换的一个变种，好处是结果是实数，没有虚部。DCT还有一个特点是，对于一般的语音信号，这一步的结果的前几个系数特别大，后面的系数比较小，可以忽略。上面说了一般取40个三角形，所以DCT的结果也是40个点；实际中，一般仅保留前12~20个，这就进一步压缩了数据。</p>\n<h2 id=\"均值方差归一化-CMVN\"><a href=\"#均值方差归一化-CMVN\" class=\"headerlink\" title=\"均值方差归一化(CMVN)\"></a>均值方差归一化(CMVN)</h2><p>实际情况下，受不同麦克风及音频通道的影响，会导致相同音素的特征差别比较大，通过CMVN可以得到均值为0，方差为1的标准特征。均值方差可以以一段语音为单位计算，但更好的是在一个较大的数据集上进行计算，这样识别效果会更加稳健。Kaldi中计算均值和方差的代码<a href=\"http://kaldi-asr.org/doc/compute-cmvn-stats_8cc_source.html\" target=\"_blank\" rel=\"noopener\">compute-cmvn-stats.cc</a>， 归一化<a href=\"http://kaldi-asr.org/doc/apply-cmvn_8cc_source.html\" target=\"_blank\" rel=\"noopener\">apply-cmvn.cc</a>。</p>\n<h2 id=\"FBank与MFCC对比\"><a href=\"#FBank与MFCC对比\" class=\"headerlink\" title=\"FBank与MFCC对比\"></a>FBank与MFCC对比</h2><ul>\n<li>计算量：MFCC是在FBank的基础上进行的，所以MFCC的计算量更大</li>\n<li>特征区分度：FBank特征相关性较高，MFCC具有更好的判别度，这也是在大多数语音识别论文中用的是MFCC，而不是FBank的原因</li>\n</ul>\n<p>使用对角协方差矩阵的GMM由于忽略了不同特征维度的相关性，MFCC更适合用来做特征。</p>\n<p>DNN/CNN可以更好的利用这些相关性，把MFCC的离散余弦变换(DCT)省略，使用fbank特征可以更多地降低WER。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"语音参数提取特征\"><a href=\"#语音参数提取特征\" class=\"headerlink\" title=\"语音参数提取特征\"></a>语音参数提取特征</h2><p>分帧 ——&gt; 预增强 ——&gt; 加窗 ——&gt; 添加噪声 ——&gt; FFT ——&gt; Mel滤波 ——&gt; 对数运算——&gt; DCT</p>\n<h3 id=\"分帧\"><a href=\"#分帧\" class=\"headerlink\" title=\"分帧\"></a>分帧</h3><p>我们需要将不定长的音频切分成固定长度的小段，这一步称为分帧。一般取10-30ms为一帧，为了避免窗边界对信号的遗漏，因此对帧做偏移时候，要有帧迭(帧与帧之间需要重叠一部分)。 一般取帧长的一半作为帧移，也就是每次位移一帧的二分之一后再取下一帧，这样可以避免帧与帧之间的特性变化太大。通常的选择是25ms每帧，帧迭为10ms。接下来的操作是对单帧进行的。</p>\n<p>要分帧是因为语音信号是快速变化的，而傅里叶变换适用于分析平稳的信号。在语音识别中，一般把帧长取为10~30ms，这样一帧内既有足够多的周期，又不会变化太剧烈。每帧信号通常要与一个平滑的窗函数相乘，让帧两端平滑地衰减到零，这样可以降低傅里叶变换后旁瓣的强度，取得更高质量的频谱。帧和帧之间的时间差常常取为10ms，这样帧与帧之间会有重叠，否则，由于帧与帧连接处的信号会因为加窗而被弱化，这部分的信息就丢失了。傅里叶变换是逐帧进行的，为的是取得每一帧的频谱。一般只保留幅度谱，丢弃相位谱。</p>","more":"<h3 id=\"预增强\"><a href=\"#预增强\" class=\"headerlink\" title=\"预增强\"></a>预增强</h3><p>预增强以帧为单位进行，目的在于加强高频。数学公式如下：<br>$$<br>s ( n ) = s ( n ) - k * s ( n - 1 ) , \\quad \\forall n \\in \\mathbb { N }<br>$$<br>k是预增强系数，范围为[0, 1)，常用0.97，N是每一帧的长度，从公式可以看出每一帧的第一个数需要特殊处理。</p>\n<h3 id=\"加窗\"><a href=\"#加窗\" class=\"headerlink\" title=\"加窗\"></a>加窗</h3><p>语音在长范围内是不停变动的，没有固定的特性无法做处理，所以将每一帧代入窗函数，窗外的值设定为0，其目的是消除各个帧两端可能会造成的信号不连续性。常用的窗函数有方窗、汉明窗等，根据窗函数的频域特性，常采用汉明窗，其对应的窗函数如下： </p>\n<p>$$<br>s _ { n } ^ { \\prime } = ( 0.54 - 0.46 \\cos ( \\frac { 2 \\pi ( n - 1 ) } { N - 137 } ) ) s _ { n }<br>$$</p>\n<p>加窗过程其实就是将data[0:n-1]与w[0:n-1]对应相乘。 </p>\n<p>注意：预增强和加窗同时使用时，要首先进行预增强</p>\n<h3 id=\"添加随机噪声\"><a href=\"#添加随机噪声\" class=\"headerlink\" title=\"添加随机噪声\"></a>添加随机噪声</h3><p>有时候我们需要进行数据增强，会手动合成一些音频。某些人工合成(使用软件)的音频可能会造成一些数字错误，诸如underflow或者overflow。 这种情况下，通过添加随机噪声可以解决这一类问题。公式如下：<br>$$<br>s ( n ) = s ( n ) + q * r a n d()<br>$$<br>q用于控制添加噪声的强度，rand() 产生[ -1.0, 1.0 )的随机数。 </p>\n<p>注意：Kaldi中是在分帧之后的下一步添加随机噪声</p>\n<h2 id=\"fbank\"><a href=\"#fbank\" class=\"headerlink\" title=\"fbank\"></a>fbank</h2><p>人耳对声音频谱的响应是非线性的，经验表明：如果我们能够设计一种前端处理算法，以类似于人耳的方式对音频进行处理，可以提高语音识别的性能。FilterBank就是这样的一种算法。FBank特征提取要在预处理之后进行，这时语音已经分帧，我们需要逐帧提取FBank特征。</p>\n<h3 id=\"快速傅里叶变换-fft\"><a href=\"#快速傅里叶变换-fft\" class=\"headerlink\" title=\"快速傅里叶变换(fft)\"></a>快速傅里叶变换(fft)</h3><p>我们分帧之后得到的仍然是时域信号，为了提取fbank特征，首先需要将时域信号转换为频域信号。傅里叶变换可以将信号从时域转到频域。傅里叶变换可以分为连续傅里叶变换和离散傅里叶变换，因为我们用的是数字音频（而非模拟音频），所以我们用到的是离散傅里叶变换。数学公式如下：<br>$$<br>X ( k ) = \\sum _ { j = 1 } ^ { N } x ( j ) w _ { N } ^ { ( j - 1 ) ( k - 1 ) }<br>$$<br>公式比较难以理解，可以想象一下傅里叶级数，一个函数可以用其他基本函数组合逼近。从公式可以看出，傅里叶变化的计算复杂度较高，因此我们通常使用的是快速傅里叶变换（fft）。</p>\n<p>信号频率 : 组合产生复杂信号的简单信号的频率，通常简单信号平率范围很广</p>\n<p>采样频率 : 模拟到数字的转换过程中，需要对模拟信号进行采样，每秒内的采样点数量就是采样频率</p>\n<p>Nyquist定理(奈奎斯特): 如果想要从数字信号无损转到模拟信号，我们需要以最高信号频率的2倍的采样频率进行采样。通常人的声音的频率大概在3kHz~4kHz ，因此语音识别通常使用8k或者16k的wav提取特征。16kHz采样率的音频，傅里叶变换之后的频率范围为0-8KHz。</p>\n<h3 id=\"计算能量谱\"><a href=\"#计算能量谱\" class=\"headerlink\" title=\"计算能量谱\"></a>计算能量谱</h3><p>傅里叶变换完成后，我们得到的是频域信号，每个频带范围的能量大小不一，不同音素的能量谱不一样。有两种计算方法：</p>\n<ul>\n<li>magnitude = sqrt(real*real + image*image)</li>\n<li>power = real*real + image*image </li>\n</ul>\n<p>注意：htk同时支持这两种方式，kaldi只支持第二种</p>\n<h3 id=\"Mel滤波\"><a href=\"#Mel滤波\" class=\"headerlink\" title=\"Mel滤波\"></a>Mel滤波</h3><p>Mel滤波的过程如下图： </p>\n<p><img src=\"/2017/10/07/fbank和mfcc特征提取/1.png\" alt=\"\"></p>\n<p>图中三角窗口表示滤波窗口。三角窗口可以覆盖从0到Nyquist的整个频率范围，通常我们会设定频率上限和下限，屏蔽掉某些不需要或者有噪声的频率范围。三角形的数量表示Mel滤波之后特征向量的维度,一般取40个。<br>$$<br>M ( b ) = \\sum _ { j = 1 } ^ { b _ { j } } m e l _ { b } ( j ) * m _ { b } ( j )<br>$$<br>关于这一部分的详细情况，每个三角形对应的滤波系数可以查看<br><a href=\"http://kaldi-asr.org/doc/mel-computations_8cc_source.html\" target=\"_blank\" rel=\"noopener\">Mel系数计算</a>， 滤波计算参考<a href=\"http://kaldi-asr.org/doc/feature-fbank_8cc_source.html\" target=\"_blank\" rel=\"noopener\">滤波计算</a></p>\n<p>mel倒谱公式：<br>$$<br>M e l ( f ) = 2595 * \\log _ { 10 } \\left( 1 + \\frac { f } { 700 } \\right)<br>$$</p>\n<h3 id=\"对数运算\"><a href=\"#对数运算\" class=\"headerlink\" title=\"对数运算\"></a>对数运算</h3><p>$$<br>M _ { \\log } ( b ) = \\log ( M ( b ) )<br>$$</p>\n<p>这一步就是取上一步结果的对数。简单点理解，它是对纵轴的放缩，可以放大低能量处的能量差异；更深层次地，这是在模仿倒谱（cepstrum）的计算步骤。</p>\n<h2 id=\"mfcc\"><a href=\"#mfcc\" class=\"headerlink\" title=\"mfcc\"></a>mfcc</h2><p>FBank特征已经很贴近人耳的响应特性，但是仍有一些不足：FBank特征相邻的特征高度相关（相邻滤波器组有重叠），因此当我们用HMM对音素建模的时候，几乎总需要首先进行倒谱转换，通过这样得到MFCC特征。</p>\n<p>MFCC特征的提取是在FBank特征的基础上再进行离散余弦变换， 因此前面几步和FBank一样.</p>\n<h3 id=\"离散余弦变换-DCT\"><a href=\"#离散余弦变换-DCT\" class=\"headerlink\" title=\"离散余弦变换(DCT)\"></a>离散余弦变换(DCT)</h3><p>假设做完取Log之后，我们得到N维的特征向量Mlog。离散余弦变换公式如下：</p>\n<p><img src=\"/2017/10/07/fbank和mfcc特征提取/2.png\" alt=\"\"></p>\n<p>N是取Log之后的特征维度，M 是 DCT(离散余弦变换)之后的特征维度。DCT的实质是去除各维信号之间的相关性，将信号映射到低维空间。</p>\n<p>离散余弦变换（discrete cosine transform，DCT）是傅里叶变换的一个变种，好处是结果是实数，没有虚部。DCT还有一个特点是，对于一般的语音信号，这一步的结果的前几个系数特别大，后面的系数比较小，可以忽略。上面说了一般取40个三角形，所以DCT的结果也是40个点；实际中，一般仅保留前12~20个，这就进一步压缩了数据。</p>\n<h2 id=\"均值方差归一化-CMVN\"><a href=\"#均值方差归一化-CMVN\" class=\"headerlink\" title=\"均值方差归一化(CMVN)\"></a>均值方差归一化(CMVN)</h2><p>实际情况下，受不同麦克风及音频通道的影响，会导致相同音素的特征差别比较大，通过CMVN可以得到均值为0，方差为1的标准特征。均值方差可以以一段语音为单位计算，但更好的是在一个较大的数据集上进行计算，这样识别效果会更加稳健。Kaldi中计算均值和方差的代码<a href=\"http://kaldi-asr.org/doc/compute-cmvn-stats_8cc_source.html\" target=\"_blank\" rel=\"noopener\">compute-cmvn-stats.cc</a>， 归一化<a href=\"http://kaldi-asr.org/doc/apply-cmvn_8cc_source.html\" target=\"_blank\" rel=\"noopener\">apply-cmvn.cc</a>。</p>\n<h2 id=\"FBank与MFCC对比\"><a href=\"#FBank与MFCC对比\" class=\"headerlink\" title=\"FBank与MFCC对比\"></a>FBank与MFCC对比</h2><ul>\n<li>计算量：MFCC是在FBank的基础上进行的，所以MFCC的计算量更大</li>\n<li>特征区分度：FBank特征相关性较高，MFCC具有更好的判别度，这也是在大多数语音识别论文中用的是MFCC，而不是FBank的原因</li>\n</ul>\n<p>使用对角协方差矩阵的GMM由于忽略了不同特征维度的相关性，MFCC更适合用来做特征。</p>\n<p>DNN/CNN可以更好的利用这些相关性，把MFCC的离散余弦变换(DCT)省略，使用fbank特征可以更多地降低WER。</p>"},{"title":"奇异值分解SVD","author":"liuyan","catalog":true,"date":"2018-10-11T07:41:02.000Z","urlname":null,"_content":"\n在介绍奇异值分解（SVD）之前我们先来回顾一下关于矩阵的一些基础知识。\n\n### 矩阵基础知识\n\n#### 方阵\n给定一个$ n×m $的矩阵$ A $，若n和m相等也就是矩阵的行和列相等那矩阵$ A $就是一个方阵。\n\n#### 单位矩阵\n在线性代数中，n阶单位矩阵，是一个$ n×n $的方阵，其主对角线元素为1，其余元素为0。单位矩阵以$ \\mathbf { I } _ { n } $表示。\n\n<!-- more -->\n\n![](2.png)\n\n单位矩阵性质：\n$$\n\\text { 1. } I _ { n } B _ { n \\times m } = B _ { n \\times m }\n$$\n$$\n\\text { 2. } B _ { n \\times m } I _ { m } = B _ { n \\times m }\n$$\n$$\n\\text { 3. } A _ { n } I _ { n } = I _ { n } A _ { n } = A _ { n }\n$$\n$$\n\\text { 4. } I _ { n } I _ { n } = I _ { n }\n$$\n\n#### 转置\n矩阵的转置是最简单的一种矩阵变换。简单来说若$ n×m $的矩阵$ A $的转置为$ A ^ { \\mathrm { T } } $，则$ A ^ { \\mathrm { T } } $是一个$ m×n $的矩阵并且有$ \\mathbf { A } _ { i j } = \\mathbf { A } _ { j i } ^ { \\mathrm { T } }  $。矩阵的转置相当于将矩阵按照主对角线翻转；同时，我们不难得出$ \\mathbf { A } = \\left( \\mathbf { A } ^ { \\top } \\right) ^ { \\top }  $。\n\n![](1.gif)\n\n#### 矩阵的逆\n逆矩阵：在线性代数中，给定一个n阶方阵$ A $，若存在n阶方阵$ B $使得$ \\mathbf { A B } = \\mathbf { B } \\mathbf { A } = \\mathbf { I } _ { n }  $，其中$ \\mathbf { I } _ { n } $是n阶单位矩阵，则称$ A $是可逆的且$ B $是$ A $的逆矩阵记作$ A ^ { -1 } $。\n\n只有方阵才可能但非必然有逆矩阵，若方阵$ A $的逆矩阵存在则称$ A $为非奇异方阵或可逆方阵。  \n\n逆矩阵性质：\n$$\n\\text { 1. } \\left( A ^ { - 1 } \\right) ^ { - 1 } = A\n$$\n$$\n\\text { 2. } ( \\lambda A ) ^ { - 1 } = \\frac { 1 } { \\lambda } \\times A ^ { - 1 }\n$$\n$$\n\\text { 3. } ( A B ) ^ { - 1 } = B ^ { - 1 } A ^ { - 1 }\n$$\n$$\n\\text { 4. } \\left( A ^ { \\mathrm { T } } \\right) ^ { - 1 } = \\left( A ^ { - 1 } \\right) ^ { \\mathrm { T } }\n$$\n\n#### 正交矩阵\n正交矩阵是一个方阵$ Q $，其元素为实数并且行和列都为正交的单位向量，使得该矩阵的转置矩阵为其逆矩阵：\n$$\nQ ^ { T } = Q ^ { - 1 } \\Leftrightarrow Q ^ { T } Q = Q Q ^ { T } = I\n$$\n其中$ I $是单位矩阵。\n\n#### 酉矩阵\n矩阵U为酉矩阵当且仅当其共轭转置$ \\boldsymbol { U } ^ { \\dagger } $为其逆矩阵：\n$$\nU ^ { - 1 } = U ^ { \\dagger }\n$$\n若酉矩阵的元素都是实数，其即为正交矩阵。\n\n#### 对称矩阵\n对称矩阵是一个方阵，其转置矩阵和自身相等：\n$$\nA = A ^ { \\mathrm { T } }\n$$\n\n#### 对角矩阵\n对角矩阵是一个主对角线之外的元素皆为0的方阵。对角线上的元素可以为0或其他值。对角矩阵都是对称矩阵。\n\n#### 可对角化矩阵\n对角化：若方阵$ A $相似于对角矩阵，即存在可逆矩阵$ P $和对角矩阵$ Σ $，有$ A = P Σ P ^ { - 1 }  $，则称A可对角化。\n\n可对角化的充分必要条件：\n\n$ n×n $阶矩阵$ A $可对角化的充分必要条件是矩阵$ A $有n个线性无关的特征向量。\n\n### 特征值分解\n\n#### 特征值与特征向量\n对于一个给定的方阵$ A $，它的**特征向量**$ v $经过这个线性变换之后，得到的新向量仍然与原来的$ v $保持在同一条直线上，但其长度或方向也许会改变。即：\n$$\nA v = \\lambda v\n$$\n$ \\lambda $为标量，即特征向量的长度在该线性变换下缩放的比例，称$ \\lambda $为其**特征值**。反过来，一个实数$ \\lambda $是矩阵$ A $的一个特征值，当且仅当有一个非零向量$ v $满足上面的式子。\n\n如果特征值为正，则表示$ v $在经过线性变换的作用后方向也不变；如果特征值为负，说明方向会反转；如果特征值为0，则是表示缩回零点。但无论怎样，仍在同一条直线上。\n\n#### 特征值分解\n令$ A $是一个$ n×n $的方阵并且有n个线性无关的特征向量$ q _ { i } ( i = 1 , \\dots , N )  $，这样A可以被分解为：\n$$\nA = Q \\Sigma Q ^ { - 1 }\n$$\n其中，$ Q $是一个$ n×n $的方阵并且是由矩阵$ A $的特征向量组成的矩阵，$ Σ $是对角矩阵，其对角线元素为对应的特征值即$ Σ _ { i i } = \\lambda _ { i }  $，里面的特征值是由大到小排列的。也就是说矩阵A的信息可以由其特征值和特征向量表示。\n\n这里需要注意**只有可对角化矩阵才可以作特征分解**。\n\n特征值分解可以得到特征值与特征向量，**特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。**\n\n### 奇异值分解（SVD）\n\n特征值分解的第一个要求就是需要矩阵是方阵，这个要求是很高的。对于一个$ n×m $的普通矩阵来说是否也可以像可对角化矩阵那样进行类似的特征值分解呢。奇异值分解（SVD）就是对普通矩阵做分解的一种方法。\n\n假设$ M $是一个$ n×m $阶矩阵，其中的元素全部属于域$ K $，也就是实数域$ R $或复数域$ C $。如此则存在一个分解使得：\n$$\nM = U \\Sigma V ^ { T }\n$$\n其中$ M $是$ n×n $阶酉矩阵，$ Σ $是$ n×m $阶非负实数对角矩阵，$ V ^ { T } $是$ V $的转置，是$ m×m $阶酉矩阵。这样的分解就称作$ M $的奇异值分解。$ Σ $对角线上的元素$ Σ _ {i,i}$即为$ M $的奇异值。$ U $和$ V $分别是$ A $的左右奇异向量矩阵。\n\n常见的做法是将奇异值由大到小排列，这样$ Σ $便能由$ M $唯一确定了。\n![](3.png)\n\n#### 特征值分解和奇异值分解\n首先，特征值只能作用在一个$ n×n $的方阵上，而奇异值分解则可以作用在一个$ n×m $的普通矩阵上。\n\n其次，奇异值分解同时包含了**旋转、缩放和投影**三种作用，$ U $和$ V $都起到了对$ M $旋转的作用，而$ Σ $起到了对$ M $缩放的作用。特征值分解只有缩放的效果。\n\n不过，这两个分解之间是有关联的。给定一个$ M $的奇异值分解，根据上面的论述，两者的关系式如下：\n$$\n\\begin{aligned} M ^ { T } M & = V \\Sigma ^ { T } U ^ { T } U \\Sigma V ^ { T } = V \\left( \\Sigma ^ { T } \\Sigma \\right) V ^ { T } \\end{aligned}\n$$\n$$\n\\begin{aligned} M M ^ { T } & = U \\Sigma V ^ { T } V \\Sigma ^ { T } U ^ { T } = U \\left( \\Sigma \\Sigma ^ { T } \\right) U ^ { T } \\end{aligned}\n$$\n关系式的右边描述了关系式左边的特征值分解。于是：\n\n- $ V $的列向量（右奇异向量）是$ M ^ { T } M $的特征向量。\n- $ U $的列向量（左奇异向量）是$ M M ^ { T } $的特征向量。\n- $ \\Sigma $的非零对角元（非零奇异值）是$ M ^ { T } M $或者$ M M ^ { T } $的非零特征值的平方根。\n\n#### SVD的低秩逼近\n奇异值$ \\sigma $和特征值类似，在矩阵$ \\Sigma $中奇异籽是从大到小排列的而且$ \\sigma $降低的特别快，**在大多数情况下前10%甚至1%的奇异值的和就占全部奇异值之和的99%以上**，也就是说我们可以用前r大的奇异值来近似描述矩阵，如下：\n$$\nA _ { m x n } \\approx U _ { n x r } \\Sigma _ { r x r } V _ { r \\times n } ^ { T }\n$$\n其中r是一个远小于m和n的数字，这样矩阵乘法看起来就是下面这个样子：\n![](4.png)\n\n右边的三个矩阵相乘结果将会是一个接近$ A $的矩阵，r越接近n相乘的结果越接近$ A $。如果我们想要**压缩空间**来表示原矩阵$ A $，我们存下矩阵$ U , \\Sigma , V $就好。\n\n#### SVD矩阵压缩\n```python\n# -*- coding: utf-8 -*-\n\n\"\"\"\narr =\n    [[1, 2, 3, 4],\n     [5, 6, 7, 8],\n     [9, 10, 11, 12]]\n\nu = 3 * 3\nsigma = 3 * 4, 只返回了对角元素, 其余0元素被省略\nv = 4 * 4\n\"\"\"\n\nimport numpy as np\n\narr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(arr)\n\n# 1. 分解\nu, sigma, v = np.linalg.svd(arr)\nprint(u)\nprint(sigma)\nprint(v)\n\n# 2. 重构\nnew_arr = np.mat(u[:, 0:1]) * np.mat(np.diag(sigma[0:1])) * np.mat(v[0:1, :])\nprint(new_arr)\n```\nnew_arr与arr非常接近，几乎相等。这其实是类似于图像压缩，只保留图像分解后的两个方阵和一个对角阵的对角元素，就可以恢复原图像。\n\n#### SVD矩阵降维与主成分分析（PCA）\nPCA就是在原始的空间中顺序地找一组相互正交的坐标轴。第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了。我们选择的r个坐标轴对空间进行压缩使得数据的损失最小。\n\n将一个$ n \\times m $的矩阵变换成一个$ n \\times r $的矩阵（r < m)，这样我们就可以对列进行压缩：\n$$\nA _ { n \\times m } P _ { m \\times r } = \\widetilde { A } _ { n \\times r }\n$$\n以上就是PCA的表达公式。但是这和SVD有什么关系呢？我们知道SVD得到的奇异值也是从大到小排列的，按PCA的观点来看就是方差最大的坐标轴就是第一个奇异向量，方差次大的坐标轴就是第二个奇异向量...我们回忆一下之前得到的SVD式子：\n$$\nA _ { n x m } \\approx U _ { n \\times r } \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }\n$$\n\n在矩阵两边同时乘上一个矩阵$ V $得到：\n$$\nA _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r } V _ { r \\times m } ^ { T } V _ { m \\times r }\n$$\n$$\nA _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r }\n$$\n其中$ V $就是上面PCA公式中的$ P $，这里是将一个$ n \\times m $的矩阵变换到一个$ n \\times r $的矩阵也就是对列进行压缩。其实我们也可以对行进行压缩：\n$$\nU _ { r \\times n } ^ { T } A _ { n \\times m } \\approx \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }\n$$\n\n可以看出，其实PCA几乎可以说是对SVD的一个包装，如果我们实现了SVD也就实现了PCA，而且更好的地方是，有了SVD我们就可以得到两个方向的PCA。\n```python\n# coding: utf-8\nimport numpy as np\n\nclass PCA:\n    \"\"\" \n    通过SVD分解来实现PCA\n    可以选择在压缩前, 是否对数据进行中心化\n    \"\"\"\n    def __init__(self, dimension, centered=True, compression=\"cols\"):\n        \"\"\"\n        dimension:      降维后的维度\n        centered:       是否事先对数据进行中心化\n        compression:    压缩行, 还是压缩列\n        \"\"\"\n        self.dimension = dimension\n        self.centered = centered\n        self.compression = compression\n\n    def _centered(self, train_x):\n        \"\"\" 数据中心化 \"\"\"\n        return train_x - np.mean(train_x, axis=0)\n\n    def _svd(self, train_x):\n        \"\"\" 奇异值分解 \"\"\"\n        return np.linalg.svd(train_x)\n\n    def transform(self, train_x):\n        \"\"\" 数据转化(降维)\n        train_x:        训练数据\n        u, sigma, v:    奇异值分解结果\n        result:         降维后的数据\n        \"\"\"\n        # 1. 数据中心化\n        if self.centered == True:\n            train_x = self._centered(train_x)\n\n        # 2. 奇异值分解\n        u, sigma, v = self._svd(train_x)\n        v = v.T\n        u = u.T\n        print(u.shape, sigma.shape, v.shape)\n\n        # 3. 降维\n        if self.compression == \"cols\":\n            result = np.dot(train_x, v[:, 0:self.dimension])\n        elif self.compression == \"rows\":\n            result = np.dot(u[0:self.dimension, :], train_x)\n        else:\n            raise(Exception(\"parameter error.\"))\n        return result\n\narr = np.random.rand(5, 10)\nclf = PCA(2, True, \"cols\")\nnew_arr = clf.transform(arr)\n```\n","source":"_posts/奇异值分解SVD.md","raw":"---\ntitle:      奇异值分解SVD\nauthor:     liuyan\ncatalog:    true\ntags:\n  - SVD\n  - deep learning\ndate:       2018-10-11 15:41:02\nurlname:\ncategories: deep learning\n---\n\n在介绍奇异值分解（SVD）之前我们先来回顾一下关于矩阵的一些基础知识。\n\n### 矩阵基础知识\n\n#### 方阵\n给定一个$ n×m $的矩阵$ A $，若n和m相等也就是矩阵的行和列相等那矩阵$ A $就是一个方阵。\n\n#### 单位矩阵\n在线性代数中，n阶单位矩阵，是一个$ n×n $的方阵，其主对角线元素为1，其余元素为0。单位矩阵以$ \\mathbf { I } _ { n } $表示。\n\n<!-- more -->\n\n![](2.png)\n\n单位矩阵性质：\n$$\n\\text { 1. } I _ { n } B _ { n \\times m } = B _ { n \\times m }\n$$\n$$\n\\text { 2. } B _ { n \\times m } I _ { m } = B _ { n \\times m }\n$$\n$$\n\\text { 3. } A _ { n } I _ { n } = I _ { n } A _ { n } = A _ { n }\n$$\n$$\n\\text { 4. } I _ { n } I _ { n } = I _ { n }\n$$\n\n#### 转置\n矩阵的转置是最简单的一种矩阵变换。简单来说若$ n×m $的矩阵$ A $的转置为$ A ^ { \\mathrm { T } } $，则$ A ^ { \\mathrm { T } } $是一个$ m×n $的矩阵并且有$ \\mathbf { A } _ { i j } = \\mathbf { A } _ { j i } ^ { \\mathrm { T } }  $。矩阵的转置相当于将矩阵按照主对角线翻转；同时，我们不难得出$ \\mathbf { A } = \\left( \\mathbf { A } ^ { \\top } \\right) ^ { \\top }  $。\n\n![](1.gif)\n\n#### 矩阵的逆\n逆矩阵：在线性代数中，给定一个n阶方阵$ A $，若存在n阶方阵$ B $使得$ \\mathbf { A B } = \\mathbf { B } \\mathbf { A } = \\mathbf { I } _ { n }  $，其中$ \\mathbf { I } _ { n } $是n阶单位矩阵，则称$ A $是可逆的且$ B $是$ A $的逆矩阵记作$ A ^ { -1 } $。\n\n只有方阵才可能但非必然有逆矩阵，若方阵$ A $的逆矩阵存在则称$ A $为非奇异方阵或可逆方阵。  \n\n逆矩阵性质：\n$$\n\\text { 1. } \\left( A ^ { - 1 } \\right) ^ { - 1 } = A\n$$\n$$\n\\text { 2. } ( \\lambda A ) ^ { - 1 } = \\frac { 1 } { \\lambda } \\times A ^ { - 1 }\n$$\n$$\n\\text { 3. } ( A B ) ^ { - 1 } = B ^ { - 1 } A ^ { - 1 }\n$$\n$$\n\\text { 4. } \\left( A ^ { \\mathrm { T } } \\right) ^ { - 1 } = \\left( A ^ { - 1 } \\right) ^ { \\mathrm { T } }\n$$\n\n#### 正交矩阵\n正交矩阵是一个方阵$ Q $，其元素为实数并且行和列都为正交的单位向量，使得该矩阵的转置矩阵为其逆矩阵：\n$$\nQ ^ { T } = Q ^ { - 1 } \\Leftrightarrow Q ^ { T } Q = Q Q ^ { T } = I\n$$\n其中$ I $是单位矩阵。\n\n#### 酉矩阵\n矩阵U为酉矩阵当且仅当其共轭转置$ \\boldsymbol { U } ^ { \\dagger } $为其逆矩阵：\n$$\nU ^ { - 1 } = U ^ { \\dagger }\n$$\n若酉矩阵的元素都是实数，其即为正交矩阵。\n\n#### 对称矩阵\n对称矩阵是一个方阵，其转置矩阵和自身相等：\n$$\nA = A ^ { \\mathrm { T } }\n$$\n\n#### 对角矩阵\n对角矩阵是一个主对角线之外的元素皆为0的方阵。对角线上的元素可以为0或其他值。对角矩阵都是对称矩阵。\n\n#### 可对角化矩阵\n对角化：若方阵$ A $相似于对角矩阵，即存在可逆矩阵$ P $和对角矩阵$ Σ $，有$ A = P Σ P ^ { - 1 }  $，则称A可对角化。\n\n可对角化的充分必要条件：\n\n$ n×n $阶矩阵$ A $可对角化的充分必要条件是矩阵$ A $有n个线性无关的特征向量。\n\n### 特征值分解\n\n#### 特征值与特征向量\n对于一个给定的方阵$ A $，它的**特征向量**$ v $经过这个线性变换之后，得到的新向量仍然与原来的$ v $保持在同一条直线上，但其长度或方向也许会改变。即：\n$$\nA v = \\lambda v\n$$\n$ \\lambda $为标量，即特征向量的长度在该线性变换下缩放的比例，称$ \\lambda $为其**特征值**。反过来，一个实数$ \\lambda $是矩阵$ A $的一个特征值，当且仅当有一个非零向量$ v $满足上面的式子。\n\n如果特征值为正，则表示$ v $在经过线性变换的作用后方向也不变；如果特征值为负，说明方向会反转；如果特征值为0，则是表示缩回零点。但无论怎样，仍在同一条直线上。\n\n#### 特征值分解\n令$ A $是一个$ n×n $的方阵并且有n个线性无关的特征向量$ q _ { i } ( i = 1 , \\dots , N )  $，这样A可以被分解为：\n$$\nA = Q \\Sigma Q ^ { - 1 }\n$$\n其中，$ Q $是一个$ n×n $的方阵并且是由矩阵$ A $的特征向量组成的矩阵，$ Σ $是对角矩阵，其对角线元素为对应的特征值即$ Σ _ { i i } = \\lambda _ { i }  $，里面的特征值是由大到小排列的。也就是说矩阵A的信息可以由其特征值和特征向量表示。\n\n这里需要注意**只有可对角化矩阵才可以作特征分解**。\n\n特征值分解可以得到特征值与特征向量，**特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。**\n\n### 奇异值分解（SVD）\n\n特征值分解的第一个要求就是需要矩阵是方阵，这个要求是很高的。对于一个$ n×m $的普通矩阵来说是否也可以像可对角化矩阵那样进行类似的特征值分解呢。奇异值分解（SVD）就是对普通矩阵做分解的一种方法。\n\n假设$ M $是一个$ n×m $阶矩阵，其中的元素全部属于域$ K $，也就是实数域$ R $或复数域$ C $。如此则存在一个分解使得：\n$$\nM = U \\Sigma V ^ { T }\n$$\n其中$ M $是$ n×n $阶酉矩阵，$ Σ $是$ n×m $阶非负实数对角矩阵，$ V ^ { T } $是$ V $的转置，是$ m×m $阶酉矩阵。这样的分解就称作$ M $的奇异值分解。$ Σ $对角线上的元素$ Σ _ {i,i}$即为$ M $的奇异值。$ U $和$ V $分别是$ A $的左右奇异向量矩阵。\n\n常见的做法是将奇异值由大到小排列，这样$ Σ $便能由$ M $唯一确定了。\n![](3.png)\n\n#### 特征值分解和奇异值分解\n首先，特征值只能作用在一个$ n×n $的方阵上，而奇异值分解则可以作用在一个$ n×m $的普通矩阵上。\n\n其次，奇异值分解同时包含了**旋转、缩放和投影**三种作用，$ U $和$ V $都起到了对$ M $旋转的作用，而$ Σ $起到了对$ M $缩放的作用。特征值分解只有缩放的效果。\n\n不过，这两个分解之间是有关联的。给定一个$ M $的奇异值分解，根据上面的论述，两者的关系式如下：\n$$\n\\begin{aligned} M ^ { T } M & = V \\Sigma ^ { T } U ^ { T } U \\Sigma V ^ { T } = V \\left( \\Sigma ^ { T } \\Sigma \\right) V ^ { T } \\end{aligned}\n$$\n$$\n\\begin{aligned} M M ^ { T } & = U \\Sigma V ^ { T } V \\Sigma ^ { T } U ^ { T } = U \\left( \\Sigma \\Sigma ^ { T } \\right) U ^ { T } \\end{aligned}\n$$\n关系式的右边描述了关系式左边的特征值分解。于是：\n\n- $ V $的列向量（右奇异向量）是$ M ^ { T } M $的特征向量。\n- $ U $的列向量（左奇异向量）是$ M M ^ { T } $的特征向量。\n- $ \\Sigma $的非零对角元（非零奇异值）是$ M ^ { T } M $或者$ M M ^ { T } $的非零特征值的平方根。\n\n#### SVD的低秩逼近\n奇异值$ \\sigma $和特征值类似，在矩阵$ \\Sigma $中奇异籽是从大到小排列的而且$ \\sigma $降低的特别快，**在大多数情况下前10%甚至1%的奇异值的和就占全部奇异值之和的99%以上**，也就是说我们可以用前r大的奇异值来近似描述矩阵，如下：\n$$\nA _ { m x n } \\approx U _ { n x r } \\Sigma _ { r x r } V _ { r \\times n } ^ { T }\n$$\n其中r是一个远小于m和n的数字，这样矩阵乘法看起来就是下面这个样子：\n![](4.png)\n\n右边的三个矩阵相乘结果将会是一个接近$ A $的矩阵，r越接近n相乘的结果越接近$ A $。如果我们想要**压缩空间**来表示原矩阵$ A $，我们存下矩阵$ U , \\Sigma , V $就好。\n\n#### SVD矩阵压缩\n```python\n# -*- coding: utf-8 -*-\n\n\"\"\"\narr =\n    [[1, 2, 3, 4],\n     [5, 6, 7, 8],\n     [9, 10, 11, 12]]\n\nu = 3 * 3\nsigma = 3 * 4, 只返回了对角元素, 其余0元素被省略\nv = 4 * 4\n\"\"\"\n\nimport numpy as np\n\narr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(arr)\n\n# 1. 分解\nu, sigma, v = np.linalg.svd(arr)\nprint(u)\nprint(sigma)\nprint(v)\n\n# 2. 重构\nnew_arr = np.mat(u[:, 0:1]) * np.mat(np.diag(sigma[0:1])) * np.mat(v[0:1, :])\nprint(new_arr)\n```\nnew_arr与arr非常接近，几乎相等。这其实是类似于图像压缩，只保留图像分解后的两个方阵和一个对角阵的对角元素，就可以恢复原图像。\n\n#### SVD矩阵降维与主成分分析（PCA）\nPCA就是在原始的空间中顺序地找一组相互正交的坐标轴。第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了。我们选择的r个坐标轴对空间进行压缩使得数据的损失最小。\n\n将一个$ n \\times m $的矩阵变换成一个$ n \\times r $的矩阵（r < m)，这样我们就可以对列进行压缩：\n$$\nA _ { n \\times m } P _ { m \\times r } = \\widetilde { A } _ { n \\times r }\n$$\n以上就是PCA的表达公式。但是这和SVD有什么关系呢？我们知道SVD得到的奇异值也是从大到小排列的，按PCA的观点来看就是方差最大的坐标轴就是第一个奇异向量，方差次大的坐标轴就是第二个奇异向量...我们回忆一下之前得到的SVD式子：\n$$\nA _ { n x m } \\approx U _ { n \\times r } \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }\n$$\n\n在矩阵两边同时乘上一个矩阵$ V $得到：\n$$\nA _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r } V _ { r \\times m } ^ { T } V _ { m \\times r }\n$$\n$$\nA _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r }\n$$\n其中$ V $就是上面PCA公式中的$ P $，这里是将一个$ n \\times m $的矩阵变换到一个$ n \\times r $的矩阵也就是对列进行压缩。其实我们也可以对行进行压缩：\n$$\nU _ { r \\times n } ^ { T } A _ { n \\times m } \\approx \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }\n$$\n\n可以看出，其实PCA几乎可以说是对SVD的一个包装，如果我们实现了SVD也就实现了PCA，而且更好的地方是，有了SVD我们就可以得到两个方向的PCA。\n```python\n# coding: utf-8\nimport numpy as np\n\nclass PCA:\n    \"\"\" \n    通过SVD分解来实现PCA\n    可以选择在压缩前, 是否对数据进行中心化\n    \"\"\"\n    def __init__(self, dimension, centered=True, compression=\"cols\"):\n        \"\"\"\n        dimension:      降维后的维度\n        centered:       是否事先对数据进行中心化\n        compression:    压缩行, 还是压缩列\n        \"\"\"\n        self.dimension = dimension\n        self.centered = centered\n        self.compression = compression\n\n    def _centered(self, train_x):\n        \"\"\" 数据中心化 \"\"\"\n        return train_x - np.mean(train_x, axis=0)\n\n    def _svd(self, train_x):\n        \"\"\" 奇异值分解 \"\"\"\n        return np.linalg.svd(train_x)\n\n    def transform(self, train_x):\n        \"\"\" 数据转化(降维)\n        train_x:        训练数据\n        u, sigma, v:    奇异值分解结果\n        result:         降维后的数据\n        \"\"\"\n        # 1. 数据中心化\n        if self.centered == True:\n            train_x = self._centered(train_x)\n\n        # 2. 奇异值分解\n        u, sigma, v = self._svd(train_x)\n        v = v.T\n        u = u.T\n        print(u.shape, sigma.shape, v.shape)\n\n        # 3. 降维\n        if self.compression == \"cols\":\n            result = np.dot(train_x, v[:, 0:self.dimension])\n        elif self.compression == \"rows\":\n            result = np.dot(u[0:self.dimension, :], train_x)\n        else:\n            raise(Exception(\"parameter error.\"))\n        return result\n\narr = np.random.rand(5, 10)\nclf = PCA(2, True, \"cols\")\nnew_arr = clf.transform(arr)\n```\n","slug":"奇异值分解SVD","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2nc002jly0gy1wdk63c","content":"<p>在介绍奇异值分解（SVD）之前我们先来回顾一下关于矩阵的一些基础知识。</p>\n<h3 id=\"矩阵基础知识\"><a href=\"#矩阵基础知识\" class=\"headerlink\" title=\"矩阵基础知识\"></a>矩阵基础知识</h3><h4 id=\"方阵\"><a href=\"#方阵\" class=\"headerlink\" title=\"方阵\"></a>方阵</h4><p>给定一个$ n×m $的矩阵$ A $，若n和m相等也就是矩阵的行和列相等那矩阵$ A $就是一个方阵。</p>\n<h4 id=\"单位矩阵\"><a href=\"#单位矩阵\" class=\"headerlink\" title=\"单位矩阵\"></a>单位矩阵</h4><p>在线性代数中，n阶单位矩阵，是一个$ n×n $的方阵，其主对角线元素为1，其余元素为0。单位矩阵以$ \\mathbf { I } _ { n } $表示。</p>\n<a id=\"more\"></a>\n<p><img src=\"/2018/10/11/奇异值分解SVD/2.png\" alt=\"\"></p>\n<p>单位矩阵性质：<br>$$<br>\\text { 1. } I _ { n } B _ { n \\times m } = B _ { n \\times m }<br>$$<br>$$<br>\\text { 2. } B _ { n \\times m } I _ { m } = B _ { n \\times m }<br>$$<br>$$<br>\\text { 3. } A _ { n } I _ { n } = I _ { n } A _ { n } = A _ { n }<br>$$<br>$$<br>\\text { 4. } I _ { n } I _ { n } = I _ { n }<br>$$</p>\n<h4 id=\"转置\"><a href=\"#转置\" class=\"headerlink\" title=\"转置\"></a>转置</h4><p>矩阵的转置是最简单的一种矩阵变换。简单来说若$ n×m $的矩阵$ A $的转置为$ A ^ { \\mathrm { T } } $，则$ A ^ { \\mathrm { T } } $是一个$ m×n $的矩阵并且有$ \\mathbf { A } _ { i j } = \\mathbf { A } _ { j i } ^ { \\mathrm { T } }  $。矩阵的转置相当于将矩阵按照主对角线翻转；同时，我们不难得出$ \\mathbf { A } = \\left( \\mathbf { A } ^ { \\top } \\right) ^ { \\top }  $。</p>\n<p><img src=\"/2018/10/11/奇异值分解SVD/1.gif\" alt=\"\"></p>\n<h4 id=\"矩阵的逆\"><a href=\"#矩阵的逆\" class=\"headerlink\" title=\"矩阵的逆\"></a>矩阵的逆</h4><p>逆矩阵：在线性代数中，给定一个n阶方阵$ A $，若存在n阶方阵$ B $使得$ \\mathbf { A B } = \\mathbf { B } \\mathbf { A } = \\mathbf { I } _ { n }  $，其中$ \\mathbf { I } _ { n } $是n阶单位矩阵，则称$ A $是可逆的且$ B $是$ A $的逆矩阵记作$ A ^ { -1 } $。</p>\n<p>只有方阵才可能但非必然有逆矩阵，若方阵$ A $的逆矩阵存在则称$ A $为非奇异方阵或可逆方阵。  </p>\n<p>逆矩阵性质：<br>$$<br>\\text { 1. } \\left( A ^ { - 1 } \\right) ^ { - 1 } = A<br>$$<br>$$<br>\\text { 2. } ( \\lambda A ) ^ { - 1 } = \\frac { 1 } { \\lambda } \\times A ^ { - 1 }<br>$$<br>$$<br>\\text { 3. } ( A B ) ^ { - 1 } = B ^ { - 1 } A ^ { - 1 }<br>$$<br>$$<br>\\text { 4. } \\left( A ^ { \\mathrm { T } } \\right) ^ { - 1 } = \\left( A ^ { - 1 } \\right) ^ { \\mathrm { T } }<br>$$</p>\n<h4 id=\"正交矩阵\"><a href=\"#正交矩阵\" class=\"headerlink\" title=\"正交矩阵\"></a>正交矩阵</h4><p>正交矩阵是一个方阵$ Q $，其元素为实数并且行和列都为正交的单位向量，使得该矩阵的转置矩阵为其逆矩阵：<br>$$<br>Q ^ { T } = Q ^ { - 1 } \\Leftrightarrow Q ^ { T } Q = Q Q ^ { T } = I<br>$$<br>其中$ I $是单位矩阵。</p>\n<h4 id=\"酉矩阵\"><a href=\"#酉矩阵\" class=\"headerlink\" title=\"酉矩阵\"></a>酉矩阵</h4><p>矩阵U为酉矩阵当且仅当其共轭转置$ \\boldsymbol { U } ^ { \\dagger } $为其逆矩阵：<br>$$<br>U ^ { - 1 } = U ^ { \\dagger }<br>$$<br>若酉矩阵的元素都是实数，其即为正交矩阵。</p>\n<h4 id=\"对称矩阵\"><a href=\"#对称矩阵\" class=\"headerlink\" title=\"对称矩阵\"></a>对称矩阵</h4><p>对称矩阵是一个方阵，其转置矩阵和自身相等：<br>$$<br>A = A ^ { \\mathrm { T } }<br>$$</p>\n<h4 id=\"对角矩阵\"><a href=\"#对角矩阵\" class=\"headerlink\" title=\"对角矩阵\"></a>对角矩阵</h4><p>对角矩阵是一个主对角线之外的元素皆为0的方阵。对角线上的元素可以为0或其他值。对角矩阵都是对称矩阵。</p>\n<h4 id=\"可对角化矩阵\"><a href=\"#可对角化矩阵\" class=\"headerlink\" title=\"可对角化矩阵\"></a>可对角化矩阵</h4><p>对角化：若方阵$ A $相似于对角矩阵，即存在可逆矩阵$ P $和对角矩阵$ Σ $，有$ A = P Σ P ^ { - 1 }  $，则称A可对角化。</p>\n<p>可对角化的充分必要条件：</p>\n<p>$ n×n $阶矩阵$ A $可对角化的充分必要条件是矩阵$ A $有n个线性无关的特征向量。</p>\n<h3 id=\"特征值分解\"><a href=\"#特征值分解\" class=\"headerlink\" title=\"特征值分解\"></a>特征值分解</h3><h4 id=\"特征值与特征向量\"><a href=\"#特征值与特征向量\" class=\"headerlink\" title=\"特征值与特征向量\"></a>特征值与特征向量</h4><p>对于一个给定的方阵$ A $，它的<strong>特征向量</strong>$ v $经过这个线性变换之后，得到的新向量仍然与原来的$ v $保持在同一条直线上，但其长度或方向也许会改变。即：<br>$$<br>A v = \\lambda v<br>$$<br>$ \\lambda $为标量，即特征向量的长度在该线性变换下缩放的比例，称$ \\lambda $为其<strong>特征值</strong>。反过来，一个实数$ \\lambda $是矩阵$ A $的一个特征值，当且仅当有一个非零向量$ v $满足上面的式子。</p>\n<p>如果特征值为正，则表示$ v $在经过线性变换的作用后方向也不变；如果特征值为负，说明方向会反转；如果特征值为0，则是表示缩回零点。但无论怎样，仍在同一条直线上。</p>\n<h4 id=\"特征值分解-1\"><a href=\"#特征值分解-1\" class=\"headerlink\" title=\"特征值分解\"></a>特征值分解</h4><p>令$ A $是一个$ n×n $的方阵并且有n个线性无关的特征向量$ q _ { i } ( i = 1 , \\dots , N )  $，这样A可以被分解为：<br>$$<br>A = Q \\Sigma Q ^ { - 1 }<br>$$<br>其中，$ Q $是一个$ n×n $的方阵并且是由矩阵$ A $的特征向量组成的矩阵，$ Σ $是对角矩阵，其对角线元素为对应的特征值即$ Σ _ { i i } = \\lambda _ { i }  $，里面的特征值是由大到小排列的。也就是说矩阵A的信息可以由其特征值和特征向量表示。</p>\n<p>这里需要注意<strong>只有可对角化矩阵才可以作特征分解</strong>。</p>\n<p>特征值分解可以得到特征值与特征向量，<strong>特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。</strong></p>\n<h3 id=\"奇异值分解（SVD）\"><a href=\"#奇异值分解（SVD）\" class=\"headerlink\" title=\"奇异值分解（SVD）\"></a>奇异值分解（SVD）</h3><p>特征值分解的第一个要求就是需要矩阵是方阵，这个要求是很高的。对于一个$ n×m $的普通矩阵来说是否也可以像可对角化矩阵那样进行类似的特征值分解呢。奇异值分解（SVD）就是对普通矩阵做分解的一种方法。</p>\n<p>假设$ M $是一个$ n×m $阶矩阵，其中的元素全部属于域$ K $，也就是实数域$ R $或复数域$ C $。如此则存在一个分解使得：<br>$$<br>M = U \\Sigma V ^ { T }<br>$$<br>其中$ M $是$ n×n $阶酉矩阵，$ Σ $是$ n×m $阶非负实数对角矩阵，$ V ^ { T } $是$ V $的转置，是$ m×m $阶酉矩阵。这样的分解就称作$ M $的奇异值分解。$ Σ $对角线上的元素$ Σ _ {i,i}$即为$ M $的奇异值。$ U $和$ V $分别是$ A $的左右奇异向量矩阵。</p>\n<p>常见的做法是将奇异值由大到小排列，这样$ Σ $便能由$ M $唯一确定了。<br><img src=\"/2018/10/11/奇异值分解SVD/3.png\" alt=\"\"></p>\n<h4 id=\"特征值分解和奇异值分解\"><a href=\"#特征值分解和奇异值分解\" class=\"headerlink\" title=\"特征值分解和奇异值分解\"></a>特征值分解和奇异值分解</h4><p>首先，特征值只能作用在一个$ n×n $的方阵上，而奇异值分解则可以作用在一个$ n×m $的普通矩阵上。</p>\n<p>其次，奇异值分解同时包含了<strong>旋转、缩放和投影</strong>三种作用，$ U $和$ V $都起到了对$ M $旋转的作用，而$ Σ $起到了对$ M $缩放的作用。特征值分解只有缩放的效果。</p>\n<p>不过，这两个分解之间是有关联的。给定一个$ M $的奇异值分解，根据上面的论述，两者的关系式如下：<br>$$<br>\\begin{aligned} M ^ { T } M &amp; = V \\Sigma ^ { T } U ^ { T } U \\Sigma V ^ { T } = V \\left( \\Sigma ^ { T } \\Sigma \\right) V ^ { T } \\end{aligned}<br>$$<br>$$<br>\\begin{aligned} M M ^ { T } &amp; = U \\Sigma V ^ { T } V \\Sigma ^ { T } U ^ { T } = U \\left( \\Sigma \\Sigma ^ { T } \\right) U ^ { T } \\end{aligned}<br>$$<br>关系式的右边描述了关系式左边的特征值分解。于是：</p>\n<ul>\n<li>$ V $的列向量（右奇异向量）是$ M ^ { T } M $的特征向量。</li>\n<li>$ U $的列向量（左奇异向量）是$ M M ^ { T } $的特征向量。</li>\n<li>$ \\Sigma $的非零对角元（非零奇异值）是$ M ^ { T } M $或者$ M M ^ { T } $的非零特征值的平方根。</li>\n</ul>\n<h4 id=\"SVD的低秩逼近\"><a href=\"#SVD的低秩逼近\" class=\"headerlink\" title=\"SVD的低秩逼近\"></a>SVD的低秩逼近</h4><p>奇异值$ \\sigma $和特征值类似，在矩阵$ \\Sigma $中奇异籽是从大到小排列的而且$ \\sigma $降低的特别快，<strong>在大多数情况下前10%甚至1%的奇异值的和就占全部奇异值之和的99%以上</strong>，也就是说我们可以用前r大的奇异值来近似描述矩阵，如下：<br>$$<br>A _ { m x n } \\approx U _ { n x r } \\Sigma _ { r x r } V _ { r \\times n } ^ { T }<br>$$<br>其中r是一个远小于m和n的数字，这样矩阵乘法看起来就是下面这个样子：<br><img src=\"/2018/10/11/奇异值分解SVD/4.png\" alt=\"\"></p>\n<p>右边的三个矩阵相乘结果将会是一个接近$ A $的矩阵，r越接近n相乘的结果越接近$ A $。如果我们想要<strong>压缩空间</strong>来表示原矩阵$ A $，我们存下矩阵$ U , \\Sigma , V $就好。</p>\n<h4 id=\"SVD矩阵压缩\"><a href=\"#SVD矩阵压缩\" class=\"headerlink\" title=\"SVD矩阵压缩\"></a>SVD矩阵压缩</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">arr =</span></span><br><span class=\"line\"><span class=\"string\">    [[1, 2, 3, 4],</span></span><br><span class=\"line\"><span class=\"string\">     [5, 6, 7, 8],</span></span><br><span class=\"line\"><span class=\"string\">     [9, 10, 11, 12]]</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">u = 3 * 3</span></span><br><span class=\"line\"><span class=\"string\">sigma = 3 * 4, 只返回了对角元素, 其余0元素被省略</span></span><br><span class=\"line\"><span class=\"string\">v = 4 * 4</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">arr = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>], [<span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]])</span><br><span class=\"line\">print(arr)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 分解</span></span><br><span class=\"line\">u, sigma, v = np.linalg.svd(arr)</span><br><span class=\"line\">print(u)</span><br><span class=\"line\">print(sigma)</span><br><span class=\"line\">print(v)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 重构</span></span><br><span class=\"line\">new_arr = np.mat(u[:, <span class=\"number\">0</span>:<span class=\"number\">1</span>]) * np.mat(np.diag(sigma[<span class=\"number\">0</span>:<span class=\"number\">1</span>])) * np.mat(v[<span class=\"number\">0</span>:<span class=\"number\">1</span>, :])</span><br><span class=\"line\">print(new_arr)</span><br></pre></td></tr></table></figure>\n<p>new_arr与arr非常接近，几乎相等。这其实是类似于图像压缩，只保留图像分解后的两个方阵和一个对角阵的对角元素，就可以恢复原图像。</p>\n<h4 id=\"SVD矩阵降维与主成分分析（PCA）\"><a href=\"#SVD矩阵降维与主成分分析（PCA）\" class=\"headerlink\" title=\"SVD矩阵降维与主成分分析（PCA）\"></a>SVD矩阵降维与主成分分析（PCA）</h4><p>PCA就是在原始的空间中顺序地找一组相互正交的坐标轴。第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了。我们选择的r个坐标轴对空间进行压缩使得数据的损失最小。</p>\n<p>将一个$ n \\times m $的矩阵变换成一个$ n \\times r $的矩阵（r &lt; m)，这样我们就可以对列进行压缩：<br>$$<br>A _ { n \\times m } P _ { m \\times r } = \\widetilde { A } _ { n \\times r }<br>$$<br>以上就是PCA的表达公式。但是这和SVD有什么关系呢？我们知道SVD得到的奇异值也是从大到小排列的，按PCA的观点来看就是方差最大的坐标轴就是第一个奇异向量，方差次大的坐标轴就是第二个奇异向量…我们回忆一下之前得到的SVD式子：<br>$$<br>A _ { n x m } \\approx U _ { n \\times r } \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }<br>$$</p>\n<p>在矩阵两边同时乘上一个矩阵$ V $得到：<br>$$<br>A _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r } V _ { r \\times m } ^ { T } V _ { m \\times r }<br>$$<br>$$<br>A _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r }<br>$$<br>其中$ V $就是上面PCA公式中的$ P $，这里是将一个$ n \\times m $的矩阵变换到一个$ n \\times r $的矩阵也就是对列进行压缩。其实我们也可以对行进行压缩：<br>$$<br>U _ { r \\times n } ^ { T } A _ { n \\times m } \\approx \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }<br>$$</p>\n<p>可以看出，其实PCA几乎可以说是对SVD的一个包装，如果我们实现了SVD也就实现了PCA，而且更好的地方是，有了SVD我们就可以得到两个方向的PCA。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># coding: utf-8</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PCA</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" </span></span><br><span class=\"line\"><span class=\"string\">    通过SVD分解来实现PCA</span></span><br><span class=\"line\"><span class=\"string\">    可以选择在压缩前, 是否对数据进行中心化</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, dimension, centered=True, compression=<span class=\"string\">\"cols\"</span>)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        dimension:      降维后的维度</span></span><br><span class=\"line\"><span class=\"string\">        centered:       是否事先对数据进行中心化</span></span><br><span class=\"line\"><span class=\"string\">        compression:    压缩行, 还是压缩列</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        self.dimension = dimension</span><br><span class=\"line\">        self.centered = centered</span><br><span class=\"line\">        self.compression = compression</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_centered</span><span class=\"params\">(self, train_x)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" 数据中心化 \"\"\"</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> train_x - np.mean(train_x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_svd</span><span class=\"params\">(self, train_x)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" 奇异值分解 \"\"\"</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> np.linalg.svd(train_x)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">transform</span><span class=\"params\">(self, train_x)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" 数据转化(降维)</span></span><br><span class=\"line\"><span class=\"string\">        train_x:        训练数据</span></span><br><span class=\"line\"><span class=\"string\">        u, sigma, v:    奇异值分解结果</span></span><br><span class=\"line\"><span class=\"string\">        result:         降维后的数据</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 1. 数据中心化</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.centered == <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            train_x = self._centered(train_x)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 2. 奇异值分解</span></span><br><span class=\"line\">        u, sigma, v = self._svd(train_x)</span><br><span class=\"line\">        v = v.T</span><br><span class=\"line\">        u = u.T</span><br><span class=\"line\">        print(u.shape, sigma.shape, v.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 3. 降维</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.compression == <span class=\"string\">\"cols\"</span>:</span><br><span class=\"line\">            result = np.dot(train_x, v[:, <span class=\"number\">0</span>:self.dimension])</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> self.compression == <span class=\"string\">\"rows\"</span>:</span><br><span class=\"line\">            result = np.dot(u[<span class=\"number\">0</span>:self.dimension, :], train_x)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span>(Exception(<span class=\"string\">\"parameter error.\"</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\">arr = np.random.rand(<span class=\"number\">5</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">clf = PCA(<span class=\"number\">2</span>, <span class=\"keyword\">True</span>, <span class=\"string\">\"cols\"</span>)</span><br><span class=\"line\">new_arr = clf.transform(arr)</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>在介绍奇异值分解（SVD）之前我们先来回顾一下关于矩阵的一些基础知识。</p>\n<h3 id=\"矩阵基础知识\"><a href=\"#矩阵基础知识\" class=\"headerlink\" title=\"矩阵基础知识\"></a>矩阵基础知识</h3><h4 id=\"方阵\"><a href=\"#方阵\" class=\"headerlink\" title=\"方阵\"></a>方阵</h4><p>给定一个$ n×m $的矩阵$ A $，若n和m相等也就是矩阵的行和列相等那矩阵$ A $就是一个方阵。</p>\n<h4 id=\"单位矩阵\"><a href=\"#单位矩阵\" class=\"headerlink\" title=\"单位矩阵\"></a>单位矩阵</h4><p>在线性代数中，n阶单位矩阵，是一个$ n×n $的方阵，其主对角线元素为1，其余元素为0。单位矩阵以$ \\mathbf { I } _ { n } $表示。</p>","more":"<p><img src=\"/2018/10/11/奇异值分解SVD/2.png\" alt=\"\"></p>\n<p>单位矩阵性质：<br>$$<br>\\text { 1. } I _ { n } B _ { n \\times m } = B _ { n \\times m }<br>$$<br>$$<br>\\text { 2. } B _ { n \\times m } I _ { m } = B _ { n \\times m }<br>$$<br>$$<br>\\text { 3. } A _ { n } I _ { n } = I _ { n } A _ { n } = A _ { n }<br>$$<br>$$<br>\\text { 4. } I _ { n } I _ { n } = I _ { n }<br>$$</p>\n<h4 id=\"转置\"><a href=\"#转置\" class=\"headerlink\" title=\"转置\"></a>转置</h4><p>矩阵的转置是最简单的一种矩阵变换。简单来说若$ n×m $的矩阵$ A $的转置为$ A ^ { \\mathrm { T } } $，则$ A ^ { \\mathrm { T } } $是一个$ m×n $的矩阵并且有$ \\mathbf { A } _ { i j } = \\mathbf { A } _ { j i } ^ { \\mathrm { T } }  $。矩阵的转置相当于将矩阵按照主对角线翻转；同时，我们不难得出$ \\mathbf { A } = \\left( \\mathbf { A } ^ { \\top } \\right) ^ { \\top }  $。</p>\n<p><img src=\"/2018/10/11/奇异值分解SVD/1.gif\" alt=\"\"></p>\n<h4 id=\"矩阵的逆\"><a href=\"#矩阵的逆\" class=\"headerlink\" title=\"矩阵的逆\"></a>矩阵的逆</h4><p>逆矩阵：在线性代数中，给定一个n阶方阵$ A $，若存在n阶方阵$ B $使得$ \\mathbf { A B } = \\mathbf { B } \\mathbf { A } = \\mathbf { I } _ { n }  $，其中$ \\mathbf { I } _ { n } $是n阶单位矩阵，则称$ A $是可逆的且$ B $是$ A $的逆矩阵记作$ A ^ { -1 } $。</p>\n<p>只有方阵才可能但非必然有逆矩阵，若方阵$ A $的逆矩阵存在则称$ A $为非奇异方阵或可逆方阵。  </p>\n<p>逆矩阵性质：<br>$$<br>\\text { 1. } \\left( A ^ { - 1 } \\right) ^ { - 1 } = A<br>$$<br>$$<br>\\text { 2. } ( \\lambda A ) ^ { - 1 } = \\frac { 1 } { \\lambda } \\times A ^ { - 1 }<br>$$<br>$$<br>\\text { 3. } ( A B ) ^ { - 1 } = B ^ { - 1 } A ^ { - 1 }<br>$$<br>$$<br>\\text { 4. } \\left( A ^ { \\mathrm { T } } \\right) ^ { - 1 } = \\left( A ^ { - 1 } \\right) ^ { \\mathrm { T } }<br>$$</p>\n<h4 id=\"正交矩阵\"><a href=\"#正交矩阵\" class=\"headerlink\" title=\"正交矩阵\"></a>正交矩阵</h4><p>正交矩阵是一个方阵$ Q $，其元素为实数并且行和列都为正交的单位向量，使得该矩阵的转置矩阵为其逆矩阵：<br>$$<br>Q ^ { T } = Q ^ { - 1 } \\Leftrightarrow Q ^ { T } Q = Q Q ^ { T } = I<br>$$<br>其中$ I $是单位矩阵。</p>\n<h4 id=\"酉矩阵\"><a href=\"#酉矩阵\" class=\"headerlink\" title=\"酉矩阵\"></a>酉矩阵</h4><p>矩阵U为酉矩阵当且仅当其共轭转置$ \\boldsymbol { U } ^ { \\dagger } $为其逆矩阵：<br>$$<br>U ^ { - 1 } = U ^ { \\dagger }<br>$$<br>若酉矩阵的元素都是实数，其即为正交矩阵。</p>\n<h4 id=\"对称矩阵\"><a href=\"#对称矩阵\" class=\"headerlink\" title=\"对称矩阵\"></a>对称矩阵</h4><p>对称矩阵是一个方阵，其转置矩阵和自身相等：<br>$$<br>A = A ^ { \\mathrm { T } }<br>$$</p>\n<h4 id=\"对角矩阵\"><a href=\"#对角矩阵\" class=\"headerlink\" title=\"对角矩阵\"></a>对角矩阵</h4><p>对角矩阵是一个主对角线之外的元素皆为0的方阵。对角线上的元素可以为0或其他值。对角矩阵都是对称矩阵。</p>\n<h4 id=\"可对角化矩阵\"><a href=\"#可对角化矩阵\" class=\"headerlink\" title=\"可对角化矩阵\"></a>可对角化矩阵</h4><p>对角化：若方阵$ A $相似于对角矩阵，即存在可逆矩阵$ P $和对角矩阵$ Σ $，有$ A = P Σ P ^ { - 1 }  $，则称A可对角化。</p>\n<p>可对角化的充分必要条件：</p>\n<p>$ n×n $阶矩阵$ A $可对角化的充分必要条件是矩阵$ A $有n个线性无关的特征向量。</p>\n<h3 id=\"特征值分解\"><a href=\"#特征值分解\" class=\"headerlink\" title=\"特征值分解\"></a>特征值分解</h3><h4 id=\"特征值与特征向量\"><a href=\"#特征值与特征向量\" class=\"headerlink\" title=\"特征值与特征向量\"></a>特征值与特征向量</h4><p>对于一个给定的方阵$ A $，它的<strong>特征向量</strong>$ v $经过这个线性变换之后，得到的新向量仍然与原来的$ v $保持在同一条直线上，但其长度或方向也许会改变。即：<br>$$<br>A v = \\lambda v<br>$$<br>$ \\lambda $为标量，即特征向量的长度在该线性变换下缩放的比例，称$ \\lambda $为其<strong>特征值</strong>。反过来，一个实数$ \\lambda $是矩阵$ A $的一个特征值，当且仅当有一个非零向量$ v $满足上面的式子。</p>\n<p>如果特征值为正，则表示$ v $在经过线性变换的作用后方向也不变；如果特征值为负，说明方向会反转；如果特征值为0，则是表示缩回零点。但无论怎样，仍在同一条直线上。</p>\n<h4 id=\"特征值分解-1\"><a href=\"#特征值分解-1\" class=\"headerlink\" title=\"特征值分解\"></a>特征值分解</h4><p>令$ A $是一个$ n×n $的方阵并且有n个线性无关的特征向量$ q _ { i } ( i = 1 , \\dots , N )  $，这样A可以被分解为：<br>$$<br>A = Q \\Sigma Q ^ { - 1 }<br>$$<br>其中，$ Q $是一个$ n×n $的方阵并且是由矩阵$ A $的特征向量组成的矩阵，$ Σ $是对角矩阵，其对角线元素为对应的特征值即$ Σ _ { i i } = \\lambda _ { i }  $，里面的特征值是由大到小排列的。也就是说矩阵A的信息可以由其特征值和特征向量表示。</p>\n<p>这里需要注意<strong>只有可对角化矩阵才可以作特征分解</strong>。</p>\n<p>特征值分解可以得到特征值与特征向量，<strong>特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。</strong></p>\n<h3 id=\"奇异值分解（SVD）\"><a href=\"#奇异值分解（SVD）\" class=\"headerlink\" title=\"奇异值分解（SVD）\"></a>奇异值分解（SVD）</h3><p>特征值分解的第一个要求就是需要矩阵是方阵，这个要求是很高的。对于一个$ n×m $的普通矩阵来说是否也可以像可对角化矩阵那样进行类似的特征值分解呢。奇异值分解（SVD）就是对普通矩阵做分解的一种方法。</p>\n<p>假设$ M $是一个$ n×m $阶矩阵，其中的元素全部属于域$ K $，也就是实数域$ R $或复数域$ C $。如此则存在一个分解使得：<br>$$<br>M = U \\Sigma V ^ { T }<br>$$<br>其中$ M $是$ n×n $阶酉矩阵，$ Σ $是$ n×m $阶非负实数对角矩阵，$ V ^ { T } $是$ V $的转置，是$ m×m $阶酉矩阵。这样的分解就称作$ M $的奇异值分解。$ Σ $对角线上的元素$ Σ _ {i,i}$即为$ M $的奇异值。$ U $和$ V $分别是$ A $的左右奇异向量矩阵。</p>\n<p>常见的做法是将奇异值由大到小排列，这样$ Σ $便能由$ M $唯一确定了。<br><img src=\"/2018/10/11/奇异值分解SVD/3.png\" alt=\"\"></p>\n<h4 id=\"特征值分解和奇异值分解\"><a href=\"#特征值分解和奇异值分解\" class=\"headerlink\" title=\"特征值分解和奇异值分解\"></a>特征值分解和奇异值分解</h4><p>首先，特征值只能作用在一个$ n×n $的方阵上，而奇异值分解则可以作用在一个$ n×m $的普通矩阵上。</p>\n<p>其次，奇异值分解同时包含了<strong>旋转、缩放和投影</strong>三种作用，$ U $和$ V $都起到了对$ M $旋转的作用，而$ Σ $起到了对$ M $缩放的作用。特征值分解只有缩放的效果。</p>\n<p>不过，这两个分解之间是有关联的。给定一个$ M $的奇异值分解，根据上面的论述，两者的关系式如下：<br>$$<br>\\begin{aligned} M ^ { T } M &amp; = V \\Sigma ^ { T } U ^ { T } U \\Sigma V ^ { T } = V \\left( \\Sigma ^ { T } \\Sigma \\right) V ^ { T } \\end{aligned}<br>$$<br>$$<br>\\begin{aligned} M M ^ { T } &amp; = U \\Sigma V ^ { T } V \\Sigma ^ { T } U ^ { T } = U \\left( \\Sigma \\Sigma ^ { T } \\right) U ^ { T } \\end{aligned}<br>$$<br>关系式的右边描述了关系式左边的特征值分解。于是：</p>\n<ul>\n<li>$ V $的列向量（右奇异向量）是$ M ^ { T } M $的特征向量。</li>\n<li>$ U $的列向量（左奇异向量）是$ M M ^ { T } $的特征向量。</li>\n<li>$ \\Sigma $的非零对角元（非零奇异值）是$ M ^ { T } M $或者$ M M ^ { T } $的非零特征值的平方根。</li>\n</ul>\n<h4 id=\"SVD的低秩逼近\"><a href=\"#SVD的低秩逼近\" class=\"headerlink\" title=\"SVD的低秩逼近\"></a>SVD的低秩逼近</h4><p>奇异值$ \\sigma $和特征值类似，在矩阵$ \\Sigma $中奇异籽是从大到小排列的而且$ \\sigma $降低的特别快，<strong>在大多数情况下前10%甚至1%的奇异值的和就占全部奇异值之和的99%以上</strong>，也就是说我们可以用前r大的奇异值来近似描述矩阵，如下：<br>$$<br>A _ { m x n } \\approx U _ { n x r } \\Sigma _ { r x r } V _ { r \\times n } ^ { T }<br>$$<br>其中r是一个远小于m和n的数字，这样矩阵乘法看起来就是下面这个样子：<br><img src=\"/2018/10/11/奇异值分解SVD/4.png\" alt=\"\"></p>\n<p>右边的三个矩阵相乘结果将会是一个接近$ A $的矩阵，r越接近n相乘的结果越接近$ A $。如果我们想要<strong>压缩空间</strong>来表示原矩阵$ A $，我们存下矩阵$ U , \\Sigma , V $就好。</p>\n<h4 id=\"SVD矩阵压缩\"><a href=\"#SVD矩阵压缩\" class=\"headerlink\" title=\"SVD矩阵压缩\"></a>SVD矩阵压缩</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">arr =</span></span><br><span class=\"line\"><span class=\"string\">    [[1, 2, 3, 4],</span></span><br><span class=\"line\"><span class=\"string\">     [5, 6, 7, 8],</span></span><br><span class=\"line\"><span class=\"string\">     [9, 10, 11, 12]]</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">u = 3 * 3</span></span><br><span class=\"line\"><span class=\"string\">sigma = 3 * 4, 只返回了对角元素, 其余0元素被省略</span></span><br><span class=\"line\"><span class=\"string\">v = 4 * 4</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">arr = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>], [<span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]])</span><br><span class=\"line\">print(arr)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 分解</span></span><br><span class=\"line\">u, sigma, v = np.linalg.svd(arr)</span><br><span class=\"line\">print(u)</span><br><span class=\"line\">print(sigma)</span><br><span class=\"line\">print(v)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 重构</span></span><br><span class=\"line\">new_arr = np.mat(u[:, <span class=\"number\">0</span>:<span class=\"number\">1</span>]) * np.mat(np.diag(sigma[<span class=\"number\">0</span>:<span class=\"number\">1</span>])) * np.mat(v[<span class=\"number\">0</span>:<span class=\"number\">1</span>, :])</span><br><span class=\"line\">print(new_arr)</span><br></pre></td></tr></table></figure>\n<p>new_arr与arr非常接近，几乎相等。这其实是类似于图像压缩，只保留图像分解后的两个方阵和一个对角阵的对角元素，就可以恢复原图像。</p>\n<h4 id=\"SVD矩阵降维与主成分分析（PCA）\"><a href=\"#SVD矩阵降维与主成分分析（PCA）\" class=\"headerlink\" title=\"SVD矩阵降维与主成分分析（PCA）\"></a>SVD矩阵降维与主成分分析（PCA）</h4><p>PCA就是在原始的空间中顺序地找一组相互正交的坐标轴。第一个轴是使得方差最大的，第二个轴是在与第一个轴正交的平面中使得方差最大的，第三个轴是在与第1、2个轴正交的平面中方差最大的，这样假设在N维空间中，我们可以找到N个这样的坐标轴，我们取前r个去近似这个空间，这样就从一个N维的空间压缩到r维的空间了。我们选择的r个坐标轴对空间进行压缩使得数据的损失最小。</p>\n<p>将一个$ n \\times m $的矩阵变换成一个$ n \\times r $的矩阵（r &lt; m)，这样我们就可以对列进行压缩：<br>$$<br>A _ { n \\times m } P _ { m \\times r } = \\widetilde { A } _ { n \\times r }<br>$$<br>以上就是PCA的表达公式。但是这和SVD有什么关系呢？我们知道SVD得到的奇异值也是从大到小排列的，按PCA的观点来看就是方差最大的坐标轴就是第一个奇异向量，方差次大的坐标轴就是第二个奇异向量…我们回忆一下之前得到的SVD式子：<br>$$<br>A _ { n x m } \\approx U _ { n \\times r } \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }<br>$$</p>\n<p>在矩阵两边同时乘上一个矩阵$ V $得到：<br>$$<br>A _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r } V _ { r \\times m } ^ { T } V _ { m \\times r }<br>$$<br>$$<br>A _ { n \\times m } V _ { m \\times r } \\approx U _ { n \\times r } \\Sigma _ { r x r }<br>$$<br>其中$ V $就是上面PCA公式中的$ P $，这里是将一个$ n \\times m $的矩阵变换到一个$ n \\times r $的矩阵也就是对列进行压缩。其实我们也可以对行进行压缩：<br>$$<br>U _ { r \\times n } ^ { T } A _ { n \\times m } \\approx \\Sigma _ { r \\times r } V _ { r \\times m } ^ { T }<br>$$</p>\n<p>可以看出，其实PCA几乎可以说是对SVD的一个包装，如果我们实现了SVD也就实现了PCA，而且更好的地方是，有了SVD我们就可以得到两个方向的PCA。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># coding: utf-8</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PCA</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" </span></span><br><span class=\"line\"><span class=\"string\">    通过SVD分解来实现PCA</span></span><br><span class=\"line\"><span class=\"string\">    可以选择在压缩前, 是否对数据进行中心化</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, dimension, centered=True, compression=<span class=\"string\">\"cols\"</span>)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">        dimension:      降维后的维度</span></span><br><span class=\"line\"><span class=\"string\">        centered:       是否事先对数据进行中心化</span></span><br><span class=\"line\"><span class=\"string\">        compression:    压缩行, 还是压缩列</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        self.dimension = dimension</span><br><span class=\"line\">        self.centered = centered</span><br><span class=\"line\">        self.compression = compression</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_centered</span><span class=\"params\">(self, train_x)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" 数据中心化 \"\"\"</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> train_x - np.mean(train_x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_svd</span><span class=\"params\">(self, train_x)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" 奇异值分解 \"\"\"</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> np.linalg.svd(train_x)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">transform</span><span class=\"params\">(self, train_x)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" 数据转化(降维)</span></span><br><span class=\"line\"><span class=\"string\">        train_x:        训练数据</span></span><br><span class=\"line\"><span class=\"string\">        u, sigma, v:    奇异值分解结果</span></span><br><span class=\"line\"><span class=\"string\">        result:         降维后的数据</span></span><br><span class=\"line\"><span class=\"string\">        \"\"\"</span></span><br><span class=\"line\">        <span class=\"comment\"># 1. 数据中心化</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.centered == <span class=\"keyword\">True</span>:</span><br><span class=\"line\">            train_x = self._centered(train_x)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 2. 奇异值分解</span></span><br><span class=\"line\">        u, sigma, v = self._svd(train_x)</span><br><span class=\"line\">        v = v.T</span><br><span class=\"line\">        u = u.T</span><br><span class=\"line\">        print(u.shape, sigma.shape, v.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 3. 降维</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.compression == <span class=\"string\">\"cols\"</span>:</span><br><span class=\"line\">            result = np.dot(train_x, v[:, <span class=\"number\">0</span>:self.dimension])</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> self.compression == <span class=\"string\">\"rows\"</span>:</span><br><span class=\"line\">            result = np.dot(u[<span class=\"number\">0</span>:self.dimension, :], train_x)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span>(Exception(<span class=\"string\">\"parameter error.\"</span>))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\">arr = np.random.rand(<span class=\"number\">5</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">clf = PCA(<span class=\"number\">2</span>, <span class=\"keyword\">True</span>, <span class=\"string\">\"cols\"</span>)</span><br><span class=\"line\">new_arr = clf.transform(arr)</span><br></pre></td></tr></table></figure></p>"},{"title":"梯度下降优化算法","author":"liuyan","catalog":true,"date":"2018-08-10T03:20:19.000Z","urlname":null,"_content":"\n梯度下降是最著名的优化算法之一，也是我们在训练神经网络过程中不可缺少的优化算法，了解梯度下降以及它的各种优化算法是必需的。\n\n### 梯度下降形式\n梯度下降有三种不同的变形形式。根据数据量的不同，在参数更新精度和训练所需时间上各有一些差异。\n<!-- more -->\n\n#### 批梯度下降法\n批梯度下降法（batch gradient descent）在整个训练集上计算损失函数关于参数$  \\theta $的梯度：\n$$\n\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J ( \\theta )\n$$\n因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，并且批梯度下降法无法处理超出内存容量限制的数据集。\n\n#### 随机梯度下降法\n与批梯度下降法相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$ x ^ { ( i ) } $和标签$ y ^ { ( i ) } $更新参数：\n$$\n\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i ) } ; y ^ { ( i ) } \\right)\n$$\n对于每一条样本SGD都更新参数，会导致目标函数出现剧烈波动。这种剧烈波动一方面会使SGD跳到潜在的更好局部最优解，但是另一方面这也使收敛过程变得缓慢复杂。\n![](1.png)\n\n#### 小批量梯度下降法\n小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：\n$$\n\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } \\right)\n$$\n这种方法减少参数更新的频率可以得到更稳定的收敛效果，也可以利用最新的矩阵优化算法高效的求解小批量数据梯度。我们也将小批量梯度下降法称为SGD，下文中为了简单我们省略参数$ x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } $。\n\n### 挑战\n单纯的只使用SGD会有一些问题：\n- 选择一个合适的学习率可能是困难的。\n- 学习率调整策略无法适应所有数据集。\n- 对所有的参数更新使用同样的学习率。如果特征数据是稀疏的并且出现的频率差异很大，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们希望使用更大的学习率。\n\n### 梯度下降优化算法\n#### 动量法（momentum）\nmomentum是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。momentum将历史更新向量的一个分量增加到当前的更新向量中：\n$$\nv _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J ( \\theta )\n$$\n$$\n\\theta = \\theta - v _ { t }\n$$\n动量项$ \\gamma $通常设置为0.9。\n![](2.png)\n\nmomentum就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同方向的维度，其动量项增大；对于在梯度点处改变方向的维度，其动量项减小。所以我们可以得到更快的收敛速度并且减少摇摆。\n\n#### Nesterov加速梯度下降法\nNesterov加速梯度下降法（Nesterov accelerated gradient，NAG）是momentum的改进，是一种能够给动量项预知能力的方法：\n$$\nv _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J \\left( \\theta - \\gamma v _ { t - 1 } \\right)\n$$\n$$\n\\theta = \\theta - v _ { t }\n$$\n动量项$ \\gamma $通常设置为0.9。\n![](3.png)\n\nNAG相对于momentum，是先走到将来可能到达的点C然后在C点计算梯度，momentum是在B点计算梯度。NAG这个具有预见性的更新防止我们前进得太快，小球知道它将要去哪在遇到斜率上升时能够知道减速。\n\n#### Adagrad\nAdagrad可以让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此Adagrad非常适合处理稀疏数据如word2vec等。\n\nAdagrad在每个时刻t对每一个参数$ \\theta _ {i} $都使用不同的学习率$ \\eta $。另$ g _ { t , i }  $为在时刻t目标函数关于参数$ \\theta _ {i} $的梯度：\n$$\ng _ { t , i } = \\nabla _ { \\theta } J \\left( \\theta _ { i } \\right)\n$$\n在时刻t对每个参数$ \\theta _ {i} $的更新过程为：\n$$\n\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\eta \\cdot g _ { t , i }\n$$\n在时刻t基于对$ \\theta _ {i} $计算过的历史梯度，Adagrad修正了对每一个参数$ \\theta _ {i} $的学习率：\n$$\n\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\frac { \\eta } { \\sqrt { G _ { t , i i } + \\epsilon } } \\cdot g _ { t , i }\n$$\n其中$ G _ { t } \\in \\mathbb { R } ^ { d x d }  $是一个对角矩阵，对角线上的元素（i，i）是到t时刻为止所有关于$ \\theta _ {i} $的梯度和。$  \\epsilon $是平滑项用于防止除数为0。\n\n由于$ G _ {t} $的对角线上包含了所有关于参数$ \\theta $的历史梯度平方和，所以我们可以通过$ G _ {t} $和$ g _ {t} $之间的元素向量乘法⊙向量化上述的操作：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }\n$$\nAdagrad算法的主要优点是无需手动调整学习率。它的主要缺点是在分母中累加梯度的平方，在整个训练过程中，累加的和会持续增长，这会导致学习率变小以至于最终变得无限小。\n\n通常$ \\eta = 0.01$。\n\n#### RMSprop\nRMSprop是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不计算所有的梯度平方，Adadelta将计算历史梯度的窗口限制为一个固定值w。\n\n在RMSprop中将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$ E[ g ^ { 2 }] _ { t } $只取决于先前的均值和当前的梯度（分量$ \\gamma $类似于动量项）：\n$$\nE \\left[ g ^ { 2 } \\right] _ { t } = \\gamma E \\left[ g ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) g _ { t } ^ { 2 }\n$$\nAdagrad的参数更新向量为：\n$$\n\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }\n$$\n现在我们简单将对角矩阵$ G _ {t} $替换成历史梯度的均值$ E[ g ^ { 2 }] _ { t } $：\n$$\n\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { E \\left[ g ^ { 2 } \\right] _ { t } + \\epsilon } } g _ { t }\n$$\n最终得到RMSprop的更新规则为：\n$$\n\\theta _ {t+1} = \\theta _ i - \\frac{\\eta}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}\n$$\n通常$ \\eta = 0.001$。\n\n#### Adadelta\nAdadelta也是一种对Adagrad的改进算法，但是其比RMSprop多了一些操作。Adadelta的作者认为RMSprop更新公式中的每个部分并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方而是参数的平方的更新：\n$$\nE \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t } = \\gamma E \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) \\Delta \\theta _ { t } ^ { 2 }\n$$\n利用$ E [ \\Delta \\theta ^ { 2 } ] _ { t -1 } $替换先前的更新规则中的学习率$ \\eta $，最终得到Adadelta的更新规则：\n$$\n\\theta _ {t+1} = \\theta _ i - \\frac{\\sqrt{E[\\Delta\\theta^2] _ {t-1} + \\epsilon}}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}\n$$\nAdadelta中我们甚至不用设置初始学习率。通常$ \\gamma = 0.9 $。\n\n#### Adam\n自适应矩估计（Adaptive Moment Estimation，Adam）是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个历史平方梯度的指数衰减均值$ v _ {t} $，Adam同时还保存一个历史梯度的指数衰减均值$ m _ {t} $，类似于动量：\n$$\n\\begin{aligned} m _ { t } & = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t } \\end{aligned}\n$$\n$$\n\\begin{aligned} v _ { t } & = \\beta _ { 2 } v _ { t - 1 } + \\left( 1 - \\beta _ { 2 } \\right) g _ { t } ^ { 2 } \\end{aligned}\n$$\n$ m _ {t} $和$ v _ {t} $分别是对梯度的一阶矩（均值）和二阶矩（方差）的估计。当 m _ {t} $和$ v _ {t} $的初始值为0向量时，Adam的作者发现它们在训练初期都偏向于0（β1和β2趋向于1），从而训练缓慢。\n\n通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：\n$$\n\\begin{aligned} \\hat { m } _ { t } & = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\end{aligned}\n$$\n$$\n\\begin{aligned} \\hat { v } _ { t } & = \\frac { v _ { t } } { 1 - \\beta _ { 2 } ^ { t } } \\end{aligned}\n$$\n最终Adam的更新规则： \n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\hat { m } _ { t }\n$$\n一般$ \\eta = 0.001，\\beta _ { 1 }  = 0.9，\\beta _ { 1 } = 0.999，\\epsilon=1e−8 $。\n\n#### AdaMax\nAdaMax是Adam的一种变体。\n$$\nu _ t = {\\lim _ {p \\to +\\infty}}(v _ t)^{1/p} = max(\\beta _ 2u _ {t-1},|g _ {t}|)\n$$\n\n$$\nm _ { t } = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t } \n$$\n\n$$\n\\hat { m } _ { t } = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } }\n$$\n\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { u _ { t } } \\odot \\hat { m } _ { t }\n$$\n\n一般$ \\eta = 0.002，\\beta _ { 1 } = 0.9，\\beta _ { 2 } = 0.999，\\epsilon = 1e-8 $。\n\n#### Nadam\nNadam是带有NAG项的Adam，Adam公式展开如下：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\frac { \\beta _ { 1 } m _ { t - 1 } } { 1 - \\beta _ { 1 } ^ { t } } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)\n$$\n带进Adam的偏差校正为：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t - 1 } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)\n$$\n结合NAG的思想我们使用$ \\hat { m } _ { t }  $代替$ \\hat { m } _ { t - 1 }  $就得到Nadam的公式：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)\n$$\n\n### SGD优化算法的选择\n- 各自适应学习率的优化算法表现不分伯仲，没有哪个算法能在所有任务上脱颖而出。\n- 目前，最流行并且使用很高的优化算法包括SGD、带动量的SGD和Adam。\n- 具体使用哪个算法取决于使用者对算法的熟悉程度，以便调节超参数。\n\n### 算法可视化\n- SGD各优化算法在损失曲面的表现\n![](4.gif)\n\n- SGD 各优化方法在鞍点的表现\n![](5.gif)\n\n\n参考：\n[An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)\n[梯度下降优化算法综述](https://blog.csdn.net/google19890102/article/details/69942970)\n","source":"_posts/梯度下降优化算法.md","raw":"---\ntitle:      梯度下降优化算法\nauthor:     liuyan\ncatalog:    true\ntags:\n  - SGD\n  - deep learning\ndate:       2018-08-10 11:20:19\nurlname:\ncategories: deep learning\n---\n\n梯度下降是最著名的优化算法之一，也是我们在训练神经网络过程中不可缺少的优化算法，了解梯度下降以及它的各种优化算法是必需的。\n\n### 梯度下降形式\n梯度下降有三种不同的变形形式。根据数据量的不同，在参数更新精度和训练所需时间上各有一些差异。\n<!-- more -->\n\n#### 批梯度下降法\n批梯度下降法（batch gradient descent）在整个训练集上计算损失函数关于参数$  \\theta $的梯度：\n$$\n\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J ( \\theta )\n$$\n因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，并且批梯度下降法无法处理超出内存容量限制的数据集。\n\n#### 随机梯度下降法\n与批梯度下降法相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$ x ^ { ( i ) } $和标签$ y ^ { ( i ) } $更新参数：\n$$\n\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i ) } ; y ^ { ( i ) } \\right)\n$$\n对于每一条样本SGD都更新参数，会导致目标函数出现剧烈波动。这种剧烈波动一方面会使SGD跳到潜在的更好局部最优解，但是另一方面这也使收敛过程变得缓慢复杂。\n![](1.png)\n\n#### 小批量梯度下降法\n小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：\n$$\n\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } \\right)\n$$\n这种方法减少参数更新的频率可以得到更稳定的收敛效果，也可以利用最新的矩阵优化算法高效的求解小批量数据梯度。我们也将小批量梯度下降法称为SGD，下文中为了简单我们省略参数$ x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } $。\n\n### 挑战\n单纯的只使用SGD会有一些问题：\n- 选择一个合适的学习率可能是困难的。\n- 学习率调整策略无法适应所有数据集。\n- 对所有的参数更新使用同样的学习率。如果特征数据是稀疏的并且出现的频率差异很大，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们希望使用更大的学习率。\n\n### 梯度下降优化算法\n#### 动量法（momentum）\nmomentum是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。momentum将历史更新向量的一个分量增加到当前的更新向量中：\n$$\nv _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J ( \\theta )\n$$\n$$\n\\theta = \\theta - v _ { t }\n$$\n动量项$ \\gamma $通常设置为0.9。\n![](2.png)\n\nmomentum就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同方向的维度，其动量项增大；对于在梯度点处改变方向的维度，其动量项减小。所以我们可以得到更快的收敛速度并且减少摇摆。\n\n#### Nesterov加速梯度下降法\nNesterov加速梯度下降法（Nesterov accelerated gradient，NAG）是momentum的改进，是一种能够给动量项预知能力的方法：\n$$\nv _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J \\left( \\theta - \\gamma v _ { t - 1 } \\right)\n$$\n$$\n\\theta = \\theta - v _ { t }\n$$\n动量项$ \\gamma $通常设置为0.9。\n![](3.png)\n\nNAG相对于momentum，是先走到将来可能到达的点C然后在C点计算梯度，momentum是在B点计算梯度。NAG这个具有预见性的更新防止我们前进得太快，小球知道它将要去哪在遇到斜率上升时能够知道减速。\n\n#### Adagrad\nAdagrad可以让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此Adagrad非常适合处理稀疏数据如word2vec等。\n\nAdagrad在每个时刻t对每一个参数$ \\theta _ {i} $都使用不同的学习率$ \\eta $。另$ g _ { t , i }  $为在时刻t目标函数关于参数$ \\theta _ {i} $的梯度：\n$$\ng _ { t , i } = \\nabla _ { \\theta } J \\left( \\theta _ { i } \\right)\n$$\n在时刻t对每个参数$ \\theta _ {i} $的更新过程为：\n$$\n\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\eta \\cdot g _ { t , i }\n$$\n在时刻t基于对$ \\theta _ {i} $计算过的历史梯度，Adagrad修正了对每一个参数$ \\theta _ {i} $的学习率：\n$$\n\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\frac { \\eta } { \\sqrt { G _ { t , i i } + \\epsilon } } \\cdot g _ { t , i }\n$$\n其中$ G _ { t } \\in \\mathbb { R } ^ { d x d }  $是一个对角矩阵，对角线上的元素（i，i）是到t时刻为止所有关于$ \\theta _ {i} $的梯度和。$  \\epsilon $是平滑项用于防止除数为0。\n\n由于$ G _ {t} $的对角线上包含了所有关于参数$ \\theta $的历史梯度平方和，所以我们可以通过$ G _ {t} $和$ g _ {t} $之间的元素向量乘法⊙向量化上述的操作：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }\n$$\nAdagrad算法的主要优点是无需手动调整学习率。它的主要缺点是在分母中累加梯度的平方，在整个训练过程中，累加的和会持续增长，这会导致学习率变小以至于最终变得无限小。\n\n通常$ \\eta = 0.01$。\n\n#### RMSprop\nRMSprop是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不计算所有的梯度平方，Adadelta将计算历史梯度的窗口限制为一个固定值w。\n\n在RMSprop中将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$ E[ g ^ { 2 }] _ { t } $只取决于先前的均值和当前的梯度（分量$ \\gamma $类似于动量项）：\n$$\nE \\left[ g ^ { 2 } \\right] _ { t } = \\gamma E \\left[ g ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) g _ { t } ^ { 2 }\n$$\nAdagrad的参数更新向量为：\n$$\n\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }\n$$\n现在我们简单将对角矩阵$ G _ {t} $替换成历史梯度的均值$ E[ g ^ { 2 }] _ { t } $：\n$$\n\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { E \\left[ g ^ { 2 } \\right] _ { t } + \\epsilon } } g _ { t }\n$$\n最终得到RMSprop的更新规则为：\n$$\n\\theta _ {t+1} = \\theta _ i - \\frac{\\eta}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}\n$$\n通常$ \\eta = 0.001$。\n\n#### Adadelta\nAdadelta也是一种对Adagrad的改进算法，但是其比RMSprop多了一些操作。Adadelta的作者认为RMSprop更新公式中的每个部分并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方而是参数的平方的更新：\n$$\nE \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t } = \\gamma E \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) \\Delta \\theta _ { t } ^ { 2 }\n$$\n利用$ E [ \\Delta \\theta ^ { 2 } ] _ { t -1 } $替换先前的更新规则中的学习率$ \\eta $，最终得到Adadelta的更新规则：\n$$\n\\theta _ {t+1} = \\theta _ i - \\frac{\\sqrt{E[\\Delta\\theta^2] _ {t-1} + \\epsilon}}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}\n$$\nAdadelta中我们甚至不用设置初始学习率。通常$ \\gamma = 0.9 $。\n\n#### Adam\n自适应矩估计（Adaptive Moment Estimation，Adam）是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个历史平方梯度的指数衰减均值$ v _ {t} $，Adam同时还保存一个历史梯度的指数衰减均值$ m _ {t} $，类似于动量：\n$$\n\\begin{aligned} m _ { t } & = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t } \\end{aligned}\n$$\n$$\n\\begin{aligned} v _ { t } & = \\beta _ { 2 } v _ { t - 1 } + \\left( 1 - \\beta _ { 2 } \\right) g _ { t } ^ { 2 } \\end{aligned}\n$$\n$ m _ {t} $和$ v _ {t} $分别是对梯度的一阶矩（均值）和二阶矩（方差）的估计。当 m _ {t} $和$ v _ {t} $的初始值为0向量时，Adam的作者发现它们在训练初期都偏向于0（β1和β2趋向于1），从而训练缓慢。\n\n通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：\n$$\n\\begin{aligned} \\hat { m } _ { t } & = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\end{aligned}\n$$\n$$\n\\begin{aligned} \\hat { v } _ { t } & = \\frac { v _ { t } } { 1 - \\beta _ { 2 } ^ { t } } \\end{aligned}\n$$\n最终Adam的更新规则： \n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\hat { m } _ { t }\n$$\n一般$ \\eta = 0.001，\\beta _ { 1 }  = 0.9，\\beta _ { 1 } = 0.999，\\epsilon=1e−8 $。\n\n#### AdaMax\nAdaMax是Adam的一种变体。\n$$\nu _ t = {\\lim _ {p \\to +\\infty}}(v _ t)^{1/p} = max(\\beta _ 2u _ {t-1},|g _ {t}|)\n$$\n\n$$\nm _ { t } = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t } \n$$\n\n$$\n\\hat { m } _ { t } = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } }\n$$\n\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { u _ { t } } \\odot \\hat { m } _ { t }\n$$\n\n一般$ \\eta = 0.002，\\beta _ { 1 } = 0.9，\\beta _ { 2 } = 0.999，\\epsilon = 1e-8 $。\n\n#### Nadam\nNadam是带有NAG项的Adam，Adam公式展开如下：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\frac { \\beta _ { 1 } m _ { t - 1 } } { 1 - \\beta _ { 1 } ^ { t } } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)\n$$\n带进Adam的偏差校正为：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t - 1 } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)\n$$\n结合NAG的思想我们使用$ \\hat { m } _ { t }  $代替$ \\hat { m } _ { t - 1 }  $就得到Nadam的公式：\n$$\n\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)\n$$\n\n### SGD优化算法的选择\n- 各自适应学习率的优化算法表现不分伯仲，没有哪个算法能在所有任务上脱颖而出。\n- 目前，最流行并且使用很高的优化算法包括SGD、带动量的SGD和Adam。\n- 具体使用哪个算法取决于使用者对算法的熟悉程度，以便调节超参数。\n\n### 算法可视化\n- SGD各优化算法在损失曲面的表现\n![](4.gif)\n\n- SGD 各优化方法在鞍点的表现\n![](5.gif)\n\n\n参考：\n[An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)\n[梯度下降优化算法综述](https://blog.csdn.net/google19890102/article/details/69942970)\n","slug":"梯度下降优化算法","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2nf002lly0g7du5gdi6","content":"<p>梯度下降是最著名的优化算法之一，也是我们在训练神经网络过程中不可缺少的优化算法，了解梯度下降以及它的各种优化算法是必需的。</p>\n<h3 id=\"梯度下降形式\"><a href=\"#梯度下降形式\" class=\"headerlink\" title=\"梯度下降形式\"></a>梯度下降形式</h3><p>梯度下降有三种不同的变形形式。根据数据量的不同，在参数更新精度和训练所需时间上各有一些差异。<br><a id=\"more\"></a></p>\n<h4 id=\"批梯度下降法\"><a href=\"#批梯度下降法\" class=\"headerlink\" title=\"批梯度下降法\"></a>批梯度下降法</h4><p>批梯度下降法（batch gradient descent）在整个训练集上计算损失函数关于参数$  \\theta $的梯度：<br>$$<br>\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J ( \\theta )<br>$$<br>因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，并且批梯度下降法无法处理超出内存容量限制的数据集。</p>\n<h4 id=\"随机梯度下降法\"><a href=\"#随机梯度下降法\" class=\"headerlink\" title=\"随机梯度下降法\"></a>随机梯度下降法</h4><p>与批梯度下降法相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$ x ^ { ( i ) } $和标签$ y ^ { ( i ) } $更新参数：<br>$$<br>\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i ) } ; y ^ { ( i ) } \\right)<br>$$<br>对于每一条样本SGD都更新参数，会导致目标函数出现剧烈波动。这种剧烈波动一方面会使SGD跳到潜在的更好局部最优解，但是另一方面这也使收敛过程变得缓慢复杂。<br><img src=\"/2018/08/10/梯度下降优化算法/1.png\" alt=\"\"></p>\n<h4 id=\"小批量梯度下降法\"><a href=\"#小批量梯度下降法\" class=\"headerlink\" title=\"小批量梯度下降法\"></a>小批量梯度下降法</h4><p>小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：<br>$$<br>\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } \\right)<br>$$<br>这种方法减少参数更新的频率可以得到更稳定的收敛效果，也可以利用最新的矩阵优化算法高效的求解小批量数据梯度。我们也将小批量梯度下降法称为SGD，下文中为了简单我们省略参数$ x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } $。</p>\n<h3 id=\"挑战\"><a href=\"#挑战\" class=\"headerlink\" title=\"挑战\"></a>挑战</h3><p>单纯的只使用SGD会有一些问题：</p>\n<ul>\n<li>选择一个合适的学习率可能是困难的。</li>\n<li>学习率调整策略无法适应所有数据集。</li>\n<li>对所有的参数更新使用同样的学习率。如果特征数据是稀疏的并且出现的频率差异很大，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们希望使用更大的学习率。</li>\n</ul>\n<h3 id=\"梯度下降优化算法\"><a href=\"#梯度下降优化算法\" class=\"headerlink\" title=\"梯度下降优化算法\"></a>梯度下降优化算法</h3><h4 id=\"动量法（momentum）\"><a href=\"#动量法（momentum）\" class=\"headerlink\" title=\"动量法（momentum）\"></a>动量法（momentum）</h4><p>momentum是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。momentum将历史更新向量的一个分量增加到当前的更新向量中：<br>$$<br>v _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J ( \\theta )<br>$$<br>$$<br>\\theta = \\theta - v _ { t }<br>$$<br>动量项$ \\gamma $通常设置为0.9。<br><img src=\"/2018/08/10/梯度下降优化算法/2.png\" alt=\"\"></p>\n<p>momentum就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同方向的维度，其动量项增大；对于在梯度点处改变方向的维度，其动量项减小。所以我们可以得到更快的收敛速度并且减少摇摆。</p>\n<h4 id=\"Nesterov加速梯度下降法\"><a href=\"#Nesterov加速梯度下降法\" class=\"headerlink\" title=\"Nesterov加速梯度下降法\"></a>Nesterov加速梯度下降法</h4><p>Nesterov加速梯度下降法（Nesterov accelerated gradient，NAG）是momentum的改进，是一种能够给动量项预知能力的方法：<br>$$<br>v _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J \\left( \\theta - \\gamma v _ { t - 1 } \\right)<br>$$<br>$$<br>\\theta = \\theta - v _ { t }<br>$$<br>动量项$ \\gamma $通常设置为0.9。<br><img src=\"/2018/08/10/梯度下降优化算法/3.png\" alt=\"\"></p>\n<p>NAG相对于momentum，是先走到将来可能到达的点C然后在C点计算梯度，momentum是在B点计算梯度。NAG这个具有预见性的更新防止我们前进得太快，小球知道它将要去哪在遇到斜率上升时能够知道减速。</p>\n<h4 id=\"Adagrad\"><a href=\"#Adagrad\" class=\"headerlink\" title=\"Adagrad\"></a>Adagrad</h4><p>Adagrad可以让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此Adagrad非常适合处理稀疏数据如word2vec等。</p>\n<p>Adagrad在每个时刻t对每一个参数$ \\theta _ {i} $都使用不同的学习率$ \\eta $。另$ g _ { t , i }  $为在时刻t目标函数关于参数$ \\theta _ {i} $的梯度：<br>$$<br>g _ { t , i } = \\nabla _ { \\theta } J \\left( \\theta _ { i } \\right)<br>$$<br>在时刻t对每个参数$ \\theta _ {i} $的更新过程为：<br>$$<br>\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\eta \\cdot g _ { t , i }<br>$$<br>在时刻t基于对$ \\theta _ {i} $计算过的历史梯度，Adagrad修正了对每一个参数$ \\theta _ {i} $的学习率：<br>$$<br>\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\frac { \\eta } { \\sqrt { G _ { t , i i } + \\epsilon } } \\cdot g _ { t , i }<br>$$<br>其中$ G _ { t } \\in \\mathbb { R } ^ { d x d }  $是一个对角矩阵，对角线上的元素（i，i）是到t时刻为止所有关于$ \\theta _ {i} $的梯度和。$  \\epsilon $是平滑项用于防止除数为0。</p>\n<p>由于$ G _ {t} $的对角线上包含了所有关于参数$ \\theta $的历史梯度平方和，所以我们可以通过$ G _ {t} $和$ g _ {t} $之间的元素向量乘法⊙向量化上述的操作：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }<br>$$<br>Adagrad算法的主要优点是无需手动调整学习率。它的主要缺点是在分母中累加梯度的平方，在整个训练过程中，累加的和会持续增长，这会导致学习率变小以至于最终变得无限小。</p>\n<p>通常$ \\eta = 0.01$。</p>\n<h4 id=\"RMSprop\"><a href=\"#RMSprop\" class=\"headerlink\" title=\"RMSprop\"></a>RMSprop</h4><p>RMSprop是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不计算所有的梯度平方，Adadelta将计算历史梯度的窗口限制为一个固定值w。</p>\n<p>在RMSprop中将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$ E[ g ^ { 2 }] _ { t } $只取决于先前的均值和当前的梯度（分量$ \\gamma $类似于动量项）：<br>$$<br>E \\left[ g ^ { 2 } \\right] _ { t } = \\gamma E \\left[ g ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) g _ { t } ^ { 2 }<br>$$<br>Adagrad的参数更新向量为：<br>$$<br>\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }<br>$$<br>现在我们简单将对角矩阵$ G _ {t} $替换成历史梯度的均值$ E[ g ^ { 2 }] _ { t } $：<br>$$<br>\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { E \\left[ g ^ { 2 } \\right] _ { t } + \\epsilon } } g _ { t }<br>$$<br>最终得到RMSprop的更新规则为：<br>$$<br>\\theta _ {t+1} = \\theta _ i - \\frac{\\eta}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}<br>$$<br>通常$ \\eta = 0.001$。</p>\n<h4 id=\"Adadelta\"><a href=\"#Adadelta\" class=\"headerlink\" title=\"Adadelta\"></a>Adadelta</h4><p>Adadelta也是一种对Adagrad的改进算法，但是其比RMSprop多了一些操作。Adadelta的作者认为RMSprop更新公式中的每个部分并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方而是参数的平方的更新：<br>$$<br>E \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t } = \\gamma E \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) \\Delta \\theta _ { t } ^ { 2 }<br>$$<br>利用$ E [ \\Delta \\theta ^ { 2 } ] _ { t -1 } $替换先前的更新规则中的学习率$ \\eta $，最终得到Adadelta的更新规则：<br>$$<br>\\theta _ {t+1} = \\theta _ i - \\frac{\\sqrt{E[\\Delta\\theta^2] _ {t-1} + \\epsilon}}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}<br>$$<br>Adadelta中我们甚至不用设置初始学习率。通常$ \\gamma = 0.9 $。</p>\n<h4 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h4><p>自适应矩估计（Adaptive Moment Estimation，Adam）是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个历史平方梯度的指数衰减均值$ v _ {t} $，Adam同时还保存一个历史梯度的指数衰减均值$ m _ {t} $，类似于动量：<br>$$<br>\\begin{aligned} m _ { t } &amp; = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t } \\end{aligned}<br>$$<br>$$<br>\\begin{aligned} v _ { t } &amp; = \\beta _ { 2 } v _ { t - 1 } + \\left( 1 - \\beta _ { 2 } \\right) g _ { t } ^ { 2 } \\end{aligned}<br>$$<br>$ m _ {t} $和$ v _ {t} $分别是对梯度的一阶矩（均值）和二阶矩（方差）的估计。当 m _ {t} $和$ v _ {t} $的初始值为0向量时，Adam的作者发现它们在训练初期都偏向于0（β1和β2趋向于1），从而训练缓慢。</p>\n<p>通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：<br>$$<br>\\begin{aligned} \\hat { m } _ { t } &amp; = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\end{aligned}<br>$$<br>$$<br>\\begin{aligned} \\hat { v } _ { t } &amp; = \\frac { v _ { t } } { 1 - \\beta _ { 2 } ^ { t } } \\end{aligned}<br>$$<br>最终Adam的更新规则：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\hat { m } _ { t }<br>$$<br>一般$ \\eta = 0.001，\\beta _ { 1 }  = 0.9，\\beta _ { 1 } = 0.999，\\epsilon=1e−8 $。</p>\n<h4 id=\"AdaMax\"><a href=\"#AdaMax\" class=\"headerlink\" title=\"AdaMax\"></a>AdaMax</h4><p>AdaMax是Adam的一种变体。<br>$$<br>u _ t = {\\lim _ {p \\to +\\infty}}(v _ t)^{1/p} = max(\\beta _ 2u _ {t-1},|g _ {t}|)<br>$$</p>\n<p>$$<br>m _ { t } = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t }<br>$$</p>\n<p>$$<br>\\hat { m } _ { t } = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } }<br>$$</p>\n<p>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { u _ { t } } \\odot \\hat { m } _ { t }<br>$$</p>\n<p>一般$ \\eta = 0.002，\\beta _ { 1 } = 0.9，\\beta _ { 2 } = 0.999，\\epsilon = 1e-8 $。</p>\n<h4 id=\"Nadam\"><a href=\"#Nadam\" class=\"headerlink\" title=\"Nadam\"></a>Nadam</h4><p>Nadam是带有NAG项的Adam，Adam公式展开如下：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\frac { \\beta _ { 1 } m _ { t - 1 } } { 1 - \\beta _ { 1 } ^ { t } } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)<br>$$<br>带进Adam的偏差校正为：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t - 1 } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)<br>$$<br>结合NAG的思想我们使用$ \\hat { m } _ { t }  $代替$ \\hat { m } _ { t - 1 }  $就得到Nadam的公式：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)<br>$$</p>\n<h3 id=\"SGD优化算法的选择\"><a href=\"#SGD优化算法的选择\" class=\"headerlink\" title=\"SGD优化算法的选择\"></a>SGD优化算法的选择</h3><ul>\n<li>各自适应学习率的优化算法表现不分伯仲，没有哪个算法能在所有任务上脱颖而出。</li>\n<li>目前，最流行并且使用很高的优化算法包括SGD、带动量的SGD和Adam。</li>\n<li>具体使用哪个算法取决于使用者对算法的熟悉程度，以便调节超参数。</li>\n</ul>\n<h3 id=\"算法可视化\"><a href=\"#算法可视化\" class=\"headerlink\" title=\"算法可视化\"></a>算法可视化</h3><ul>\n<li><p>SGD各优化算法在损失曲面的表现<br><img src=\"/2018/08/10/梯度下降优化算法/4.gif\" alt=\"\"></p>\n</li>\n<li><p>SGD 各优化方法在鞍点的表现<br><img src=\"/2018/08/10/梯度下降优化算法/5.gif\" alt=\"\"></p>\n</li>\n</ul>\n<p>参考：<br><a href=\"https://arxiv.org/pdf/1609.04747.pdf\" target=\"_blank\" rel=\"noopener\">An overview of gradient descent optimization algorithms</a><br><a href=\"https://blog.csdn.net/google19890102/article/details/69942970\" target=\"_blank\" rel=\"noopener\">梯度下降优化算法综述</a></p>\n","site":{"data":{}},"excerpt":"<p>梯度下降是最著名的优化算法之一，也是我们在训练神经网络过程中不可缺少的优化算法，了解梯度下降以及它的各种优化算法是必需的。</p>\n<h3 id=\"梯度下降形式\"><a href=\"#梯度下降形式\" class=\"headerlink\" title=\"梯度下降形式\"></a>梯度下降形式</h3><p>梯度下降有三种不同的变形形式。根据数据量的不同，在参数更新精度和训练所需时间上各有一些差异。<br></p>","more":"<p></p>\n<h4 id=\"批梯度下降法\"><a href=\"#批梯度下降法\" class=\"headerlink\" title=\"批梯度下降法\"></a>批梯度下降法</h4><p>批梯度下降法（batch gradient descent）在整个训练集上计算损失函数关于参数$  \\theta $的梯度：<br>$$<br>\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J ( \\theta )<br>$$<br>因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，并且批梯度下降法无法处理超出内存容量限制的数据集。</p>\n<h4 id=\"随机梯度下降法\"><a href=\"#随机梯度下降法\" class=\"headerlink\" title=\"随机梯度下降法\"></a>随机梯度下降法</h4><p>与批梯度下降法相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$ x ^ { ( i ) } $和标签$ y ^ { ( i ) } $更新参数：<br>$$<br>\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i ) } ; y ^ { ( i ) } \\right)<br>$$<br>对于每一条样本SGD都更新参数，会导致目标函数出现剧烈波动。这种剧烈波动一方面会使SGD跳到潜在的更好局部最优解，但是另一方面这也使收敛过程变得缓慢复杂。<br><img src=\"/2018/08/10/梯度下降优化算法/1.png\" alt=\"\"></p>\n<h4 id=\"小批量梯度下降法\"><a href=\"#小批量梯度下降法\" class=\"headerlink\" title=\"小批量梯度下降法\"></a>小批量梯度下降法</h4><p>小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：<br>$$<br>\\theta = \\theta - \\eta \\cdot \\nabla _ { \\theta } J \\left( \\theta ; x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } \\right)<br>$$<br>这种方法减少参数更新的频率可以得到更稳定的收敛效果，也可以利用最新的矩阵优化算法高效的求解小批量数据梯度。我们也将小批量梯度下降法称为SGD，下文中为了简单我们省略参数$ x ^ { ( i : i + n ) } ; y ^ { ( i : i + n ) } $。</p>\n<h3 id=\"挑战\"><a href=\"#挑战\" class=\"headerlink\" title=\"挑战\"></a>挑战</h3><p>单纯的只使用SGD会有一些问题：</p>\n<ul>\n<li>选择一个合适的学习率可能是困难的。</li>\n<li>学习率调整策略无法适应所有数据集。</li>\n<li>对所有的参数更新使用同样的学习率。如果特征数据是稀疏的并且出现的频率差异很大，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们希望使用更大的学习率。</li>\n</ul>\n<h3 id=\"梯度下降优化算法\"><a href=\"#梯度下降优化算法\" class=\"headerlink\" title=\"梯度下降优化算法\"></a>梯度下降优化算法</h3><h4 id=\"动量法（momentum）\"><a href=\"#动量法（momentum）\" class=\"headerlink\" title=\"动量法（momentum）\"></a>动量法（momentum）</h4><p>momentum是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。momentum将历史更新向量的一个分量增加到当前的更新向量中：<br>$$<br>v _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J ( \\theta )<br>$$<br>$$<br>\\theta = \\theta - v _ { t }<br>$$<br>动量项$ \\gamma $通常设置为0.9。<br><img src=\"/2018/08/10/梯度下降优化算法/2.png\" alt=\"\"></p>\n<p>momentum就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同方向的维度，其动量项增大；对于在梯度点处改变方向的维度，其动量项减小。所以我们可以得到更快的收敛速度并且减少摇摆。</p>\n<h4 id=\"Nesterov加速梯度下降法\"><a href=\"#Nesterov加速梯度下降法\" class=\"headerlink\" title=\"Nesterov加速梯度下降法\"></a>Nesterov加速梯度下降法</h4><p>Nesterov加速梯度下降法（Nesterov accelerated gradient，NAG）是momentum的改进，是一种能够给动量项预知能力的方法：<br>$$<br>v _ { t } = \\gamma v _ { t - 1 } + \\eta \\nabla _ { \\theta } J \\left( \\theta - \\gamma v _ { t - 1 } \\right)<br>$$<br>$$<br>\\theta = \\theta - v _ { t }<br>$$<br>动量项$ \\gamma $通常设置为0.9。<br><img src=\"/2018/08/10/梯度下降优化算法/3.png\" alt=\"\"></p>\n<p>NAG相对于momentum，是先走到将来可能到达的点C然后在C点计算梯度，momentum是在B点计算梯度。NAG这个具有预见性的更新防止我们前进得太快，小球知道它将要去哪在遇到斜率上升时能够知道减速。</p>\n<h4 id=\"Adagrad\"><a href=\"#Adagrad\" class=\"headerlink\" title=\"Adagrad\"></a>Adagrad</h4><p>Adagrad可以让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此Adagrad非常适合处理稀疏数据如word2vec等。</p>\n<p>Adagrad在每个时刻t对每一个参数$ \\theta _ {i} $都使用不同的学习率$ \\eta $。另$ g _ { t , i }  $为在时刻t目标函数关于参数$ \\theta _ {i} $的梯度：<br>$$<br>g _ { t , i } = \\nabla _ { \\theta } J \\left( \\theta _ { i } \\right)<br>$$<br>在时刻t对每个参数$ \\theta _ {i} $的更新过程为：<br>$$<br>\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\eta \\cdot g _ { t , i }<br>$$<br>在时刻t基于对$ \\theta _ {i} $计算过的历史梯度，Adagrad修正了对每一个参数$ \\theta _ {i} $的学习率：<br>$$<br>\\theta _ { t + 1 , i } = \\theta _ { t , i } - \\frac { \\eta } { \\sqrt { G _ { t , i i } + \\epsilon } } \\cdot g _ { t , i }<br>$$<br>其中$ G _ { t } \\in \\mathbb { R } ^ { d x d }  $是一个对角矩阵，对角线上的元素（i，i）是到t时刻为止所有关于$ \\theta _ {i} $的梯度和。$  \\epsilon $是平滑项用于防止除数为0。</p>\n<p>由于$ G _ {t} $的对角线上包含了所有关于参数$ \\theta $的历史梯度平方和，所以我们可以通过$ G _ {t} $和$ g _ {t} $之间的元素向量乘法⊙向量化上述的操作：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }<br>$$<br>Adagrad算法的主要优点是无需手动调整学习率。它的主要缺点是在分母中累加梯度的平方，在整个训练过程中，累加的和会持续增长，这会导致学习率变小以至于最终变得无限小。</p>\n<p>通常$ \\eta = 0.01$。</p>\n<h4 id=\"RMSprop\"><a href=\"#RMSprop\" class=\"headerlink\" title=\"RMSprop\"></a>RMSprop</h4><p>RMSprop是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不计算所有的梯度平方，Adadelta将计算历史梯度的窗口限制为一个固定值w。</p>\n<p>在RMSprop中将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$ E[ g ^ { 2 }] _ { t } $只取决于先前的均值和当前的梯度（分量$ \\gamma $类似于动量项）：<br>$$<br>E \\left[ g ^ { 2 } \\right] _ { t } = \\gamma E \\left[ g ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) g _ { t } ^ { 2 }<br>$$<br>Adagrad的参数更新向量为：<br>$$<br>\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { G _ { t } + \\epsilon } } \\odot g _ { t }<br>$$<br>现在我们简单将对角矩阵$ G _ {t} $替换成历史梯度的均值$ E[ g ^ { 2 }] _ { t } $：<br>$$<br>\\Delta \\theta _ { t } = - \\frac { \\eta } { \\sqrt { E \\left[ g ^ { 2 } \\right] _ { t } + \\epsilon } } g _ { t }<br>$$<br>最终得到RMSprop的更新规则为：<br>$$<br>\\theta _ {t+1} = \\theta _ i - \\frac{\\eta}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}<br>$$<br>通常$ \\eta = 0.001$。</p>\n<h4 id=\"Adadelta\"><a href=\"#Adadelta\" class=\"headerlink\" title=\"Adadelta\"></a>Adadelta</h4><p>Adadelta也是一种对Adagrad的改进算法，但是其比RMSprop多了一些操作。Adadelta的作者认为RMSprop更新公式中的每个部分并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方而是参数的平方的更新：<br>$$<br>E \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t } = \\gamma E \\left[ \\Delta \\theta ^ { 2 } \\right] _ { t - 1 } + ( 1 - \\gamma ) \\Delta \\theta _ { t } ^ { 2 }<br>$$<br>利用$ E [ \\Delta \\theta ^ { 2 } ] _ { t -1 } $替换先前的更新规则中的学习率$ \\eta $，最终得到Adadelta的更新规则：<br>$$<br>\\theta _ {t+1} = \\theta _ i - \\frac{\\sqrt{E[\\Delta\\theta^2] _ {t-1} + \\epsilon}}{\\sqrt{E[g^2] _ t + \\epsilon}} \\bigodot g _ {t}<br>$$<br>Adadelta中我们甚至不用设置初始学习率。通常$ \\gamma = 0.9 $。</p>\n<h4 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h4><p>自适应矩估计（Adaptive Moment Estimation，Adam）是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个历史平方梯度的指数衰减均值$ v _ {t} $，Adam同时还保存一个历史梯度的指数衰减均值$ m _ {t} $，类似于动量：<br>$$<br>\\begin{aligned} m _ { t } &amp; = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t } \\end{aligned}<br>$$<br>$$<br>\\begin{aligned} v _ { t } &amp; = \\beta _ { 2 } v _ { t - 1 } + \\left( 1 - \\beta _ { 2 } \\right) g _ { t } ^ { 2 } \\end{aligned}<br>$$<br>$ m _ {t} $和$ v _ {t} $分别是对梯度的一阶矩（均值）和二阶矩（方差）的估计。当 m _ {t} $和$ v _ {t} $的初始值为0向量时，Adam的作者发现它们在训练初期都偏向于0（β1和β2趋向于1），从而训练缓慢。</p>\n<p>通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：<br>$$<br>\\begin{aligned} \\hat { m } _ { t } &amp; = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\end{aligned}<br>$$<br>$$<br>\\begin{aligned} \\hat { v } _ { t } &amp; = \\frac { v _ { t } } { 1 - \\beta _ { 2 } ^ { t } } \\end{aligned}<br>$$<br>最终Adam的更新规则：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\hat { m } _ { t }<br>$$<br>一般$ \\eta = 0.001，\\beta _ { 1 }  = 0.9，\\beta _ { 1 } = 0.999，\\epsilon=1e−8 $。</p>\n<h4 id=\"AdaMax\"><a href=\"#AdaMax\" class=\"headerlink\" title=\"AdaMax\"></a>AdaMax</h4><p>AdaMax是Adam的一种变体。<br>$$<br>u _ t = {\\lim _ {p \\to +\\infty}}(v _ t)^{1/p} = max(\\beta _ 2u _ {t-1},|g _ {t}|)<br>$$</p>\n<p>$$<br>m _ { t } = \\beta _ { 1 } m _ { t - 1 } + \\left( 1 - \\beta _ { 1 } \\right) g _ { t }<br>$$</p>\n<p>$$<br>\\hat { m } _ { t } = \\frac { m _ { t } } { 1 - \\beta _ { 1 } ^ { t } }<br>$$</p>\n<p>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { u _ { t } } \\odot \\hat { m } _ { t }<br>$$</p>\n<p>一般$ \\eta = 0.002，\\beta _ { 1 } = 0.9，\\beta _ { 2 } = 0.999，\\epsilon = 1e-8 $。</p>\n<h4 id=\"Nadam\"><a href=\"#Nadam\" class=\"headerlink\" title=\"Nadam\"></a>Nadam</h4><p>Nadam是带有NAG项的Adam，Adam公式展开如下：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\frac { \\beta _ { 1 } m _ { t - 1 } } { 1 - \\beta _ { 1 } ^ { t } } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)<br>$$<br>带进Adam的偏差校正为：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t - 1 } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)<br>$$<br>结合NAG的思想我们使用$ \\hat { m } _ { t }  $代替$ \\hat { m } _ { t - 1 }  $就得到Nadam的公式：<br>$$<br>\\theta _ { t + 1 } = \\theta _ { t } - \\frac { \\eta } { \\sqrt { \\hat { v } _ { t } } + \\epsilon } \\left( \\beta _ { 1 } \\hat { m } _ { t } + \\frac { \\left( 1 - \\beta _ { 1 } \\right) g _ { t } } { 1 - \\beta _ { 1 } ^ { t } } \\right)<br>$$</p>\n<h3 id=\"SGD优化算法的选择\"><a href=\"#SGD优化算法的选择\" class=\"headerlink\" title=\"SGD优化算法的选择\"></a>SGD优化算法的选择</h3><ul>\n<li>各自适应学习率的优化算法表现不分伯仲，没有哪个算法能在所有任务上脱颖而出。</li>\n<li>目前，最流行并且使用很高的优化算法包括SGD、带动量的SGD和Adam。</li>\n<li>具体使用哪个算法取决于使用者对算法的熟悉程度，以便调节超参数。</li>\n</ul>\n<h3 id=\"算法可视化\"><a href=\"#算法可视化\" class=\"headerlink\" title=\"算法可视化\"></a>算法可视化</h3><ul>\n<li><p>SGD各优化算法在损失曲面的表现<br><img src=\"/2018/08/10/梯度下降优化算法/4.gif\" alt=\"\"></p>\n</li>\n<li><p>SGD 各优化方法在鞍点的表现<br><img src=\"/2018/08/10/梯度下降优化算法/5.gif\" alt=\"\"></p>\n</li>\n</ul>\n<p>参考：<br><a href=\"https://arxiv.org/pdf/1609.04747.pdf\" target=\"_blank\" rel=\"noopener\">An overview of gradient descent optimization algorithms</a><br><a href=\"https://blog.csdn.net/google19890102/article/details/69942970\" target=\"_blank\" rel=\"noopener\">梯度下降优化算法综述</a></p>"},{"title":"语音识别基本原理","author":"liuyan","catalog":true,"date":"2017-10-07T07:32:30.000Z","urlname":null,"_content":"\n## 语音识别基本架构\n\n![](1.png)\n\n上式中W表示文字序列，Y表示语音输入。\n\n公式1表示语音识别的目标是在给定语音输入的情况下，找到可能性最大的文字序列。\n\n根据贝叶斯定理，可以得到公式2，其中分母表示出现这条语音的概率，它相比于求解的文字序列没有参数关系，可以在求解时忽略，进而得到公式3。\n\n公式3中第一部分表示给定一个文字序列出现这条音频的概率，它就是语音识别中的声学模型；第二部分表示出现这个文字序列的概率，它就是语音识别中的语言模型。\n\n无论是传统的方法也好，现在火热的深度神经网络的方法也罢，目前的语音识别在架构上都没有脱离上面的公式，也就是说都离不开AM和LM。\n\n<!-- more -->\n\n下面分别对这两部分进行介绍。\n\n## 声学模型（Acoustic Model，AM）\n\n声学模型可以理解为是对发声的建模，它能够把语音输入转换成声学表示的输出，更准确的说是给出语音属于某个声学符号的概率。在英文中这个声学符号可以是音节或者更小的颗粒度音素（phone）；在中文中这个声学符号可以是声韵母或者是颗粒度同英文一样小的音素。\n\n### CD-DNN—HMM模型\n\n公式3中的声学模型就可以表示为下面公式4的形式：\n\n![](2.png)\n\n其中Q表示发音单位的序列。从公式中可以看到，声学模型最终转换成了一个语音到发音序列的模型和一个发音序列到输出文字序列的字典。这里的发音序列通常是音素，到此为止声学模型是从语音到音素状态的一个描述。\n\n为了对不同上下文的音素加以区分，通常使用上下文相关的“三音子”作为建模单元。可以用下图表示：\n\n![](3.png)\n\n公式4中的字典部分表示为如下公式5，其意义是把每个文字拆分成若干发音符号的序列。\n\n![](4.png)\n\n公式4中的声学部分可以继续分解为如下公式6：\n\n![](5.png)\n\n公式6表示声学建模的颗粒度可以继续分解为更小的状态（state）。通常一个三音子对应有3个状态（静音通常是5个状态），那么声学建模的总数就是3\\*Q^3+5这么多。为了压缩建模单元数量，状态绑定的技术被大量使用，它使得发音类似的状态用一个模型表示，从而减少了参数量。具体绑定形式如下图所示：\n\n![](6.png)\n\n基于上面的推导，声学模型是一个描述语音和状态之间转换的模型。\n此时，引入HMM假设：状态是隐变量，语音是观测值，状态之间的跳转符合马尔科夫假设。那么声学模型可以继续表示为如下公式：\n\n![](7.png)\n\n其中a表示转移概率，b表示发射概率。用图来表示的话就是下图中的结构：\n\n![](8.png)\n\n如图中所示，观测概率通常用GMM或是DNN来描述。这就是CD-GMM-HMM架构和CD-DNN-HMM架构的语音识别声学模型。CD-DNN-HMM的架构图表示如下：\n\n![](9.png)\n\n### CTC模型\n\n在基于CD-DNN-HMM架构的语音识别声学模型中，训练DNN通常需要帧对齐标签。在GMM中，这个对齐操作是通过EM算法不断迭代完成的。\n- E-step：估计(重估)GMM参数\n- M-step：使用BW(Baum-Welch算法)对齐\n\n此外对于HMM假设一直受到诟病，等到RNN出现之后，使用RNN来对时序关系进行描述来取代HMM成为当时的热潮。\n\n随着神经网络优化技术的发展和GPU计算能力的不断提升，最终使用RNN和CTC来进行建模实现了end-to-end语音识别的声学模型。\n\nCTC的全称是Connectionist Temporal Classification，中文翻译大概是连接时序分类。它要达到的目标就是直接将语音和相应的文字对应起来，实现时序问题的分类。\n用公式来描述的话，CTC的公式推导如下：\n$$\np ( \\pi | x ) = \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t } , \\forall \\pi \\in L ^ { T }\n$$\n\n其中π表示文字序列，X表示语音输入，y表示RNN的输出。由于很多帧可以输出同样的一个文字，同时很多帧也可以没有任何输出，因此定义了一个多对一的函数，把输出序列中重复的字符合并起来，形成唯一的序列，进而公式表示如下：\n$$\np ( l | x ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) } p ( \\pi | x )\n$$\n\n起始l表示对应的标注文本，而π是带有冗余的神经网络输出。求解上述公式，需要使用前后向算法。\n\n前向因子：\n$$\n\\alpha _ { t } ( s ) \\stackrel { d e f } { = } \\sum _ { \\pi \\in N ^ { t } : \\Re \\left( \\pi _ { 1 : t } = l _ { 1 : s } \\right) t ^ { \\prime } = 1 } ^ { t } y _ { \\pi _ { t } ^ { \\prime } } ^ { t ^ { \\prime } }\n$$\n\n后向因子：\n$$\n\\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }\n$$\n\n那么神经网络的输出和前后向因子的关系可以表示为：\n$$\n\\alpha _ { t } ( s ) \\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }\n$$\n\n进而得到：\n$$\np ( l | x ) = \\sum _ { s = 1 } ^ { \\left| l ^ { \\prime } \\right| } \\frac { \\alpha _ { t } ( s ) \\beta _ { t } ( s ) } { y _ { l _ { s } ^ { t } } }\n$$\n\n利用上述公式，就可以进行神经网络的训练了，这里仍然可以描述为EM的思想：\n\n- E步：使用BPTT算法优化神经网络参数；\n- M步：使用神经网络的输出，重新寻找最优的对齐关系。\n\nCTC可以看成是一个分类方法，甚至可以看作是目标函数。在构建end-to-end声学模型的过程中，CTC起到了很好的自动对齐的效果。同传统的基于CD-DNN-HMM的方法相比，对齐效果是这样的：\n\n![](10.png)\n\n基于帧对齐的方法强制要求切分好的帧对齐到对应的标签上去，而CTC则可以时帧的输出为空，只有少数帧对齐到对应的输出标签上。\n\n### End-to-End模型\n\n由于神经网络强大的建模能力，End-to-End的输出标签也不再需要像传统架构一样的进行细分。例如对于中文，输出不再需要进行细分为状态、音素或者声韵母，直接将汉字作为输出即可；对于英文，考虑到英文单词的数量庞大，可以使用字母作为输出标签。\n\n从这一点出发，我们可以认为神经网络将声学符号到字符串的映射关系也一并建模学习了出来，这部分是在传统的框架中时词典所应承担的任务。针对这个模块，传统框架中有一个专门的建模单元叫做G2P（grapheme-to-phoneme），来处理集外词（out of vocabulary，OOV）。在End-to-End的声学模型中，可以没有词典，没有OOV，也没有G2P。这些全都被建模在一个神经网络中。\n\n另外，在传统的框架结构中，语音需要分帧，加窗，提取特征（MFCC、PLP等）。在基于神经网络的声学模型中，通常使用更裸的Fbank特征。在End-to-End的识别中，使用更简单的特征比如FFT等也是常见的做法。或许在不久的将来，语音的采样点也可以作为输入，这就是更加彻底的End-to-End声学模型。\n\n除此之外，End-to-End的声学模型中已经带有了语言模型的信息，它是通过RNN在输出序列上学习得到的。但这个语言模型仍然比较弱，如果外加一个更大数据量的语言模型，解码的效果会更好。因此，End-to-End现在指声学模型部分，等到不需要语言模型的时候，才是完全的End-to-End。\n\n## 语言模型（Language Model， LM）\n\n语言模型的作用之一为消解多音字的问题，在声学模型给出发音序列之后，从候选的文字序列中找出概率最大的字符串序列。\n语言模型还会对声学的解码作约束和重打分，让最终识别结果符合语法规则。目前最常见的是N-Gram语言模型和基于RNN的语言模型。\n\n## 解码\n\n传统的语音识别解码都是建立在WFST的基础之上，它是将HMM、词典以及语言模型编译成一个网络。解码就是在这个WFST构造的动态网络空间中，找到最优的输出字符序列。搜索通常使用Viterbi算法，另外为了防止搜索空间爆炸，通常会采用剪枝算法，因此搜索得到的结果可能不是最优结果。\n","source":"_posts/语音识别基本原理.md","raw":"---\ntitle:      语音识别基本原理\nauthor:     liuyan\ncatalog:    true\ntags:\n  - 语音识别\ndate:       2017-10-07 15:32:30\nurlname:\ncategories: 语音识别\n---\n\n## 语音识别基本架构\n\n![](1.png)\n\n上式中W表示文字序列，Y表示语音输入。\n\n公式1表示语音识别的目标是在给定语音输入的情况下，找到可能性最大的文字序列。\n\n根据贝叶斯定理，可以得到公式2，其中分母表示出现这条语音的概率，它相比于求解的文字序列没有参数关系，可以在求解时忽略，进而得到公式3。\n\n公式3中第一部分表示给定一个文字序列出现这条音频的概率，它就是语音识别中的声学模型；第二部分表示出现这个文字序列的概率，它就是语音识别中的语言模型。\n\n无论是传统的方法也好，现在火热的深度神经网络的方法也罢，目前的语音识别在架构上都没有脱离上面的公式，也就是说都离不开AM和LM。\n\n<!-- more -->\n\n下面分别对这两部分进行介绍。\n\n## 声学模型（Acoustic Model，AM）\n\n声学模型可以理解为是对发声的建模，它能够把语音输入转换成声学表示的输出，更准确的说是给出语音属于某个声学符号的概率。在英文中这个声学符号可以是音节或者更小的颗粒度音素（phone）；在中文中这个声学符号可以是声韵母或者是颗粒度同英文一样小的音素。\n\n### CD-DNN—HMM模型\n\n公式3中的声学模型就可以表示为下面公式4的形式：\n\n![](2.png)\n\n其中Q表示发音单位的序列。从公式中可以看到，声学模型最终转换成了一个语音到发音序列的模型和一个发音序列到输出文字序列的字典。这里的发音序列通常是音素，到此为止声学模型是从语音到音素状态的一个描述。\n\n为了对不同上下文的音素加以区分，通常使用上下文相关的“三音子”作为建模单元。可以用下图表示：\n\n![](3.png)\n\n公式4中的字典部分表示为如下公式5，其意义是把每个文字拆分成若干发音符号的序列。\n\n![](4.png)\n\n公式4中的声学部分可以继续分解为如下公式6：\n\n![](5.png)\n\n公式6表示声学建模的颗粒度可以继续分解为更小的状态（state）。通常一个三音子对应有3个状态（静音通常是5个状态），那么声学建模的总数就是3\\*Q^3+5这么多。为了压缩建模单元数量，状态绑定的技术被大量使用，它使得发音类似的状态用一个模型表示，从而减少了参数量。具体绑定形式如下图所示：\n\n![](6.png)\n\n基于上面的推导，声学模型是一个描述语音和状态之间转换的模型。\n此时，引入HMM假设：状态是隐变量，语音是观测值，状态之间的跳转符合马尔科夫假设。那么声学模型可以继续表示为如下公式：\n\n![](7.png)\n\n其中a表示转移概率，b表示发射概率。用图来表示的话就是下图中的结构：\n\n![](8.png)\n\n如图中所示，观测概率通常用GMM或是DNN来描述。这就是CD-GMM-HMM架构和CD-DNN-HMM架构的语音识别声学模型。CD-DNN-HMM的架构图表示如下：\n\n![](9.png)\n\n### CTC模型\n\n在基于CD-DNN-HMM架构的语音识别声学模型中，训练DNN通常需要帧对齐标签。在GMM中，这个对齐操作是通过EM算法不断迭代完成的。\n- E-step：估计(重估)GMM参数\n- M-step：使用BW(Baum-Welch算法)对齐\n\n此外对于HMM假设一直受到诟病，等到RNN出现之后，使用RNN来对时序关系进行描述来取代HMM成为当时的热潮。\n\n随着神经网络优化技术的发展和GPU计算能力的不断提升，最终使用RNN和CTC来进行建模实现了end-to-end语音识别的声学模型。\n\nCTC的全称是Connectionist Temporal Classification，中文翻译大概是连接时序分类。它要达到的目标就是直接将语音和相应的文字对应起来，实现时序问题的分类。\n用公式来描述的话，CTC的公式推导如下：\n$$\np ( \\pi | x ) = \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t } , \\forall \\pi \\in L ^ { T }\n$$\n\n其中π表示文字序列，X表示语音输入，y表示RNN的输出。由于很多帧可以输出同样的一个文字，同时很多帧也可以没有任何输出，因此定义了一个多对一的函数，把输出序列中重复的字符合并起来，形成唯一的序列，进而公式表示如下：\n$$\np ( l | x ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) } p ( \\pi | x )\n$$\n\n起始l表示对应的标注文本，而π是带有冗余的神经网络输出。求解上述公式，需要使用前后向算法。\n\n前向因子：\n$$\n\\alpha _ { t } ( s ) \\stackrel { d e f } { = } \\sum _ { \\pi \\in N ^ { t } : \\Re \\left( \\pi _ { 1 : t } = l _ { 1 : s } \\right) t ^ { \\prime } = 1 } ^ { t } y _ { \\pi _ { t } ^ { \\prime } } ^ { t ^ { \\prime } }\n$$\n\n后向因子：\n$$\n\\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }\n$$\n\n那么神经网络的输出和前后向因子的关系可以表示为：\n$$\n\\alpha _ { t } ( s ) \\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }\n$$\n\n进而得到：\n$$\np ( l | x ) = \\sum _ { s = 1 } ^ { \\left| l ^ { \\prime } \\right| } \\frac { \\alpha _ { t } ( s ) \\beta _ { t } ( s ) } { y _ { l _ { s } ^ { t } } }\n$$\n\n利用上述公式，就可以进行神经网络的训练了，这里仍然可以描述为EM的思想：\n\n- E步：使用BPTT算法优化神经网络参数；\n- M步：使用神经网络的输出，重新寻找最优的对齐关系。\n\nCTC可以看成是一个分类方法，甚至可以看作是目标函数。在构建end-to-end声学模型的过程中，CTC起到了很好的自动对齐的效果。同传统的基于CD-DNN-HMM的方法相比，对齐效果是这样的：\n\n![](10.png)\n\n基于帧对齐的方法强制要求切分好的帧对齐到对应的标签上去，而CTC则可以时帧的输出为空，只有少数帧对齐到对应的输出标签上。\n\n### End-to-End模型\n\n由于神经网络强大的建模能力，End-to-End的输出标签也不再需要像传统架构一样的进行细分。例如对于中文，输出不再需要进行细分为状态、音素或者声韵母，直接将汉字作为输出即可；对于英文，考虑到英文单词的数量庞大，可以使用字母作为输出标签。\n\n从这一点出发，我们可以认为神经网络将声学符号到字符串的映射关系也一并建模学习了出来，这部分是在传统的框架中时词典所应承担的任务。针对这个模块，传统框架中有一个专门的建模单元叫做G2P（grapheme-to-phoneme），来处理集外词（out of vocabulary，OOV）。在End-to-End的声学模型中，可以没有词典，没有OOV，也没有G2P。这些全都被建模在一个神经网络中。\n\n另外，在传统的框架结构中，语音需要分帧，加窗，提取特征（MFCC、PLP等）。在基于神经网络的声学模型中，通常使用更裸的Fbank特征。在End-to-End的识别中，使用更简单的特征比如FFT等也是常见的做法。或许在不久的将来，语音的采样点也可以作为输入，这就是更加彻底的End-to-End声学模型。\n\n除此之外，End-to-End的声学模型中已经带有了语言模型的信息，它是通过RNN在输出序列上学习得到的。但这个语言模型仍然比较弱，如果外加一个更大数据量的语言模型，解码的效果会更好。因此，End-to-End现在指声学模型部分，等到不需要语言模型的时候，才是完全的End-to-End。\n\n## 语言模型（Language Model， LM）\n\n语言模型的作用之一为消解多音字的问题，在声学模型给出发音序列之后，从候选的文字序列中找出概率最大的字符串序列。\n语言模型还会对声学的解码作约束和重打分，让最终识别结果符合语法规则。目前最常见的是N-Gram语言模型和基于RNN的语言模型。\n\n## 解码\n\n传统的语音识别解码都是建立在WFST的基础之上，它是将HMM、词典以及语言模型编译成一个网络。解码就是在这个WFST构造的动态网络空间中，找到最优的输出字符序列。搜索通常使用Viterbi算法，另外为了防止搜索空间爆炸，通常会采用剪枝算法，因此搜索得到的结果可能不是最优结果。\n","slug":"语音识别基本原理","published":1,"updated":"2019-01-15T09:43:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxku2ng002mly0gqz2wzb9n","content":"<h2 id=\"语音识别基本架构\"><a href=\"#语音识别基本架构\" class=\"headerlink\" title=\"语音识别基本架构\"></a>语音识别基本架构</h2><p><img src=\"/2017/10/07/语音识别基本原理/1.png\" alt=\"\"></p>\n<p>上式中W表示文字序列，Y表示语音输入。</p>\n<p>公式1表示语音识别的目标是在给定语音输入的情况下，找到可能性最大的文字序列。</p>\n<p>根据贝叶斯定理，可以得到公式2，其中分母表示出现这条语音的概率，它相比于求解的文字序列没有参数关系，可以在求解时忽略，进而得到公式3。</p>\n<p>公式3中第一部分表示给定一个文字序列出现这条音频的概率，它就是语音识别中的声学模型；第二部分表示出现这个文字序列的概率，它就是语音识别中的语言模型。</p>\n<p>无论是传统的方法也好，现在火热的深度神经网络的方法也罢，目前的语音识别在架构上都没有脱离上面的公式，也就是说都离不开AM和LM。</p>\n<a id=\"more\"></a>\n<p>下面分别对这两部分进行介绍。</p>\n<h2 id=\"声学模型（Acoustic-Model，AM）\"><a href=\"#声学模型（Acoustic-Model，AM）\" class=\"headerlink\" title=\"声学模型（Acoustic Model，AM）\"></a>声学模型（Acoustic Model，AM）</h2><p>声学模型可以理解为是对发声的建模，它能够把语音输入转换成声学表示的输出，更准确的说是给出语音属于某个声学符号的概率。在英文中这个声学符号可以是音节或者更小的颗粒度音素（phone）；在中文中这个声学符号可以是声韵母或者是颗粒度同英文一样小的音素。</p>\n<h3 id=\"CD-DNN—HMM模型\"><a href=\"#CD-DNN—HMM模型\" class=\"headerlink\" title=\"CD-DNN—HMM模型\"></a>CD-DNN—HMM模型</h3><p>公式3中的声学模型就可以表示为下面公式4的形式：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/2.png\" alt=\"\"></p>\n<p>其中Q表示发音单位的序列。从公式中可以看到，声学模型最终转换成了一个语音到发音序列的模型和一个发音序列到输出文字序列的字典。这里的发音序列通常是音素，到此为止声学模型是从语音到音素状态的一个描述。</p>\n<p>为了对不同上下文的音素加以区分，通常使用上下文相关的“三音子”作为建模单元。可以用下图表示：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/3.png\" alt=\"\"></p>\n<p>公式4中的字典部分表示为如下公式5，其意义是把每个文字拆分成若干发音符号的序列。</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/4.png\" alt=\"\"></p>\n<p>公式4中的声学部分可以继续分解为如下公式6：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/5.png\" alt=\"\"></p>\n<p>公式6表示声学建模的颗粒度可以继续分解为更小的状态（state）。通常一个三音子对应有3个状态（静音通常是5个状态），那么声学建模的总数就是3*Q^3+5这么多。为了压缩建模单元数量，状态绑定的技术被大量使用，它使得发音类似的状态用一个模型表示，从而减少了参数量。具体绑定形式如下图所示：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/6.png\" alt=\"\"></p>\n<p>基于上面的推导，声学模型是一个描述语音和状态之间转换的模型。<br>此时，引入HMM假设：状态是隐变量，语音是观测值，状态之间的跳转符合马尔科夫假设。那么声学模型可以继续表示为如下公式：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/7.png\" alt=\"\"></p>\n<p>其中a表示转移概率，b表示发射概率。用图来表示的话就是下图中的结构：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/8.png\" alt=\"\"></p>\n<p>如图中所示，观测概率通常用GMM或是DNN来描述。这就是CD-GMM-HMM架构和CD-DNN-HMM架构的语音识别声学模型。CD-DNN-HMM的架构图表示如下：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/9.png\" alt=\"\"></p>\n<h3 id=\"CTC模型\"><a href=\"#CTC模型\" class=\"headerlink\" title=\"CTC模型\"></a>CTC模型</h3><p>在基于CD-DNN-HMM架构的语音识别声学模型中，训练DNN通常需要帧对齐标签。在GMM中，这个对齐操作是通过EM算法不断迭代完成的。</p>\n<ul>\n<li>E-step：估计(重估)GMM参数</li>\n<li>M-step：使用BW(Baum-Welch算法)对齐</li>\n</ul>\n<p>此外对于HMM假设一直受到诟病，等到RNN出现之后，使用RNN来对时序关系进行描述来取代HMM成为当时的热潮。</p>\n<p>随着神经网络优化技术的发展和GPU计算能力的不断提升，最终使用RNN和CTC来进行建模实现了end-to-end语音识别的声学模型。</p>\n<p>CTC的全称是Connectionist Temporal Classification，中文翻译大概是连接时序分类。它要达到的目标就是直接将语音和相应的文字对应起来，实现时序问题的分类。<br>用公式来描述的话，CTC的公式推导如下：<br>$$<br>p ( \\pi | x ) = \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t } , \\forall \\pi \\in L ^ { T }<br>$$</p>\n<p>其中π表示文字序列，X表示语音输入，y表示RNN的输出。由于很多帧可以输出同样的一个文字，同时很多帧也可以没有任何输出，因此定义了一个多对一的函数，把输出序列中重复的字符合并起来，形成唯一的序列，进而公式表示如下：<br>$$<br>p ( l | x ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) } p ( \\pi | x )<br>$$</p>\n<p>起始l表示对应的标注文本，而π是带有冗余的神经网络输出。求解上述公式，需要使用前后向算法。</p>\n<p>前向因子：<br>$$<br>\\alpha _ { t } ( s ) \\stackrel { d e f } { = } \\sum _ { \\pi \\in N ^ { t } : \\Re \\left( \\pi _ { 1 : t } = l _ { 1 : s } \\right) t ^ { \\prime } = 1 } ^ { t } y _ { \\pi _ { t } ^ { \\prime } } ^ { t ^ { \\prime } }<br>$$</p>\n<p>后向因子：<br>$$<br>\\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }<br>$$</p>\n<p>那么神经网络的输出和前后向因子的关系可以表示为：<br>$$<br>\\alpha _ { t } ( s ) \\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }<br>$$</p>\n<p>进而得到：<br>$$<br>p ( l | x ) = \\sum _ { s = 1 } ^ { \\left| l ^ { \\prime } \\right| } \\frac { \\alpha _ { t } ( s ) \\beta _ { t } ( s ) } { y _ { l _ { s } ^ { t } } }<br>$$</p>\n<p>利用上述公式，就可以进行神经网络的训练了，这里仍然可以描述为EM的思想：</p>\n<ul>\n<li>E步：使用BPTT算法优化神经网络参数；</li>\n<li>M步：使用神经网络的输出，重新寻找最优的对齐关系。</li>\n</ul>\n<p>CTC可以看成是一个分类方法，甚至可以看作是目标函数。在构建end-to-end声学模型的过程中，CTC起到了很好的自动对齐的效果。同传统的基于CD-DNN-HMM的方法相比，对齐效果是这样的：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/10.png\" alt=\"\"></p>\n<p>基于帧对齐的方法强制要求切分好的帧对齐到对应的标签上去，而CTC则可以时帧的输出为空，只有少数帧对齐到对应的输出标签上。</p>\n<h3 id=\"End-to-End模型\"><a href=\"#End-to-End模型\" class=\"headerlink\" title=\"End-to-End模型\"></a>End-to-End模型</h3><p>由于神经网络强大的建模能力，End-to-End的输出标签也不再需要像传统架构一样的进行细分。例如对于中文，输出不再需要进行细分为状态、音素或者声韵母，直接将汉字作为输出即可；对于英文，考虑到英文单词的数量庞大，可以使用字母作为输出标签。</p>\n<p>从这一点出发，我们可以认为神经网络将声学符号到字符串的映射关系也一并建模学习了出来，这部分是在传统的框架中时词典所应承担的任务。针对这个模块，传统框架中有一个专门的建模单元叫做G2P（grapheme-to-phoneme），来处理集外词（out of vocabulary，OOV）。在End-to-End的声学模型中，可以没有词典，没有OOV，也没有G2P。这些全都被建模在一个神经网络中。</p>\n<p>另外，在传统的框架结构中，语音需要分帧，加窗，提取特征（MFCC、PLP等）。在基于神经网络的声学模型中，通常使用更裸的Fbank特征。在End-to-End的识别中，使用更简单的特征比如FFT等也是常见的做法。或许在不久的将来，语音的采样点也可以作为输入，这就是更加彻底的End-to-End声学模型。</p>\n<p>除此之外，End-to-End的声学模型中已经带有了语言模型的信息，它是通过RNN在输出序列上学习得到的。但这个语言模型仍然比较弱，如果外加一个更大数据量的语言模型，解码的效果会更好。因此，End-to-End现在指声学模型部分，等到不需要语言模型的时候，才是完全的End-to-End。</p>\n<h2 id=\"语言模型（Language-Model，-LM）\"><a href=\"#语言模型（Language-Model，-LM）\" class=\"headerlink\" title=\"语言模型（Language Model， LM）\"></a>语言模型（Language Model， LM）</h2><p>语言模型的作用之一为消解多音字的问题，在声学模型给出发音序列之后，从候选的文字序列中找出概率最大的字符串序列。<br>语言模型还会对声学的解码作约束和重打分，让最终识别结果符合语法规则。目前最常见的是N-Gram语言模型和基于RNN的语言模型。</p>\n<h2 id=\"解码\"><a href=\"#解码\" class=\"headerlink\" title=\"解码\"></a>解码</h2><p>传统的语音识别解码都是建立在WFST的基础之上，它是将HMM、词典以及语言模型编译成一个网络。解码就是在这个WFST构造的动态网络空间中，找到最优的输出字符序列。搜索通常使用Viterbi算法，另外为了防止搜索空间爆炸，通常会采用剪枝算法，因此搜索得到的结果可能不是最优结果。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"语音识别基本架构\"><a href=\"#语音识别基本架构\" class=\"headerlink\" title=\"语音识别基本架构\"></a>语音识别基本架构</h2><p><img src=\"/2017/10/07/语音识别基本原理/1.png\" alt=\"\"></p>\n<p>上式中W表示文字序列，Y表示语音输入。</p>\n<p>公式1表示语音识别的目标是在给定语音输入的情况下，找到可能性最大的文字序列。</p>\n<p>根据贝叶斯定理，可以得到公式2，其中分母表示出现这条语音的概率，它相比于求解的文字序列没有参数关系，可以在求解时忽略，进而得到公式3。</p>\n<p>公式3中第一部分表示给定一个文字序列出现这条音频的概率，它就是语音识别中的声学模型；第二部分表示出现这个文字序列的概率，它就是语音识别中的语言模型。</p>\n<p>无论是传统的方法也好，现在火热的深度神经网络的方法也罢，目前的语音识别在架构上都没有脱离上面的公式，也就是说都离不开AM和LM。</p>","more":"<p>下面分别对这两部分进行介绍。</p>\n<h2 id=\"声学模型（Acoustic-Model，AM）\"><a href=\"#声学模型（Acoustic-Model，AM）\" class=\"headerlink\" title=\"声学模型（Acoustic Model，AM）\"></a>声学模型（Acoustic Model，AM）</h2><p>声学模型可以理解为是对发声的建模，它能够把语音输入转换成声学表示的输出，更准确的说是给出语音属于某个声学符号的概率。在英文中这个声学符号可以是音节或者更小的颗粒度音素（phone）；在中文中这个声学符号可以是声韵母或者是颗粒度同英文一样小的音素。</p>\n<h3 id=\"CD-DNN—HMM模型\"><a href=\"#CD-DNN—HMM模型\" class=\"headerlink\" title=\"CD-DNN—HMM模型\"></a>CD-DNN—HMM模型</h3><p>公式3中的声学模型就可以表示为下面公式4的形式：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/2.png\" alt=\"\"></p>\n<p>其中Q表示发音单位的序列。从公式中可以看到，声学模型最终转换成了一个语音到发音序列的模型和一个发音序列到输出文字序列的字典。这里的发音序列通常是音素，到此为止声学模型是从语音到音素状态的一个描述。</p>\n<p>为了对不同上下文的音素加以区分，通常使用上下文相关的“三音子”作为建模单元。可以用下图表示：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/3.png\" alt=\"\"></p>\n<p>公式4中的字典部分表示为如下公式5，其意义是把每个文字拆分成若干发音符号的序列。</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/4.png\" alt=\"\"></p>\n<p>公式4中的声学部分可以继续分解为如下公式6：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/5.png\" alt=\"\"></p>\n<p>公式6表示声学建模的颗粒度可以继续分解为更小的状态（state）。通常一个三音子对应有3个状态（静音通常是5个状态），那么声学建模的总数就是3*Q^3+5这么多。为了压缩建模单元数量，状态绑定的技术被大量使用，它使得发音类似的状态用一个模型表示，从而减少了参数量。具体绑定形式如下图所示：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/6.png\" alt=\"\"></p>\n<p>基于上面的推导，声学模型是一个描述语音和状态之间转换的模型。<br>此时，引入HMM假设：状态是隐变量，语音是观测值，状态之间的跳转符合马尔科夫假设。那么声学模型可以继续表示为如下公式：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/7.png\" alt=\"\"></p>\n<p>其中a表示转移概率，b表示发射概率。用图来表示的话就是下图中的结构：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/8.png\" alt=\"\"></p>\n<p>如图中所示，观测概率通常用GMM或是DNN来描述。这就是CD-GMM-HMM架构和CD-DNN-HMM架构的语音识别声学模型。CD-DNN-HMM的架构图表示如下：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/9.png\" alt=\"\"></p>\n<h3 id=\"CTC模型\"><a href=\"#CTC模型\" class=\"headerlink\" title=\"CTC模型\"></a>CTC模型</h3><p>在基于CD-DNN-HMM架构的语音识别声学模型中，训练DNN通常需要帧对齐标签。在GMM中，这个对齐操作是通过EM算法不断迭代完成的。</p>\n<ul>\n<li>E-step：估计(重估)GMM参数</li>\n<li>M-step：使用BW(Baum-Welch算法)对齐</li>\n</ul>\n<p>此外对于HMM假设一直受到诟病，等到RNN出现之后，使用RNN来对时序关系进行描述来取代HMM成为当时的热潮。</p>\n<p>随着神经网络优化技术的发展和GPU计算能力的不断提升，最终使用RNN和CTC来进行建模实现了end-to-end语音识别的声学模型。</p>\n<p>CTC的全称是Connectionist Temporal Classification，中文翻译大概是连接时序分类。它要达到的目标就是直接将语音和相应的文字对应起来，实现时序问题的分类。<br>用公式来描述的话，CTC的公式推导如下：<br>$$<br>p ( \\pi | x ) = \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t } , \\forall \\pi \\in L ^ { T }<br>$$</p>\n<p>其中π表示文字序列，X表示语音输入，y表示RNN的输出。由于很多帧可以输出同样的一个文字，同时很多帧也可以没有任何输出，因此定义了一个多对一的函数，把输出序列中重复的字符合并起来，形成唯一的序列，进而公式表示如下：<br>$$<br>p ( l | x ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) } p ( \\pi | x )<br>$$</p>\n<p>起始l表示对应的标注文本，而π是带有冗余的神经网络输出。求解上述公式，需要使用前后向算法。</p>\n<p>前向因子：<br>$$<br>\\alpha _ { t } ( s ) \\stackrel { d e f } { = } \\sum _ { \\pi \\in N ^ { t } : \\Re \\left( \\pi _ { 1 : t } = l _ { 1 : s } \\right) t ^ { \\prime } = 1 } ^ { t } y _ { \\pi _ { t } ^ { \\prime } } ^ { t ^ { \\prime } }<br>$$</p>\n<p>后向因子：<br>$$<br>\\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }<br>$$</p>\n<p>那么神经网络的输出和前后向因子的关系可以表示为：<br>$$<br>\\alpha _ { t } ( s ) \\beta _ { t } ( s ) = \\sum _ { \\pi \\in \\Re ^ { - 1 } ( l ) : \\pi _ { t } = l _ { s } ^ { \\prime } } y _ { l _ { s } ^ { \\prime } } ^ { t } \\prod _ { t = 1 } ^ { T } y _ { \\pi _ { t } } ^ { t }<br>$$</p>\n<p>进而得到：<br>$$<br>p ( l | x ) = \\sum _ { s = 1 } ^ { \\left| l ^ { \\prime } \\right| } \\frac { \\alpha _ { t } ( s ) \\beta _ { t } ( s ) } { y _ { l _ { s } ^ { t } } }<br>$$</p>\n<p>利用上述公式，就可以进行神经网络的训练了，这里仍然可以描述为EM的思想：</p>\n<ul>\n<li>E步：使用BPTT算法优化神经网络参数；</li>\n<li>M步：使用神经网络的输出，重新寻找最优的对齐关系。</li>\n</ul>\n<p>CTC可以看成是一个分类方法，甚至可以看作是目标函数。在构建end-to-end声学模型的过程中，CTC起到了很好的自动对齐的效果。同传统的基于CD-DNN-HMM的方法相比，对齐效果是这样的：</p>\n<p><img src=\"/2017/10/07/语音识别基本原理/10.png\" alt=\"\"></p>\n<p>基于帧对齐的方法强制要求切分好的帧对齐到对应的标签上去，而CTC则可以时帧的输出为空，只有少数帧对齐到对应的输出标签上。</p>\n<h3 id=\"End-to-End模型\"><a href=\"#End-to-End模型\" class=\"headerlink\" title=\"End-to-End模型\"></a>End-to-End模型</h3><p>由于神经网络强大的建模能力，End-to-End的输出标签也不再需要像传统架构一样的进行细分。例如对于中文，输出不再需要进行细分为状态、音素或者声韵母，直接将汉字作为输出即可；对于英文，考虑到英文单词的数量庞大，可以使用字母作为输出标签。</p>\n<p>从这一点出发，我们可以认为神经网络将声学符号到字符串的映射关系也一并建模学习了出来，这部分是在传统的框架中时词典所应承担的任务。针对这个模块，传统框架中有一个专门的建模单元叫做G2P（grapheme-to-phoneme），来处理集外词（out of vocabulary，OOV）。在End-to-End的声学模型中，可以没有词典，没有OOV，也没有G2P。这些全都被建模在一个神经网络中。</p>\n<p>另外，在传统的框架结构中，语音需要分帧，加窗，提取特征（MFCC、PLP等）。在基于神经网络的声学模型中，通常使用更裸的Fbank特征。在End-to-End的识别中，使用更简单的特征比如FFT等也是常见的做法。或许在不久的将来，语音的采样点也可以作为输入，这就是更加彻底的End-to-End声学模型。</p>\n<p>除此之外，End-to-End的声学模型中已经带有了语言模型的信息，它是通过RNN在输出序列上学习得到的。但这个语言模型仍然比较弱，如果外加一个更大数据量的语言模型，解码的效果会更好。因此，End-to-End现在指声学模型部分，等到不需要语言模型的时候，才是完全的End-to-End。</p>\n<h2 id=\"语言模型（Language-Model，-LM）\"><a href=\"#语言模型（Language-Model，-LM）\" class=\"headerlink\" title=\"语言模型（Language Model， LM）\"></a>语言模型（Language Model， LM）</h2><p>语言模型的作用之一为消解多音字的问题，在声学模型给出发音序列之后，从候选的文字序列中找出概率最大的字符串序列。<br>语言模型还会对声学的解码作约束和重打分，让最终识别结果符合语法规则。目前最常见的是N-Gram语言模型和基于RNN的语言模型。</p>\n<h2 id=\"解码\"><a href=\"#解码\" class=\"headerlink\" title=\"解码\"></a>解码</h2><p>传统的语音识别解码都是建立在WFST的基础之上，它是将HMM、词典以及语言模型编译成一个网络。解码就是在这个WFST构造的动态网络空间中，找到最优的输出字符序列。搜索通常使用Viterbi算法，另外为了防止搜索空间爆炸，通常会采用剪枝算法，因此搜索得到的结果可能不是最优结果。</p>"}],"PostAsset":[{"_id":"source/_posts/kaldi-chain-model/4.png","slug":"4.png","post":"cjqxku2hp000gly0gpzxf7hz4","modified":0,"renderable":0},{"_id":"source/_posts/fbank和mfcc特征提取/1.png","slug":"1.png","post":"cjqxku2na002hly0gox83ppg5","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/1.png","slug":"1.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/10.png","slug":"10.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/3.png","slug":"3.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/ctc在asr上的应用/4.png","slug":"4.png","post":"cjqxku2hg0005ly0ggta75jfa","modified":0,"renderable":0},{"_id":"source/_posts/kaldi-chain-model/1.png","slug":"1.png","post":"cjqxku2hp000gly0gpzxf7hz4","modified":0,"renderable":0},{"_id":"source/_posts/kaldi-chain-model/3.png","slug":"3.png","post":"cjqxku2hp000gly0gpzxf7hz4","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/2.png","slug":"2.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/item2和zsh配置/1.png","slug":"1.png","post":"cjqxku2hk0007ly0gqhqd78wp","modified":0,"renderable":0},{"_id":"source/_posts/item2和zsh配置/2.png","slug":"2.png","post":"cjqxku2hk0007ly0gqhqd78wp","modified":0,"renderable":0},{"_id":"source/_posts/git基础/git.jgp","slug":"git.jgp","post":"cjqxku2hl000bly0gwnkbhl98","modified":0,"renderable":0},{"_id":"source/_posts/git基础/git常用命令速查表.jpg","slug":"git常用命令速查表.jpg","post":"cjqxku2hl000bly0gwnkbhl98","modified":0,"renderable":0},{"_id":"source/_posts/viterbi以及forward-backword算法/1.png","slug":"1.png","post":"cjqxku2i2000wly0gbuca4juk","modified":0,"renderable":0},{"_id":"source/_posts/viterbi以及forward-backword算法/2.png","slug":"2.png","post":"cjqxku2i2000wly0gbuca4juk","modified":0,"renderable":0},{"_id":"source/_posts/语音基础概念/1.png","slug":"1.png","post":"cjqxku2i3000zly0gh9lnj3z9","modified":0,"renderable":0},{"_id":"source/_posts/语音基础概念/2.png","slug":"2.png","post":"cjqxku2i3000zly0gh9lnj3z9","modified":0,"renderable":0},{"_id":"source/_posts/Markdown/1.jpg","slug":"1.jpg","post":"cjqxku2h70000ly0gdoe3gih5","modified":0,"renderable":0},{"_id":"source/_posts/Markdown/2.jpg","slug":"2.jpg","post":"cjqxku2h70000ly0gdoe3gih5","modified":0,"renderable":0},{"_id":"source/_posts/Markdown/3.jpg","slug":"3.jpg","post":"cjqxku2h70000ly0gdoe3gih5","modified":0,"renderable":0},{"_id":"source/_posts/Markdown/4.jpg","slug":"4.jpg","post":"cjqxku2h70000ly0gdoe3gih5","modified":0,"renderable":0},{"_id":"source/_posts/kaldi-chain-model/2.png","slug":"2.png","post":"cjqxku2hp000gly0gpzxf7hz4","modified":0,"renderable":0},{"_id":"source/_posts/ctc在asr上的应用/1.png","slug":"1.png","post":"cjqxku2hg0005ly0ggta75jfa","modified":0,"renderable":0},{"_id":"source/_posts/ctc在asr上的应用/2.png","slug":"2.png","post":"cjqxku2hg0005ly0ggta75jfa","modified":0,"renderable":0},{"_id":"source/_posts/ctc在asr上的应用/3.png","slug":"3.png","post":"cjqxku2hg0005ly0ggta75jfa","modified":0,"renderable":0},{"_id":"source/_posts/ctc在asr上的应用/5.png","slug":"5.png","post":"cjqxku2hg0005ly0ggta75jfa","modified":0,"renderable":0},{"_id":"source/_posts/fbank和mfcc特征提取/2.png","slug":"2.png","post":"cjqxku2na002hly0gox83ppg5","modified":0,"renderable":0},{"_id":"source/_posts/奇异值分解SVD/1.gif","slug":"1.gif","post":"cjqxku2nc002jly0gy1wdk63c","modified":0,"renderable":0},{"_id":"source/_posts/奇异值分解SVD/2.png","slug":"2.png","post":"cjqxku2nc002jly0gy1wdk63c","modified":0,"renderable":0},{"_id":"source/_posts/奇异值分解SVD/3.png","slug":"3.png","post":"cjqxku2nc002jly0gy1wdk63c","modified":0,"renderable":0},{"_id":"source/_posts/奇异值分解SVD/4.png","slug":"4.png","post":"cjqxku2nc002jly0gy1wdk63c","modified":0,"renderable":0},{"_id":"source/_posts/奇异值分解SVD/5.png","slug":"5.png","post":"cjqxku2nc002jly0gy1wdk63c","modified":0,"renderable":0},{"_id":"source/_posts/梯度下降优化算法/1.png","slug":"1.png","post":"cjqxku2nf002lly0g7du5gdi6","modified":0,"renderable":0},{"_id":"source/_posts/梯度下降优化算法/2.png","slug":"2.png","post":"cjqxku2nf002lly0g7du5gdi6","modified":0,"renderable":0},{"_id":"source/_posts/梯度下降优化算法/3.png","slug":"3.png","post":"cjqxku2nf002lly0g7du5gdi6","modified":0,"renderable":0},{"_id":"source/_posts/梯度下降优化算法/4.gif","slug":"4.gif","post":"cjqxku2nf002lly0g7du5gdi6","modified":0,"renderable":0},{"_id":"source/_posts/梯度下降优化算法/5.gif","slug":"5.gif","post":"cjqxku2nf002lly0g7du5gdi6","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/11.png","slug":"11.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/4.png","slug":"4.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/5.png","slug":"5.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/6.png","slug":"6.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/7.png","slug":"7.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/8.png","slug":"8.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0},{"_id":"source/_posts/语音识别基本原理/9.png","slug":"9.png","post":"cjqxku2ng002mly0gqz2wzb9n","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjqxku2h70000ly0gdoe3gih5","category_id":"cjqxku2he0003ly0ga98cr173","_id":"cjqxku2hn000dly0gsvtcxub3"},{"post_id":"cjqxku2hc0002ly0g9dexu64i","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2ht000jly0gg9fd9ye2"},{"post_id":"cjqxku2hn000cly0gkggl4iyj","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2hv000mly0g8l0fa956"},{"post_id":"cjqxku2hp000gly0gpzxf7hz4","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2hz000ply0g490f1tp8"},{"post_id":"cjqxku2hg0005ly0ggta75jfa","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2i1000uly0grqtds8hj"},{"post_id":"cjqxku2hu000lly0ge5hczpl3","category_id":"cjqxku2he0003ly0ga98cr173","_id":"cjqxku2i2000xly0gplni4tsw"},{"post_id":"cjqxku2hi0006ly0gd5yiwx6e","category_id":"cjqxku2ht000ily0g9y06vs6d","_id":"cjqxku2i40011ly0gpcdrtn1o"},{"post_id":"cjqxku2i0000tly0gv8cvughy","category_id":"cjqxku2ht000ily0g9y06vs6d","_id":"cjqxku2i40012ly0gdd15l0ra"},{"post_id":"cjqxku2hk0007ly0gqhqd78wp","category_id":"cjqxku2ht000ily0g9y06vs6d","_id":"cjqxku2i50016ly0gicn5xdyq"},{"post_id":"cjqxku2i2000wly0gbuca4juk","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2i50018ly0g9s98erxp"},{"post_id":"cjqxku2i3000zly0gh9lnj3z9","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2i6001bly0gikcceepk"},{"post_id":"cjqxku2hl000bly0gwnkbhl98","category_id":"cjqxku2ht000ily0g9y06vs6d","_id":"cjqxku2i6001ely0g3tlbnifi"},{"post_id":"cjqxku2hr000hly0gv9f3r6jg","category_id":"cjqxku2ht000ily0g9y06vs6d","_id":"cjqxku2i7001fly0g1oax2dlj"},{"post_id":"cjqxku2hy000oly0g19lmbkfk","category_id":"cjqxku2i60019ly0gycjrb0fk","_id":"cjqxku2i7001ily0gp2u304iz"},{"post_id":"cjqxku2na002hly0gox83ppg5","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2nh002nly0gwgtpsnq3"},{"post_id":"cjqxku2nc002jly0gy1wdk63c","category_id":"cjqxku2i60019ly0gycjrb0fk","_id":"cjqxku2nh002oly0gurf606jh"},{"post_id":"cjqxku2nf002lly0g7du5gdi6","category_id":"cjqxku2i60019ly0gycjrb0fk","_id":"cjqxku2ni002rly0gbaabxutx"},{"post_id":"cjqxku2ng002mly0gqz2wzb9n","category_id":"cjqxku2hk0008ly0guuv2w86e","_id":"cjqxku2ni002tly0gymvqbvuo"}],"PostTag":[{"post_id":"cjqxku2h70000ly0gdoe3gih5","tag_id":"cjqxku2hg0004ly0grv8yt055","_id":"cjqxku2hl000aly0gsi5rua0g"},{"post_id":"cjqxku2hc0002ly0g9dexu64i","tag_id":"cjqxku2hl0009ly0gloynz4m1","_id":"cjqxku2hv000nly0g09dhzfud"},{"post_id":"cjqxku2hc0002ly0g9dexu64i","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2hz000qly0g1g32a4v7"},{"post_id":"cjqxku2hu000lly0ge5hczpl3","tag_id":"cjqxku2hg0004ly0grv8yt055","_id":"cjqxku2i1000vly0gvq6gmzf9"},{"post_id":"cjqxku2i3000zly0gh9lnj3z9","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2i50014ly0guzsw2azd"},{"post_id":"cjqxku2hg0005ly0ggta75jfa","tag_id":"cjqxku2hu000kly0gw9puz3l5","_id":"cjqxku2i50017ly0gadfw6euh"},{"post_id":"cjqxku2hg0005ly0ggta75jfa","tag_id":"cjqxku2i0000sly0guwz4m9gh","_id":"cjqxku2i6001aly0g0day6nrn"},{"post_id":"cjqxku2hg0005ly0ggta75jfa","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2i6001dly0ga7qs8rtq"},{"post_id":"cjqxku2hi0006ly0gd5yiwx6e","tag_id":"cjqxku2i50015ly0g8bqbikmn","_id":"cjqxku2i7001hly0g4wc74cjq"},{"post_id":"cjqxku2hi0006ly0gd5yiwx6e","tag_id":"cjqxku2i6001cly0go6vsymag","_id":"cjqxku2i7001jly0gwye28zdu"},{"post_id":"cjqxku2hk0007ly0gqhqd78wp","tag_id":"cjqxku2i7001gly0gnr6sk7iz","_id":"cjqxku2i8001nly0g8buge0dd"},{"post_id":"cjqxku2hk0007ly0gqhqd78wp","tag_id":"cjqxku2i7001kly0g2jgy38gz","_id":"cjqxku2i8001oly0ghe9gk0yq"},{"post_id":"cjqxku2hk0007ly0gqhqd78wp","tag_id":"cjqxku2i50015ly0g8bqbikmn","_id":"cjqxku2i9001qly0gu6kg6yrq"},{"post_id":"cjqxku2hl000bly0gwnkbhl98","tag_id":"cjqxku2i8001mly0gnf2bjpw8","_id":"cjqxku2i9001sly0g7631plcd"},{"post_id":"cjqxku2hl000bly0gwnkbhl98","tag_id":"cjqxku2i50015ly0g8bqbikmn","_id":"cjqxku2i9001tly0gvoffthey"},{"post_id":"cjqxku2hn000cly0gkggl4iyj","tag_id":"cjqxku2i9001rly0g3f6zhhw6","_id":"cjqxku2ia001yly0gnmn4n4sm"},{"post_id":"cjqxku2hn000cly0gkggl4iyj","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2ia001zly0gyekhd24o"},{"post_id":"cjqxku2hn000cly0gkggl4iyj","tag_id":"cjqxku2ia001vly0g8geutezb","_id":"cjqxku2ib0021ly0gzlpp3nd2"},{"post_id":"cjqxku2hn000cly0gkggl4iyj","tag_id":"cjqxku2ia001wly0ghqhlhmqi","_id":"cjqxku2ib0022ly0gucifshzm"},{"post_id":"cjqxku2hp000gly0gpzxf7hz4","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2ic0024ly0gzukjqceb"},{"post_id":"cjqxku2hp000gly0gpzxf7hz4","tag_id":"cjqxku2i9001rly0g3f6zhhw6","_id":"cjqxku2ic0025ly0gdwqicso9"},{"post_id":"cjqxku2hp000gly0gpzxf7hz4","tag_id":"cjqxku2ia0020ly0gugx9kcru","_id":"cjqxku2id0027ly0gt3mkogso"},{"post_id":"cjqxku2hr000hly0gv9f3r6jg","tag_id":"cjqxku2i50015ly0g8bqbikmn","_id":"cjqxku2id0028ly0gs5lqdby0"},{"post_id":"cjqxku2hy000oly0g19lmbkfk","tag_id":"cjqxku2ic0026ly0glbt78osm","_id":"cjqxku2id002bly0ghp19gn50"},{"post_id":"cjqxku2hy000oly0g19lmbkfk","tag_id":"cjqxku2i0000sly0guwz4m9gh","_id":"cjqxku2ie002cly0g24lma5i7"},{"post_id":"cjqxku2i0000tly0gv8cvughy","tag_id":"cjqxku2i50015ly0g8bqbikmn","_id":"cjqxku2if002ely0g0ksdbkov"},{"post_id":"cjqxku2i2000wly0gbuca4juk","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2if002fly0giiunh6h8"},{"post_id":"cjqxku2i2000wly0gbuca4juk","tag_id":"cjqxku2ie002dly0gojohu34z","_id":"cjqxku2if002gly0gju77otue"},{"post_id":"cjqxku2ng002mly0gqz2wzb9n","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2ni002qly0gba5tuemc"},{"post_id":"cjqxku2na002hly0gox83ppg5","tag_id":"cjqxku2ho000fly0gwfz3rwju","_id":"cjqxku2ni002sly0gygokmhlc"},{"post_id":"cjqxku2na002hly0gox83ppg5","tag_id":"cjqxku2nf002kly0g5zkx8ask","_id":"cjqxku2nj002vly0g91lr9vep"},{"post_id":"cjqxku2nc002jly0gy1wdk63c","tag_id":"cjqxku2nh002ply0gojju0i0i","_id":"cjqxku2nj002wly0ggltkjcar"},{"post_id":"cjqxku2nc002jly0gy1wdk63c","tag_id":"cjqxku2i0000sly0guwz4m9gh","_id":"cjqxku2nj002xly0g5ek2q8ln"},{"post_id":"cjqxku2nf002lly0g7du5gdi6","tag_id":"cjqxku2ni002uly0gmox5jyxb","_id":"cjqxku2nj002yly0gd85ioy8h"},{"post_id":"cjqxku2nf002lly0g7du5gdi6","tag_id":"cjqxku2i0000sly0guwz4m9gh","_id":"cjqxku2nk002zly0gujzjbav9"}],"Tag":[{"name":"工具","_id":"cjqxku2hg0004ly0grv8yt055"},{"name":"GMM","_id":"cjqxku2hl0009ly0gloynz4m1"},{"name":"语音识别","_id":"cjqxku2ho000fly0gwfz3rwju"},{"name":"ctc","_id":"cjqxku2hu000kly0gw9puz3l5"},{"name":"deep learning","_id":"cjqxku2i0000sly0guwz4m9gh"},{"name":"linux","_id":"cjqxku2i50015ly0g8bqbikmn"},{"name":"gdb","_id":"cjqxku2i6001cly0go6vsymag"},{"name":"iTerm2","_id":"cjqxku2i7001gly0gnr6sk7iz"},{"name":"zsh","_id":"cjqxku2i7001kly0g2jgy38gz"},{"name":"git","_id":"cjqxku2i8001mly0gnf2bjpw8"},{"name":"kaldi","_id":"cjqxku2i9001rly0g3f6zhhw6"},{"name":"sge","_id":"cjqxku2ia001vly0g8geutezb"},{"name":"nfs","_id":"cjqxku2ia001wly0ghqhlhmqi"},{"name":"chain model","_id":"cjqxku2ia0020ly0gugx9kcru"},{"name":"tensorflow","_id":"cjqxku2ic0026ly0glbt78osm"},{"name":"viterbi","_id":"cjqxku2ie002dly0gojohu34z"},{"name":"特征提取","_id":"cjqxku2nf002kly0g5zkx8ask"},{"name":"SVD","_id":"cjqxku2nh002ply0gojju0i0i"},{"name":"SGD","_id":"cjqxku2ni002uly0gmox5jyxb"}]}}