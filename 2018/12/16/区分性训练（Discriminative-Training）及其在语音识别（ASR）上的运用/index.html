<!DOCTYPE html><html class="theme-next mist use-motion" lang="zh-Hans,en,default"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="语音识别,deep learning,"><meta name="description" content="介绍语音识别声学模型DNN训练通常用交叉熵（Cross-Entropy，CE）作为损失函数进行训练，但是在基于帧识别的语音识别中我们一般使用WER来评价语音识别的准确率，我们更关心的是序列的准确性，这就导致损失函数和训练目标不一致。序列区分性训练（Discriminative Training，DT）在识别序列上定义误差，更接近我们语音识别的最终目标。常见的DT目标函数有最大互信息（ maximu"><meta name="keywords" content="语音识别,deep learning"><meta property="og:type" content="article"><meta property="og:title" content="区分性训练（Discriminative Training）及其在语音识别（ASR）上的运用"><meta property="og:url" content="http://yoursite.com/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/index.html"><meta property="og:site_name" content="You&#39;re Beautiful"><meta property="og:description" content="介绍语音识别声学模型DNN训练通常用交叉熵（Cross-Entropy，CE）作为损失函数进行训练，但是在基于帧识别的语音识别中我们一般使用WER来评价语音识别的准确率，我们更关心的是序列的准确性，这就导致损失函数和训练目标不一致。序列区分性训练（Discriminative Training，DT）在识别序列上定义误差，更接近我们语音识别的最终目标。常见的DT目标函数有最大互信息（ maximu"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http://yoursite.com/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/1.png"><meta property="og:image" content="http://yoursite.com/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/2.png"><meta property="og:updated_time" content="2019-01-17T08:42:54.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="区分性训练（Discriminative Training）及其在语音识别（ASR）上的运用"><meta name="twitter:description" content="介绍语音识别声学模型DNN训练通常用交叉熵（Cross-Entropy，CE）作为损失函数进行训练，但是在基于帧识别的语音识别中我们一般使用WER来评价语音识别的准确率，我们更关心的是序列的准确性，这就导致损失函数和训练目标不一致。序列区分性训练（Discriminative Training，DT）在识别序列上定义误差，更接近我们语音识别的最终目标。常见的DT目标函数有最大互信息（ maximu"><meta name="twitter:image" content="http://yoursite.com/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/1.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"5.1.4",sidebar:{position:"left",display:"always",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/"><title>区分性训练（Discriminative Training）及其在语音识别（ASR）上的运用 | You're Beautiful</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">You're Beautiful</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle"></p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="liuyan"><meta itemprop="description" content=""><meta itemprop="image" content="/uploads/avatar.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="You're Beautiful"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">区分性训练（Discriminative Training）及其在语音识别（ASR）上的运用</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-16T16:25:12+08:00">2018-12-16 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/语音识别/" itemprop="url" rel="index"><span itemprop="name">语音识别</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/" itemprop="commentCount"></span> </a></span><span id="/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/" class="leancloud_visitors" data-flag-title="区分性训练（Discriminative Training）及其在语音识别（ASR）上的运用"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数&#58;</span> <span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><ul><li>语音识别声学模型DNN训练通常用交叉熵（Cross-Entropy，CE）作为损失函数进行训练，但是在基于帧识别的语音识别中我们一般使用WER来评价语音识别的准确率，我们更关心的是序列的准确性，这就导致损失函数和训练目标不一致。</li><li>序列区分性训练（Discriminative Training，DT）在识别序列上定义误差，更接近我们语音识别的最终目标。</li><li>常见的DT目标函数有最大互信息（ maximum mutual information, MMI），增强型最大互信息（Boosted MMI, BMMI），最小音素错误（minimum phone error, MPE）和最小贝叶斯风险（minimum bayes risk, MBR）</li></ul><a id="more"></a><p>使用CE准则的时候，帧的正确率提高了但是最终解码的WER可能没有变化甚至变坏了，这也是我们想让训练准则直接和最后的评估函数（WER）相关的原因。 下面我们主要以MMI为主要介绍对象。</p><h3 id="GMM与DT"><a href="#GMM与DT" class="headerlink" title="GMM与DT"></a>GMM与DT</h3><p>在语音GMM-HMM框架下，我们使用最大似然准则（Maximum likelihood estimation ）进行训练：<br>$$<br>F _ { \mathrm { ML } } = \sum _ { u = 1 } ^ { U } \log P \left( \mathbf { X } _ { u } | W _ { u } ; \theta \right)<br>$$<br>其中$ W _ { u } $是标注序列，$ X _ { u } $是语音信号，$ \theta $是声学模型参数。</p><p>MMI准则（Maximum mutual information estimation ）为：<br>$$<br>\begin{aligned} F _ { \mathrm { MMI } } &amp; = \sum _ { u = 1 } ^ { U } \log P \left( W _ { u } | \mathbf { x } _ { u } ; \theta \right) \ = \sum _ { u = 1 } ^ { U } \log \frac { P \left( \mathbf { X } _ { u } | W _ { w } ; \theta \right) P \left( W _ { u } \right) } { \sum _ { w ^ { \prime } } P \left( \mathbf { X } _ { u } | w ^ { \prime } ; \theta \right) P \left( w ^ { \prime } \right) } \end{aligned}<br>$$<br>其中$ P ( W _ { u } ) $是固定的语言模型。</p><p>分子上的$ P ( \mathbf { X } _ { u } | W _ { u } ; \theta ) $，正是ML的目标函数；而分母则是所有文本（包括训练文本和它的所有竞争者）产生训练语音的概率（按语言模型加权）和。</p><p>两者之间的区别在于条件概率不同。ML中只要训练文本产生训练语音的概率大就行，而MMI要求的是训练语音对应训练文本的概率大，就是要训练文本产生语音信号的概率与其它文本产生语音信号的概率之差大。</p><h3 id="DNN与DT"><a href="#DNN与DT" class="headerlink" title="DNN与DT"></a>DNN与DT</h3><h4 id="MMI损失函数"><a href="#MMI损失函数" class="headerlink" title="MMI损失函数"></a>MMI损失函数</h4><p>在DNN神经网络中，DT准则可以替换CE准则作为损失函数。MMI准则为：<br>$$<br>\begin{aligned} { \mathcal { L } _ { M M I } (\theta ; \mathbb { S }) } &amp; = \sum _ { m = 1 } ^ { M } \mathcal { L } _ { \mathrm { MMI } } \left( \theta ; \mathbf { o } ^ { m } , \mathbf { w } ^ { m } \right) \ = \sum _ { m = 1 } ^ { M } \log P \left( \mathbf { w } ^ { m } | \mathbf { o } ^ { m } ; \theta \right) \ = \sum _ { m = 1 } ^ { M } \log \frac { p \left( \mathbf { o } ^ { m } | \mathbf { s } ^ { m } ; \theta \right) ^ { \kappa } P \left( \mathbf { w } ^ { m } \right) } { \sum _ { \mathbf { w } } p \left( \mathbf { o } ^ { m } | \mathbf { s } ^ { w } ; \theta \right) ^ { \kappa } P ( \mathbf { w } ) } \end{aligned}<br>$$<br>其中$ \mathbf { o } ^ { m } = \mathbf { o } _ { 1 } ^ { m } , \cdots , \mathbf { o } _ { t } ^ { m } , \cdots , \mathbf { o } _ { T _ { m } } ^ { m } $和$ \mathbf { w } ^ { m } = \mathbf { w } _ { 1 } ^ { m } , \cdots , \mathbf { w } _ { t } ^ { m } , \cdots , \mathbf { w } _ { N _ { m } } ^ { m } $分别为第m个音频样本的观测序列和正确的单词标注序列，$ T _ { m } $为第m个音频样本的帧数，$ N _ { m } $是标注序列的单词总数，$ \theta $是模型参数，$ \mathbf { s } ^ { m } = \mathbf { s } _ { 1 } ^ { m } , \cdots , \mathbf { s } _ { t } ^ { m } , \cdots , \mathbf { s } _ { T _ { m } } ^ { m } $是$ w _ { m } $的状态序列，$ \kappa $是声学缩放系数。</p><p>MMI准则公式中，分子Numerator表示的是正确单词序列的可能性，分母Denominator是所有可能单词序列的可能性之和。</p><p>MMI准则最大化单词序列分布和观察序列分布之间的互信息,，减小句子错误率。最大化分子， 最小化分母。</p><p>DT训练之前需要使用CE准则生成alignments和lattices，DT的初始化模型为使用CE准则训练出的最好模型。</p><p>理论上说,，DT训练分母应该取遍所有可能的单词序列。不过在实际中，这个求和运算是限制在解码得到的lattice上做的，这样可以减少运算量。</p><p>DNN训练算法一般是用来最小化一个目标方程, 所以我们可以对MMI准则取反进行最小化，而不是最大化互信息。</p><h4 id="MMI求导"><a href="#MMI求导" class="headerlink" title="MMI求导"></a>MMI求导</h4><p>$$<br>\frac { \partial \mathcal { L } _ { MMI} (\theta ; \mathbb { S }) } { \partial \theta } = \sum _ { m = 1 } ^ { M } \sum _ { t = 1 } ^ { T } \frac { \partial \mathcal { L } (\theta ; \mathbb { S } ) } { \partial z _ { mt } } \frac { \partial z _ { mt } } { \partial \theta }<br>$$<br>其中$ z _ { mt } $表示softmax层的输入，$ \frac { \partial z _ { mt } } { \partial \theta } $的计算方式和CE准则是一样的没有区别，我们称之为外导数。真正和DT相关的是$ \frac { \partial \mathcal { L } (\theta ; \mathbb { S } ) } { \partial z _ { mt } } $，我们称之为内导数。</p><p>$$<br>\frac { \partial \mathscr { L } _ { M M I } ( \theta ; \mathbb { S } ) } { \partial z _ { m t } ( i ) } = \kappa \left( \gamma _ { m t } ^ { n u m } ( i ) - \gamma _ { m t } ^ { d e n } ( i ) \right)<br>$$<br>其中$ z _ { m t } (i ) $是$ z _ {m t } $的第i个元素，最终求导结果如上过程省略。$ \gamma _ { mt } ^ { n u m } ( r ) $和$ \gamma _ { mt } ^ { d e n } ( r ) $分别表示t时刻分子lattice和分母lattice在状态r上的后验概率，可以通过在lattice上使用<a href="https://liuyanfeier.github.io/2019/01/07/viterbi%E4%BB%A5%E5%8F%8Aforward-backword%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener">前向-后向算法</a>得到：</p><p>$$<br>\gamma _ { t } ( r ) = P \left( s _ { t } = r | ( \theta ; \mathbb { S } ) \right) = \frac { \alpha _ { t } ( r ) \beta _ { t } ( r ) } { \sum _ { r } ^ { N } \alpha _ { t } ( r ) }<br>$$<br>其中$ \alpha _ { t } ( r ) $和$ \beta _ { t } ( r ) $分别是前向后向算法中计算出来的前向因子和后向因子，$ \sum _ { r } ^ { N } \alpha _ { t } ( r ) $是前向或者后向算法中从起始节点到结束节点的概率和。</p><p>前向后向算法都是在lattice上进行的，下图是一个word级别的lattice：</p><p><img src="/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/1.png" alt=""></p><h4 id="kaldi中的DT实现"><a href="#kaldi中的DT实现" class="headerlink" title="kaldi中的DT实现"></a>kaldi中的DT实现</h4><p>流程图：<br><img src="/2018/12/16/区分性训练（Discriminative-Training）及其在语音识别（ASR）上的运用/2.png" alt=""><br>该流程图是kaldi nnet3中的DT计算过程。</p><p>lattice rescore是DNN前向计算出$ P ( s | o ) $，除以先验概率$ P ( s ) $，得到似然概率$ P ( o | s ) $，替换lattice边上对应的$ P ( o | s ) $。<br>其中<code>vector&lt;BaseFloat&gt; answers</code>是前面计算出来的DNN的输出对应参考pdf的概率。<br></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// nnet3/discriminative-training.cc</span></span><br><span class="line"><span class="comment">// 对lattice进行声学校正, 将负（缩放）声学对数似然置于lattice的弧中</span></span><br><span class="line"><span class="keyword">size_t</span> DiscriminativeComputation::LatticeAcousticRescore(</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;BaseFloat&gt; &amp;answers,</span><br><span class="line">    <span class="keyword">size_t</span> index, Lattice *lat) &#123;</span><br><span class="line">  int32 num_states = lat-&gt;NumStates();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (StateId s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (fst::MutableArcIterator&lt;Lattice&gt; aiter(lat, s);</span><br><span class="line">         !aiter.Done(); aiter.Next()) &#123;</span><br><span class="line">      Arc arc = aiter.Value();</span><br><span class="line">      <span class="keyword">if</span> (arc.ilabel != <span class="number">0</span>) &#123; <span class="comment">// input-side has transition-ids, output-side empty</span></span><br><span class="line">        arc.weight.SetValue2(-answers[index]);</span><br><span class="line">        <span class="comment">// graph cost: lm + transition + pronunciation</span></span><br><span class="line">        <span class="comment">// acoustic cost: -P(o|s)</span></span><br><span class="line">        index++;</span><br><span class="line">        aiter.SetValue(arc);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    LatticeWeight final = lat-&gt;Final(s);</span><br><span class="line">    <span class="keyword">if</span> (final != LatticeWeight::Zero()) &#123;</span><br><span class="line">      final.SetValue2(<span class="number">0.0</span>); <span class="comment">// 确保在最终概率中没有声学项</span></span><br><span class="line">      lat-&gt;SetFinal(s, final);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 用于rescore lattice的对数似然的索引个数</span></span><br><span class="line">  <span class="keyword">return</span> index;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>在分母lattice上进行前向后向的计算函数为LatticeForwardBackward；在分子lattice的前向后向计算函数为AlignmentToPosterior。<br></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// lat/lattice-functions.cc</span></span><br><span class="line"><span class="comment">// 在lattice上执行前向后向算法并计算弧的后验概率</span></span><br><span class="line"><span class="function">BaseFloat <span class="title">LatticeForwardBackward</span><span class="params">(<span class="keyword">const</span> Lattice &amp;lat, Posterior *post,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">double</span> *acoustic_like_sum)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 注意Posterior定义如下:  </span></span><br><span class="line">  <span class="comment">// Indexed [frame], then a list of (transition-id, posterior-probability) pairs.</span></span><br><span class="line">  <span class="comment">// typedef std::vector&lt;std::vector&lt;std::pair&lt;int32, BaseFloat&gt; &gt; &gt; Posterior;</span></span><br><span class="line">  <span class="keyword">using</span> <span class="keyword">namespace</span> fst;</span><br><span class="line">  <span class="keyword">typedef</span> Lattice::Arc Arc;</span><br><span class="line">  <span class="keyword">typedef</span> Arc::Weight Weight;</span><br><span class="line">  <span class="keyword">typedef</span> Arc::StateId StateId;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (acoustic_like_sum) *acoustic_like_sum = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 确保lattices在拓扑上排序</span></span><br><span class="line">  <span class="keyword">if</span> (lat.Properties(fst::kTopSorted, <span class="literal">true</span>) == <span class="number">0</span>)</span><br><span class="line">    KALDI_ERR &lt;&lt; <span class="string">"Input lattice must be topologically sorted."</span>;</span><br><span class="line">  KALDI_ASSERT(lat.Start() == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  int32 num_states = lat.NumStates();</span><br><span class="line">  <span class="built_in">vector</span>&lt;int32&gt; state_times;</span><br><span class="line">  <span class="comment">// 拓扑迭代den_lats中的每个state，并按顺序对每个state进行计数，结果</span></span><br><span class="line">  <span class="comment">// 保存在vector state_times中，最后一个state对应的计数时间应该为帧的数量值</span></span><br><span class="line">  int32 max_time = LatticeStateTimes(lat, &amp;state_times);</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; alpha(num_states, kLogZeroDouble);</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; &amp;beta(alpha); </span><br><span class="line">  <span class="comment">// 重用相同的内存，beta是alpha的引用</span></span><br><span class="line">  <span class="keyword">double</span> tot_forward_prob = kLogZeroDouble;</span><br><span class="line"></span><br><span class="line">  post-&gt;clear();</span><br><span class="line">  post-&gt;resize(max_time);</span><br><span class="line"></span><br><span class="line">  alpha[<span class="number">0</span>] = <span class="number">0.0</span>;</span><br><span class="line">  <span class="comment">// Propagate alphas forward.</span></span><br><span class="line">  <span class="keyword">for</span> (StateId s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    <span class="keyword">double</span> this_alpha = alpha[s];</span><br><span class="line">    <span class="comment">// alpha[]里面存储着从init state走到该state的所有路径中cost value加和最大值</span></span><br><span class="line">    <span class="keyword">for</span> (ArcIterator&lt;Lattice&gt; aiter(lat, s); !aiter.Done(); aiter.Next()) &#123;</span><br><span class="line">      <span class="keyword">const</span> Arc &amp;arc = aiter.Value();</span><br><span class="line">      <span class="comment">// arc_like = arc.weight.value1 + arc.weight.value2</span></span><br><span class="line">      <span class="keyword">double</span> arc_like = -ConvertToCost(arc.weight);    </span><br><span class="line">      <span class="comment">// LogAdd返回两者之间较大的一个... + something else</span></span><br><span class="line">      alpha[arc.nextstate] = LogAdd(alpha[arc.nextstate], this_alpha + arc_like);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// get状态s的final weight; if == Weight::Zero() =&gt; non-final</span></span><br><span class="line">    <span class="comment">// final state上面有单独的语言和声学分 </span></span><br><span class="line">    Weight f = lat.Final(s);</span><br><span class="line">    <span class="keyword">if</span> (f != Weight::Zero()) &#123;     </span><br><span class="line">      <span class="keyword">double</span> final_like = this_alpha - (f.Value1() + f.Value2());</span><br><span class="line">      tot_forward_prob = LogAdd(tot_forward_prob, final_like);</span><br><span class="line">      KALDI_ASSERT(state_times[s] == max_time &amp;&amp;</span><br><span class="line">                   <span class="string">"Lattice is inconsistent (final-prob not at max_time)"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (StateId s = num_states<span class="number">-1</span>; s &gt;= <span class="number">0</span>; s--) &#123;</span><br><span class="line">    Weight f = lat.Final(s);</span><br><span class="line">    <span class="comment">// 如果s不是final state, this_beta = 0</span></span><br><span class="line">    <span class="keyword">double</span> this_beta = -(f.Value1() + f.Value2());</span><br><span class="line">    <span class="comment">// beta[]里面存储的是从该state走到final state的所有路径中cost value加和最大值（加上final state的权值）</span></span><br><span class="line">    <span class="keyword">for</span> (ArcIterator&lt;Lattice&gt; aiter(lat, s); !aiter.Done(); aiter.Next()) &#123;</span><br><span class="line">      <span class="keyword">const</span> Arc &amp;arc = aiter.Value();</span><br><span class="line">      <span class="keyword">double</span> arc_like = -ConvertToCost(arc.weight),</span><br><span class="line">          arc_beta = beta[arc.nextstate] + arc_like;</span><br><span class="line">      this_beta = LogAdd(this_beta, arc_beta);</span><br><span class="line">      int32 transition_id = arc.ilabel;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 该if判断是一个优化，以避免不需要的exp()函数</span></span><br><span class="line">      <span class="keyword">if</span> (transition_id != <span class="number">0</span> || acoustic_like_sum != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">double</span> posterior = Exp(alpha[s] + arc_beta - tot_forward_prob);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transition_id != <span class="number">0</span>) <span class="comment">// 该弧上有tid，不是epsilon</span></span><br><span class="line">          <span class="comment">// (*post)[state_times[s]]是以时间帧为编号的vector</span></span><br><span class="line">          (*post)[state_times[s]].push_back(<span class="built_in">std</span>::make_pair(transition_id,</span><br><span class="line">                                                           <span class="keyword">static_cast</span>&lt;kaldi::BaseFloat&gt;(posterior)));</span><br><span class="line">        <span class="keyword">if</span> (acoustic_like_sum != <span class="literal">NULL</span>)</span><br><span class="line">          *acoustic_like_sum -= posterior * arc.weight.Value2();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (acoustic_like_sum != <span class="literal">NULL</span> &amp;&amp; f != Weight::Zero()) &#123;</span><br><span class="line">      <span class="keyword">double</span> final_logprob = - ConvertToCost(f),</span><br><span class="line">          posterior = Exp(alpha[s] + final_logprob - tot_forward_prob);</span><br><span class="line">      *acoustic_like_sum -= posterior * f.Value2();     <span class="comment">// value2声学分数 </span></span><br><span class="line">    &#125;</span><br><span class="line">    beta[s] = this_beta;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">double</span> tot_backward_prob = beta[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">if</span> (!ApproxEqual(tot_forward_prob, tot_backward_prob, <span class="number">1e-8</span>)) &#123;</span><br><span class="line">    KALDI_WARN &lt;&lt; <span class="string">"Total forward probability over lattice = "</span> &lt;&lt; tot_forward_prob</span><br><span class="line">              &lt;&lt; <span class="string">", while total backward probability = "</span> &lt;&lt; tot_backward_prob;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 按照第一个元素排序，把tid(pdfid)相同的后验combine起来(posterior值加起来)</span></span><br><span class="line">  <span class="keyword">for</span> (int32 t = <span class="number">0</span>; t &lt; max_time; t++)</span><br><span class="line">    MergePairVectorSumming(&amp;((*post)[t]));</span><br><span class="line">  <span class="keyword">return</span> tot_backward_prob;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4 id="trick"><a href="#trick" class="headerlink" title="trick"></a>trick</h4><ul><li>frame rejection<br>当分子alignment的状态没有在分母lattice中出现的时候，会导致梯度过大，舍弃该帧的梯度。这种情况对于silence帧尤其常见，因为silence经常出现在分子的lattice，但是很容易被分母的lattice忽略。<br>如果新的对齐和lattice在每轮训练后被重新生成，那么运算结果将得到进一步改进。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果两个post[i]的第一个元素(tid)没有交集，返回true</span></span><br><span class="line">    <span class="keyword">if</span> (PosteriorEntriesAreDisjoint(post1[i], post2[i])) &#123;</span><br><span class="line">      num_disjoint++;</span><br><span class="line">      <span class="keyword">if</span> (drop_frames)</span><br><span class="line">        (*post)[i].clear();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li><p>帧平滑<br>$$<br>J _ { \mathrm { FS } - \mathrm { SEQ } } ( \theta ; \mathrm { S } ) = ( 1 - H ) J _ { \mathrm { CE } } ( \theta ; \mathrm { S } ) + H J _ { \mathrm { SEQ } } ( \theta ; \mathrm { S } )<br>$$<br>当训练dt准则函数持续改进时，只用DNN计算出的帧准确率却显著变差。帧/序列的比从 1:4 (H = 4/s )到 1:10 (H = 10/11 )常常是有效的。</p></li><li><p>更小的lr，大数据集上smbr效果最好</p></li></ul></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div></div><button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'><span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/wechatpay.jpg" alt="liuyan 微信支付"><p>微信支付</p></div></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/语音识别/" rel="tag"><i class="fa fa-tag"></i> 语音识别</a> <a href="/tags/deep-learning/" rel="tag"><i class="fa fa-tag"></i> deep learning</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/10/11/奇异值分解SVD/" rel="next" title="奇异值分解SVD"><i class="fa fa-chevron-left"></i> 奇异值分解SVD</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2019/01/04/gdb使用笔记/" rel="prev" title="gdb使用笔记">gdb使用笔记 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/uploads/avatar.jpg" alt="liuyan"><p class="site-author-name" itemprop="name">liuyan</p><p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish.</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">19</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/liuyanfeier" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:liuyanfeier@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#介绍"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GMM与DT"><span class="nav-number">2.</span> <span class="nav-text">GMM与DT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DNN与DT"><span class="nav-number">3.</span> <span class="nav-text">DNN与DT</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MMI损失函数"><span class="nav-number">3.1.</span> <span class="nav-text">MMI损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MMI求导"><span class="nav-number">3.2.</span> <span class="nav-text">MMI求导</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kaldi中的DT实现"><span class="nav-number">3.3.</span> <span class="nav-text">kaldi中的DT实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#trick"><span class="nav-number">3.4.</span> <span class="nav-text">trick</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2016 &mdash; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">liuyan</span></div><div class="powered-by"></div><span class="post-meta-divider"></span><div class="theme-info"></div><div class="theme-info"><div class="powered-by"></div><span class="post-count">全站共22.6k字</span></div><span id="busuanzi_container_site_pv" class="theme-info">&nbsp;&nbsp;|&nbsp;&nbsp;总访问量<span id="busuanzi_value_site_pv"></span></span><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script type="text/javascript">var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'Qjopph93LqsnyC77HpQsdSsI-gzGzoHsz',
        appKey: 'eLVBvnVpwxVsh69H3vl0tc8u',
        placeholder: '好嗨哦！',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("Qjopph93LqsnyC77HpQsdSsI-gzGzoHsz","eLVBvnVpwxVsh69H3vl0tc8u")</script><script>function showTime(e){var t=new AV.Query(e),c=[],u=$(".leancloud_visitors");u.each(function(){c.push($(this).attr("id").trim())}),t.containedIn("url",c),t.find().done(function(e){var t=".leancloud-visitors-count";if(0!==e.length){for(var n=0;n<e.length;n++){var o=e[n],i=o.get("url"),s=o.get("time"),r=document.getElementById(i);$(r).find(t).text(s)}for(n=0;n<c.length;n++){i=c[n],r=document.getElementById(i);var l=$(r).find(t);""==l.text()&&l.text(0)}}else u.find(t).text(0)}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(i){var e=$(".leancloud_visitors"),s=e.attr("id").trim(),r=e.attr("data-flag-title").trim(),t=new AV.Query(i);t.equalTo("url",s),t.find({success:function(e){if(0<e.length){var t=e[0];t.fetchWhenSave(!0),t.increment("time"),t.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var n=new i,o=new AV.ACL;o.setPublicReadAccess(!0),o.setPublicWriteAccess(!0),n.setACL(o),n.set("title",r),n.set("url",s),n.set("time",1),n.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):1<$(".post-title-link").length&&showTime(e)})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>